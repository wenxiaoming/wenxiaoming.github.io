<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="machine learning," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="0x1 总体结构clDNN(Compute Library for Deep Neural Networks)是采用OpenCL来加速DNN(Deep Neural Networks)的framework。目标平台是Intel® HD and Iris™ Pro Graphics。clDNN目前已经是Intel OpenVINO的一部分。OpenVINO还包括了其它各种硬件平台的加速库，如CPU上">
<meta name="keywords" content="machine learning">
<meta property="og:type" content="article">
<meta property="og:title" content="clDNN Introduction">
<meta property="og:url" content="http://yoursite.com/2020/03/15/clDNN Introduction/index.html">
<meta property="og:site_name" content="Kevin Wen&#39;s Blog">
<meta property="og:description" content="0x1 总体结构clDNN(Compute Library for Deep Neural Networks)是采用OpenCL来加速DNN(Deep Neural Networks)的framework。目标平台是Intel® HD and Iris™ Pro Graphics。clDNN目前已经是Intel OpenVINO的一部分。OpenVINO还包括了其它各种硬件平台的加速库，如CPU上">
<meta property="og:image" content="http://yoursite.com/2020/03/15/clDNN%20Introduction/cldnn.png">
<meta property="og:image" content="http://yoursite.com/2020/03/15/clDNN%20Introduction/workflow.jpg">
<meta property="og:image" content="http://yoursite.com/2020/03/15/clDNN%20Introduction/loadnetwork.svg">
<meta property="og:image" content="http://yoursite.com/2020/03/15/clDNN%20Introduction/infer.svg">
<meta property="og:image" content="http://yoursite.com/2020/03/15/clDNN%20Introduction/execution_sync.png">
<meta property="og:image" content="http://yoursite.com/2020/03/15/clDNN%20Introduction/execution_async.png">
<meta property="og:updated_time" content="2020-08-15T14:11:15.136Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="clDNN Introduction">
<meta name="twitter:description" content="0x1 总体结构clDNN(Compute Library for Deep Neural Networks)是采用OpenCL来加速DNN(Deep Neural Networks)的framework。目标平台是Intel® HD and Iris™ Pro Graphics。clDNN目前已经是Intel OpenVINO的一部分。OpenVINO还包括了其它各种硬件平台的加速库，如CPU上">
<meta name="twitter:image" content="http://yoursite.com/2020/03/15/clDNN%20Introduction/cldnn.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2020/03/15/clDNN Introduction/"/>





  <title>clDNN Introduction | Kevin Wen's Blog</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  















  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Kevin Wen's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/15/clDNN Introduction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">clDNN Introduction</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-03-15T20:20:31+09:00">
                2020-03-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2020/03/15/clDNN Introduction/" class="leancloud_visitors" data-flag-title="clDNN Introduction">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="0x1-总体结构"><a href="#0x1-总体结构" class="headerlink" title="0x1 总体结构"></a>0x1 总体结构</h1><p>clDNN(Compute Library for Deep Neural Networks)是采用OpenCL来加速DNN(Deep Neural Networks)的framework。目标平台是Intel® HD and Iris™ Pro Graphics。clDNN目前已经是Intel OpenVINO的一部分。OpenVINO还包括了其它各种硬件平台的加速库，如CPU上的加速库mklDNN等。clDNN当然也可以改造成在NVIDIA和AMD的GPU上运行，虽然这个时候的性能可能需要进一步tuning。</p>
<p>clDNN对DNN中有关概念进行了抽象，其中有关数据类型的层次结构如下。</p>
<p><img src="/2020/03/15/clDNN Introduction/cldnn.png" alt=""></p>
<p>这些数据类型的定义简单说明如下。</p>
<p>Kernel - 算子计算的OpenCL实现。<br>Primitive - DNN中基本运算单元，如convolution, pooling, softmax等，也就是通常所说的算子。<br>Data - 特殊的算子，用来表示运算过程中的参数，如weights和biases, 也指DNN的输入和输出。<br>Engine - DNN中运行的加速器的类型，目前只有OpenCL engine一种。<br>Topology - 指DNN中的graph，其中包括了primitives, data和他们之间的关系。<br>Program - 位于Topology和Network之间(可选项)，是编译好的graph网络但是没有分配内存。<br>Network - 编译好的graph网络并且已经分配内存，可以运行，在编译网络的过程中，网络参数可以进行特殊的优化如fusing，data reordering等。</p>
<p>clDNN的执行<a href="https://intel.github.io/clDNN/index.html" target="_blank" rel="external">流程图</a>如下所示。</p>
<p><img src="/2020/03/15/clDNN Introduction/workflow.jpg" alt=""></p>
<p>执行过程包括下面的步骤<br>a.Create Engine.<br>b.Declare or define primitives parameters (weights and biases) if needed.<br>c.Create primitives. It is required to provide name for each primitive.<br>d.Create topology<br>e.Add primitives to topology<br>f.Build Network from topology<br>h.Set Inputs data<br>g.Execute Network</p>
<p>本文后续对这些过程进行详细的说明。</p>
<h1 id="0x2-LoadNetwork流程分析"><a href="#0x2-LoadNetwork流程分析" class="headerlink" title="0x2 LoadNetwork流程分析"></a>0x2 LoadNetwork流程分析</h1><p>   <img src="/2020/03/15/clDNN Introduction/loadnetwork.svg" alt=""><br>   LoadNetwork的执行流程如上图所示，下面详细来介绍一下其中涉及到的内容。</p>
<h2 id="0x21-kernel-selector"><a href="#0x21-kernel-selector" class="headerlink" title="0x21 kernel selector"></a>0x21 kernel selector</h2><p>  前面已经知道，clDNN是通过OpenCL来加速DNN的推理执行，就是说其中的算子是通过OpenCL来加速的，kernel就是指采用OpenCL内核实现的算子。<br>  kernel selector提供了如何选择最适合的kernel的接口，Primitive创建kernel的时候，调用kernel selector来得到最合适的kernel。</p>
<p>  上层不能直接操作OpenCL kernel，所以提供了对应的wrapper，这些wrapper都在下面这个目录中。<br>  inference-engine\thirdparty\clDNN\kernel_selector\core\actual_kernels<br>  另外wrapper还定义了kernel支持的输入和输出数据格式。</p>
<p>  对应的OpenCL kernel的定义都在这个目录下面。<br>  inference-engine\thirdparty\clDNN\kernel_selector\core\cl_kernels</p>
<p>  现在我们想知道OpenCL kernel是什么时候创建的呢？通过分析代码，我们可以知道OpenCL kernel的创建是在build_program的时候通过下面的循环来实现的。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">void</span> compile_graph::run(program_impl&amp; p) &#123;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; node : p.get_processing_order()) &#123;</div><div class="line">        <span class="keyword">if</span> (!node-&gt;is_type&lt;internal_primitive&gt;() &amp;&amp; !node-&gt;is_type&lt;data&gt;()) &#123;</div><div class="line">            node-&gt;get_output_layout();</div><div class="line">            <span class="keyword">if</span> (!node-&gt;is_type&lt;data&gt;() &amp;&amp; !(node-&gt;is_type&lt;mutable_data&gt;() &amp;&amp; node-&gt;get_dependencies().empty())) &#123;</div><div class="line">                node-&gt;selected_impl = node-&gt;type()-&gt;choose_impl(p.get_engine(), *node);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>上述代码中selected_impl的定义为primitive_impl类型的std::shared_ptr变量。<br>上述函数会调用到下面的create()函数。<br>这个函数再通过调用kernel_selector.GetBestKernels来创建最合适的OpenCL kernel。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">static</span> primitive_impl* <span class="title">create</span><span class="params">(<span class="keyword">const</span> scale_node&amp; arg)</span> </span>&#123;</div><div class="line">    ......</div><div class="line">    ew_params.layoutBased = <span class="literal">true</span>;</div><div class="line"></div><div class="line">    <span class="keyword">auto</span>&amp; kernel_selector = kernel_selector::eltwise_kernel_selector::Instance();</div><div class="line">    <span class="keyword">auto</span> best_kernels = kernel_selector.GetBestKernels(ew_params, ew_optional_params);</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> scale = <span class="keyword">new</span> scale_gpu(arg, best_kernels[<span class="number">0</span>]);</div><div class="line"></div><div class="line">    <span class="keyword">return</span> scale;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="0x22-primitive封装"><a href="#0x22-primitive封装" class="headerlink" title="0x22 primitive封装"></a>0x22 primitive封装</h2><p>primitive是对前面通过kernel selector取得的kernel的封装。<br>其中的primitive结构体都是通过typed_primitive_gpu_impl来定义的。</p>
<p>clDNN Library提供了下面这些<a href="https://intel.github.io/clDNN/index.html" target="_blank" rel="external">primitives</a>，</p>
<pre><code>Convolution
Fully connected (inner product)
Pooling
    average
    maximum
Normalization
    across channel
    within channel
    batch
Activation
    logistic
    tanh
    rectified linear unit (ReLU)
    softplus (softReLU)
    abs
    square
    sqrt
    linear
Softmax
Crop
Deconvolution
Depth concatenation
Eltwise
ROI pooling
Simpler NMS
Prior box
Detection output
</code></pre><p>通过对上述primitive的封装，clDNN提供了下面的topologies<br>    Alexnet<br>    Googlenet(v1-v3)<br>    ResNet<br>    VGG<br>    faster-rCNN and other.</p>
<h2 id="0x23-OpenCL接口的封装"><a href="#0x23-OpenCL接口的封装" class="headerlink" title="0x23 OpenCL接口的封装"></a>0x23 OpenCL接口的封装</h2><p>在目录inference-engine\thirdparty\clDNN\src\gpu\下面提供了OpenCL封装的代码，这些代码对OpenCL的底层api进行了封装，方便了clDNN其他模块的调用。</p>
<p>其中的gpu_queue类提供了对OpenCL command queue的封装，对外提供了command queue的创建和使用的接口。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">gpu_queue</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    ......</div><div class="line"><span class="keyword">private</span>:</div><div class="line">    <span class="keyword">uint32_t</span> id;</div><div class="line">    <span class="built_in">std</span>::weak_ptr&lt;gpu_toolkit&gt; _context;</div><div class="line">    cl::CommandQueue _command_queue;</div><div class="line">    <span class="built_in">std</span>::atomic&lt;<span class="keyword">uint64_t</span>&gt; _queue_counter&#123;<span class="number">0</span>&#125;;</div><div class="line">    <span class="built_in">std</span>::atomic&lt;<span class="keyword">uint64_t</span>&gt; _last_barrier&#123;<span class="number">0</span>&#125;;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;events_pool&gt; _events_pool;</div><div class="line">    cl::Event _last_barrier_ev;</div><div class="line">    <span class="keyword">bool</span> _output_event = <span class="literal">false</span>;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>gpu_toolkit类提供了OpenCL操作的统一接口，其他模块只需要调用gpu_toolkit就可以实现OpenCL的相关操作。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">gpu_toolkit</span> :</span> <span class="keyword">public</span> <span class="built_in">std</span>::enable_shared_from_this&lt;gpu_toolkit&gt; &#123;</div><div class="line">    ......</div><div class="line"><span class="keyword">private</span>:</div><div class="line">    configuration _configuration;</div><div class="line">    cl::Device _device;</div><div class="line">    cl::Context _context;</div><div class="line">    cl_platform_id _platform_id;</div><div class="line">    device_info_internal _device_info;</div><div class="line">    <span class="keyword">bool</span> _neo_driver = <span class="literal">false</span>;</div><div class="line">    kernels_cache _kernels_cache;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">map</span>&lt;<span class="keyword">uint32_t</span>, gpu_queue&gt; _command_queues_w;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;rapidjson::Document&gt; _device_cache;</div><div class="line">    kernels_binaries_container _binaries;</div><div class="line">    <span class="keyword">bool</span> _serialize = <span class="literal">false</span>;</div><div class="line"></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">string</span> _extensions;</div><div class="line"></div><div class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ocl_logger</span>;</span></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;ocl_logger&gt; _logger;</div><div class="line"></div><div class="line">    <span class="comment">// returns whether a barrier has been added</span></div><div class="line">    <span class="built_in">std</span>::<span class="function">ofstream&amp; <span class="title">open_log</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">    <span class="built_in">std</span>::<span class="function"><span class="built_in">string</span> <span class="title">get_device_version</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> _device.getInfo&lt;CL_DEVICE_VERSION&gt;(); &#125;</div><div class="line"></div><div class="line">    <span class="comment">// void build_command_queues();</span></div><div class="line">    <span class="function">gpu_queue&amp; <span class="title">get_command_queue</span><span class="params">(<span class="keyword">uint32_t</span> id)</span></span>;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h2 id="0x24-graph-optimizer"><a href="#0x24-graph-optimizer" class="headerlink" title="0x24 graph optimizer"></a>0x24 graph optimizer</h2><p>在build_program的时候会初始化graph，然后执行graph优化，包括pre_optimize_graph和post_optimize_graph。<br>执行步骤都是在下面的build_program函数中完成的。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">void</span> program_impl::build_program(<span class="keyword">bool</span> is_internal) &#123;</div><div class="line">    init_graph();</div><div class="line">    &#123; pre_optimize_graph(is_internal); &#125;</div><div class="line">    run_graph_compilation();</div><div class="line">    &#123; post_optimize_graph(is_internal); &#125;</div><div class="line">    prepare_memory_dependencies();</div><div class="line">    engine-&gt;compile_program(*<span class="keyword">this</span>);</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (!is_internal)</div><div class="line">        prim_info = get_current_stage_info();</div><div class="line"></div><div class="line">    cleanup();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>下面来分析一下pre_optimize_graph和post_optimize_graph分别是如何对graph进行优化的。<br>graph优化是通过调用apply_opt_pass来实现的。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">apply_opt_pass&lt;trim_to_outputs&gt;();</div></pre></td></tr></table></figure>
<p>apply_opt_pass是模板函数，模板参数trim_to_outputs是继承于base_pass的优化pass。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">trim_to_outputs</span> :</span> <span class="keyword">public</span> base_pass &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    trim_to_outputs() : base_pass(<span class="string">"trimmed"</span>) &#123;&#125;</div><div class="line"></div><div class="line"><span class="keyword">private</span>:</div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">(program_impl&amp; p)</span> override</span>;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>模板函数apply_opt_pass的定义如下。在模板函数中生成Pass对象，Pass对象的基类是base_pass，然后调用pass_manager的run函数执行优化操作。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">apply_opt_pass</span><span class="params">(base_pass&amp; pass)</span> </span>&#123; pm-&gt;run(*<span class="keyword">this</span>, pass); &#125;</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span> <span class="title">Pass</span>, <span class="title">typename</span>... <span class="title">Args</span>&gt;</span></div><div class="line"><span class="title">typename</span> <span class="title">std</span>::enable_if&lt;<span class="built_in">std</span>::is_base_of&lt;base_pass, Pass&gt;::value &amp;&amp;</div><div class="line">                        <span class="built_in">std</span>::is_constructible&lt;Pass, Args...&gt;::value&gt;::<span class="function">type</span></div><div class="line"><span class="title">apply_opt_pass</span><span class="params">(Args&amp;&amp;... args)</span> &#123;</div><div class="line">    <span class="keyword">auto</span> pass = Pass(<span class="built_in">std</span>::forward&lt;Args&gt;(args)...);</div><div class="line">    apply_opt_pass(pass);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>pass_manager的run函数定义如下。在run函数里会调用优化pass的run函数来执行具体的优化操作。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">void</span> pass_manager::run(program_impl&amp; p, base_pass&amp; pass) &#123;</div><div class="line">    ......</div><div class="line">    pass.run(p);</div><div class="line">    ......</div><div class="line">    pass_count++;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="0x25-program-node创建"><a href="#0x25-program-node创建" class="headerlink" title="0x25 program node创建"></a>0x25 program node创建</h2><p>program_node的定义如下，每一个program_node和一个primitive_impl相对应，primitive_impl是前面提到的OpenCL kernel函数的封装。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/*</span></div><div class="line">    Base class for all primitives which wraps API class and extends it to be used</div><div class="line">    in graph context.</div><div class="line">*/</div><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">program_node</span> &#123;</span></div><div class="line">    ......</div><div class="line"><span class="keyword">protected</span>:</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;primitive&gt; desc;</div><div class="line">    program_impl&amp; myprog;</div><div class="line"></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;primitive_impl&gt; selected_impl;</div><div class="line"></div><div class="line">    <span class="keyword">bool</span> valid_output_layout = <span class="literal">false</span>;</div><div class="line">    layout output_layout = layout(data_types::f32, format::bfyx, tensor());</div><div class="line"></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;program_node*&gt; dependencies;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">list</span>&lt;program_node*&gt; users;</div></pre></td></tr></table></figure>
<p>program_node的创建函数如下，创建好的node保存在nodes_map中。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// create all nodes from topology primitives, add dependencies among them and create inputs list</span></div><div class="line"><span class="keyword">void</span> program_impl::prepare_nodes(topology_impl <span class="keyword">const</span>&amp; topology) &#123;</div><div class="line">    <span class="keyword">auto</span> <span class="keyword">const</span>&amp; topo_map = topology.get_primitives();</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; prim : topo_map) &#123;</div><div class="line">        get_or_create(prim.second);</div><div class="line">    &#125;</div><div class="line">    ......</div><div class="line">&#125;</div><div class="line"></div><div class="line">program_node&amp; program_impl::get_or_create(<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;primitive&gt; prim) &#123;</div><div class="line">    <span class="keyword">auto</span> itr = nodes_map.lower_bound(prim-&gt;id);</div><div class="line">    <span class="keyword">if</span> (itr != nodes_map.end() &amp;&amp; itr-&gt;first == prim-&gt;id)</div><div class="line">        <span class="keyword">return</span> *itr-&gt;second;</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> new_node = prim-&gt;type-&gt;create_node(*<span class="keyword">this</span>, prim);</div><div class="line">    nodes_map.insert(itr, &#123;prim-&gt;id, new_node&#125;);</div><div class="line">    <span class="keyword">return</span> *new_node;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>typed_program_node是program_node的继承类，提供了对各种类型的program_node的封装。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">template</span> &lt;&gt;</div><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">typed_program_node</span>&lt;activation&gt; :</span> <span class="keyword">public</span> typed_program_node_base&lt;activation&gt; &#123;</div><div class="line">    <span class="keyword">using</span> parent = typed_program_node_base&lt;activation&gt;;</div><div class="line">    typed_program_node(<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;activation&gt; prim, program_impl&amp; prog) : parent(prim, prog) &#123;</div><div class="line">        support_padding_all(<span class="literal">true</span>);</div><div class="line">    &#125;</div><div class="line">    ......</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h1 id="0x3-Infer流程分析"><a href="#0x3-Infer流程分析" class="headerlink" title="0x3 Infer流程分析"></a>0x3 Infer流程分析</h1><p>前面网络加载好了以后，下面就开始真正的推理执行了，详细的流程如下。<br>   <img src="/2020/03/15/clDNN Introduction/infer.svg" alt=""><br>这个时候为了加速推理执行，如上图所示，采用了多线程的方法来提高执行的并行度，主线程把不同stage的task分配到不同的线程中去执行。<br>每个kernel执行的时候会调用enqueueNDRangeKernel来issue OpenCL驱动来执行计算。</p>
<p>我们知道一个推理网络执行的时候会有很多算子在执行，这些算子的执行在GPU上，如果每个算子执行完成以后都需要把结果从GPU读取到CPU中的话，效率会很低，这种执行模型如下所示，我们称之为sync执行模式。<br>   <img src="/2020/03/15/clDNN Introduction/execution_sync.png" alt=""></p>
<p>clDNN中采用的是如下图所示的async执行模型，各个算子之间的同步通过event来控制，每次算子执行完成以后，不需要把数据从GPU读取到CPU中。整个流程中只需要一次GPU buffer写入操作和一次GPU buffer读取操作。<br>   <img src="/2020/03/15/clDNN Introduction/execution_async.png" alt=""></p>
<p>下面是clDNN中enqueue kernel的代码。从代码中我们可以看到算子在每次执行enqueueNDRangeKernel的时候，需要等待一个算子执行完成的event被触发，这样算子之间的数据同步就不需要CPU的干预了。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line">event_impl::ptr gpu_queue::enqueue_kernel(cl::Kernel <span class="keyword">const</span>&amp; kern,</div><div class="line">                                          cl::NDRange <span class="keyword">const</span>&amp; global,</div><div class="line">                                          cl::NDRange <span class="keyword">const</span>&amp; local,</div><div class="line">                                          <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;event_impl::ptr&gt; <span class="keyword">const</span>&amp; deps) &#123;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;cl::Event&gt; dep_events;</div><div class="line">    <span class="keyword">auto</span> dep_events_ptr = &amp;dep_events;</div><div class="line">    <span class="keyword">if</span> (!context()-&gt;get_configuration().host_out_of_order) &#123;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; dep : deps)</div><div class="line">            <span class="keyword">if</span> (<span class="keyword">auto</span> ocl_ev = <span class="keyword">dynamic_cast</span>&lt;base_event*&gt;(dep.get()))</div><div class="line">                dep_events.push_back(ocl_ev-&gt;get());</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">        dep_events_ptr = <span class="literal">nullptr</span>;</div><div class="line"></div><div class="line">        sync_events(deps);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    cl::Event ret_ev;</div><div class="line"></div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        <span class="keyword">if</span> (!context()-&gt;get_configuration().host_out_of_order || _output_event ||</div><div class="line">            context()-&gt;get_configuration().enable_profiling) &#123;</div><div class="line">            _command_queue.enqueueNDRangeKernel(kern, cl::NullRange, global, local, dep_events_ptr, &amp;ret_ev);</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            _command_queue.enqueueNDRangeKernel(kern, cl::NullRange, global, local, dep_events_ptr, <span class="literal">nullptr</span>);</div><div class="line">        &#125;</div><div class="line">    &#125; <span class="keyword">catch</span> (cl::Error <span class="keyword">const</span>&amp; err) &#123;</div><div class="line">        <span class="keyword">throw</span> ocl_error(err);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> _events_pool-&gt;get_from_base_pool(context(), ret_ev, ++_queue_counter);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">void</span> gpu_queue::sync_events(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;event_impl::ptr&gt; <span class="keyword">const</span>&amp; deps) &#123;</div><div class="line">    <span class="keyword">bool</span> needs_barrier = <span class="literal">false</span>;</div><div class="line">    ......</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (needs_barrier) &#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            <span class="keyword">if</span> (_output_event)</div><div class="line">                _command_queue.enqueueBarrierWithWaitList(<span class="literal">nullptr</span>, &amp;_last_barrier_ev);</div><div class="line">            <span class="keyword">else</span></div><div class="line">                _command_queue.enqueueBarrierWithWaitList(<span class="literal">nullptr</span>, <span class="literal">nullptr</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (cl::Error <span class="keyword">const</span>&amp; err) &#123;</div><div class="line">            <span class="keyword">throw</span> ocl_error(err);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        _last_barrier = ++_queue_counter;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/machine-learning/" rel="tag"># machine learning</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/02/22/Cycles in Blender/" rel="next" title="Cycles in Blender">
                <i class="fa fa-chevron-left"></i> Cycles in Blender
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/04/26/About SceneGraph/" rel="prev" title="About SceneGraph">
                About SceneGraph <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Kevin Wen" />
          <p class="site-author-name" itemprop="name">Kevin Wen</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">44</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">20</span>
                <span class="site-state-item-name">标签</span>
              
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#0x1-总体结构"><span class="nav-number">1.</span> <span class="nav-text">0x1 总体结构</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#0x2-LoadNetwork流程分析"><span class="nav-number">2.</span> <span class="nav-text">0x2 LoadNetwork流程分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#0x21-kernel-selector"><span class="nav-number">2.1.</span> <span class="nav-text">0x21 kernel selector</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#0x22-primitive封装"><span class="nav-number">2.2.</span> <span class="nav-text">0x22 primitive封装</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#0x23-OpenCL接口的封装"><span class="nav-number">2.3.</span> <span class="nav-text">0x23 OpenCL接口的封装</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#0x24-graph-optimizer"><span class="nav-number">2.4.</span> <span class="nav-text">0x24 graph optimizer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#0x25-program-node创建"><span class="nav-number">2.5.</span> <span class="nav-text">0x25 program node创建</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#0x3-Infer流程分析"><span class="nav-number">3.</span> <span class="nav-text">0x3 Infer流程分析</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Kevin Wen</span>
</div>


<div> <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
访问量 <span id="busuanzi_value_site_pv"></span>
访问人数 <span id="busuanzi_value_site_uv"></span>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("orq8xxsDQDXKiHdqSRcjlflB-gzGzoHsz", "ecCFdIcWDfbJKQOCiLFf1EBm");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  

  

  

</body>
</html>
