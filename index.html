<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta property="og:type" content="website">
<meta property="og:title" content="Kevin Wen&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Kevin Wen&#39;s Blog">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kevin Wen&#39;s Blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>Kevin Wen's Blog</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  















  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Kevin Wen's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/02/20/Mixed Render Architecture/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/02/20/Mixed Render Architecture/" itemprop="url">Mixed Render Architecture</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-02-20T22:21:36+09:00">
                2022-02-20
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2022/02/20/Mixed Render Architecture/" class="leancloud_visitors" data-flag-title="Mixed Render Architecture">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="0x1-混合渲染架构"><a href="#0x1-混合渲染架构" class="headerlink" title="0x1 混合渲染架构"></a>0x1 混合渲染架构</h1><p>在开发渲染程序的过程中，我们常常会碰到需要把多个渲染引擎混合在一起使用的场景，如android中渲染视频数据的时候还需要渲染UI。游戏中渲染游戏3D场景的时候还需要渲染UI等场景。本文对这种混合渲染的架构进行了总结。下面对五种混合渲染方式进行了分别介绍。</p>
<h1 id="0x2-SurfaceView"><a href="#0x2-SurfaceView" class="headerlink" title="0x2 SurfaceView"></a>0x2 SurfaceView</h1><p><img src="/2022/02/20/Mixed Render Architecture/SurfaceView.png" alt=""><br>我们知道SurfaceView是在Android中提出的概念。Android中的UI显示采用了View的架构进行处理，View可以满足大部分的绘图需求，但是有时候，View却显得力不从心，所以Android提供了SurfaceView给Android开发者，以满足更多的绘图需求。</p>
<p>SurfaceView是一个组件，可用于在View层次结构中嵌入其他合成层。但因为SurfaceView拥有独立于主View之外的独立渲染线程，SurfaceView的内容对其他View来说是透明的，也就是说SurfaceView的绘制游离于其他View的控制之外。</p>
<p>使用SurfaceView进行渲染时，SurfaceFlinger会直接将SurfaceView的输出缓冲区直接合成到屏幕上。如果没有SurfaceView，则需要将绘制内容先绘制到其他View对应的Surface中，注意该Surface也包括了其他View的内容绘制，然后再作为一层合成到屏幕上，而使用SurfaceView进行渲染可以省去额外的工作。但是SurfaceView是作为单独的一层合成到屏幕上的，在拥有绘制灵活性的同时也消耗了更多的内存。</p>
<p>View和SurfaceView的区别主要有这两点，<br>一是View适用于主动更新的情况，而SurfaceView则适用于被动更新的情况，比如频繁刷新界面。另外一点是View是在主线程中对页面进行刷新，而SurfaceView则需要开启一个子线程来对页面进行刷新。</p>
<p>GLSurfaceView<br>GLSurfaceView提供了帮助管理EGL上下文、在线程间通信以及与activity生命周期交互的辅助程序类。GLSurfaceView会创建一个渲染线程，并在线程上配置EGL上下文。大多数应用无需了解有关 EGL 的任何信息即可通过 GLSurfaceView 来使用GLES。</p>
<h1 id="0x3-TextureView"><a href="#0x3-TextureView" class="headerlink" title="0x3 TextureView"></a>0x3 TextureView</h1><p><img src="/2022/02/20/Mixed Render Architecture/TextureView.png" alt=""><br>TextureView一般和SurfaceTexture配合使用。<br>SurfaceTexture一般包括producer和consumer模块，producer负责生产texture，生产好了通知consumer，consumer把texture作为view的贴图输入完成SurfaceTexture的绘制。TextureView 类是一个结合了 View 和 SurfaceTexture 的 View 对象。可以理解为在主窗口的体系之内的子View，和主窗口的其他View形成父子关系，可以一起联动，形成复杂的渲染效果。</p>
<p>SurfaceTexture 是Surface和OpenGL ES (GLES)纹理的组合。SurfaceTexture实例用于提供输出到 GLES 纹理的接口。</p>
<p>SurfaceTexture包含一个以应用为使用方的BufferQueue实例。当生产方将新的缓冲区排入队列时，onFrameAvailable() 回调会通知应用。然后，应用调用updateTexImage()。这会释放先前占用的缓冲区，从队列中获取新缓冲区并执行EGL调用，从而使GLES可将此缓冲区作为外部纹理使用。</p>
<p>TextureView对象会对SurfaceTexture进行包装，从而响应回调以及获取新的缓冲区。在TextureView获取新的缓冲区时，TextureView会发出View失效请求，并使用最新缓冲区的内容作为数据源进行绘图，根据View状态的指示，以相应的方式在相应的位置进行呈现。</p>
<p>与SurfaceView 相比，TextureView具有更出色的UI绘制操作能力，但在视频上以分层方式合成界面元素时，SurfaceView具有性能方面的优势。当客户端使用SurfaceView呈现内容时，SurfaceView会为客户端提供单独的合成层。如果设备支持，SurfaceFlinger会将单独的层合成为硬件叠加层。当客户端使用TextureView呈现内容时，界面工具包会使用GPU将 TextureView的内容合成到视图层次结构中。对内容进行的更新可能会导致其他View元素重绘，例如，在其他View被置于TextureView顶部时。View呈现完成后，SurfaceFlinger会合成应用界面层和所有其他层，以便每个可见像素合成两次。</p>
<h1 id="0x4-同一个Shared-Context-直接渲染"><a href="#0x4-同一个Shared-Context-直接渲染" class="headerlink" title="0x4 同一个Shared Context 直接渲染"></a>0x4 同一个Shared Context 直接渲染</h1><p><img src="/2022/02/20/Mixed Render Architecture/Direct Render.png" alt=""><br>我们把这种渲染混合方式叫做DirectRender。<br>简单把流程说明如下，这里假设渲染采用EGL与系统窗口系统进行对接。<br>Main Render负责创建EGL环境，然后CPU准备绘制数据，并把绘制数据送到GPU，然后调用GPU Draw函数进行绘制，注意这个时候并没有调用SwapBuffer，<br>而是去调用了Sub Render的绘制流程，在SubRender中同样完成绘制数据准备和调用GPU Draw函数进行绘制的过程，最后再去调用SwapBuffer。<br>在Main Render和Sub Render的切换过程中，涉及到GL状态的切换，可能两个Render之间的设置存在冲突，需要有一个保存和恢复的过程，另外有些状态的设置需要在两个引擎之间配合好，否则会出现各种显示问题。<br>另外一点是这个Main Render和Sub Render是在同一个渲染线程中运行，没有多线程的切换。</p>
<h1 id="0x5-同一个Shared-Context-fbo渲染"><a href="#0x5-同一个Shared-Context-fbo渲染" class="headerlink" title="0x5 同一个Shared Context fbo渲染"></a>0x5 同一个Shared Context fbo渲染</h1><p><img src="/2022/02/20/Mixed Render Architecture/FBO Render.png" alt=""><br>简单把流程说明如下，<br>Main Render负责创建EGL环境，然后CPU准备绘制数据，并把绘制数据送到GPU，然后调用GPU Draw函数进行绘制，<br>然后调用了Sub Render的绘制流程，Sub Render的绘制结果是保存在framebuffer object中，这个framebuffer object和一个texture绑定在一起。<br>在SubRender中同样完成绘制数据准备和调用GPU Draw函数进行绘制以后，也就是说对framebuffer object进行了写入，这个时候texture也就准备好了，<br>Main Render拿着这个texture作为输入，再进行一次绘制，最后再去调用SwapBuffer输出。<br>在Main Render和Sub Render的切换过程中，也涉及到GL状态的切换，有些状态的设置也是需要在两个引擎之间配合好，否则会出现各种显示问题。另外一点是这个Main Render和Sub Render也是在同一个渲染线程中运行。</p>
<h1 id="0x6-shared-context渲染"><a href="#0x6-shared-context渲染" class="headerlink" title="0x6 shared context渲染"></a>0x6 shared context渲染</h1><p><img src="/2022/02/20/Mixed Render Architecture/Shared Context Render.png" alt=""></p>
<p>简单把流程说明如下，<br>Main Render负责创建EGL环境，然后CPU准备绘制数据，并把绘制数据送到GPU，然后调用GPU Draw函数进行绘制。<br>Sub Render通过shared context的方式创建，也是需要完成EGL设置的过程，另外这个Sub Render创建的Surface是Pbuffer，是offscreen的。<br>另外这个Sub Render的绘制结果也是保存在framebuffer object中，这个framebuffer object和一个texture绑定在一起。<br>在SubRender中同样完成绘制数据准备和调用GPU Draw函数进行绘制以后，这个时候Main Render和Sub Render有一个sync的操作。<br>保证对Sub Render对framebuffer object进行了写入，texture也是准备好了。<br>然后Main Render拿着这个texture作为输入，再进行一次绘制，最后再去调用SwapBuffer输出。<br>在Main Render和Sub Render的切换过程中，由于采用的是Shared Context架构，GL状态在Main Render和Sub Render之间相对比较独立，相互的影响比较小。另外一点是这个Main Render和Sub Render是在两个独立的渲染线程中运行。</p>
<p>下面再对Shared Context的绘制渲染架构进行详细的分析。<br>我们知道OpenGL是一个线程级别的状态机，其操作被局限在一个线程中进行。OpenGL 的绘制命令都是作用在当前的 Context 上，这个 Current Context是一个线程私有thread-local）的变量。如果在多线程环境下操作同一个opengl context，对opengl api的调用需要加锁进行保护。否则会出现各种问题。<br>通过共享context架构，上下文是可以在多个线程间共享的，在使用eglCreateContext时， 可以传入一个已创建成功的上下文， 这样就可以得到一个共享的上下文(Shared Context)，我们可以实现多个渲染线程并行处理，其中一些线程作为生产者，这些生产者一般是离屏渲染，生成相关纹理供另外的线程消费、</p>
<p>举例来说, Google为Android的MediaCodec设计了一套基于OpenGL的Pipeline, 其涉及的模块包括 Video Capture, Pre-processing, Encode, Decode, Post processing，Render等。上述的整个Pipeline会在多个线程中工作. 可以使用Shared Context的方式为这个架构设计高度优化的Pipeline，这样设计思路也比较自然。如果强制设计为单独context的架构，各个线程的OpenGL操作都需要post任务到OpenGL线程来处理，涉及到多次加锁保护的过程，无论是架构的可读性，还是系统的性能应该都会受到影响。</p>
<p>另外Shared Context架构下共享资源有纹理，shader，Buffer等。不共享资源有FBO, VAO等。</p>
<h1 id="0x7-Shared-Contxt架构下纹理共享访问问题"><a href="#0x7-Shared-Contxt架构下纹理共享访问问题" class="headerlink" title="0x7 Shared Contxt架构下纹理共享访问问题"></a>0x7 Shared Contxt架构下纹理共享访问问题</h1><p>这个问题是Shared Contxt架构下渲染绘制crash问题，场景是webview播放视频的时候crash，crash的位置在GPU驱动中，但是具体原因未知。<br>大概的渲染流程是这样的，UI渲染是Main Render负责的，webview播放视频是Sub Render绘制完成的，其中用到了Shared context架构，webview播放视频的过程渲染到纹理中，Main Render拿到这个纹理后完成真正的视频内容绘制。<br>通过分析大概的渲染流程，我怀疑是Shared context架构下纹理访问冲突问题。根据前面的分析，Sub Render会通过填充纹理内容的方式生产绘制内容，Main Render得到纹理内容以后再读入GPU，最后完成渲染。如果Main Render读取纹理内容的同时，Sub Render正在填充纹理的话，肯定就发生访问冲突了。</p>
<p>我们通过一个单元测试来模拟这个问题。看看出现crash的地方是否和真实场景下出错的地方一致。<br>piglit下面有相关的Shared Context测试，代码位于piglit/tests/glx/glx-multithread-texture.c<br>其中包括一个纹理填充线程，一个纹理读取线程。我们通过在修改测试代码，模拟前面说的读取个填充纹理同时发生的情况。<br>但是很遗憾，没有出现crash。看来这个问题对timing很敏感，应该是特定时序下发生的问题<br>看来这能在GPU驱动代码mesa中hack来复现了。如下所示，这个是在Main Render执行纹理读取设置的时候加一个sleep等待。等待Sub Render有足够的时间去修改纹理设置。果然这样hack以后问题必现，而且出错的堆栈和真实场景下完全一致。<br>这样问题基本定位，最后发送确实是webview里面播放视频的时候分配的buffer不够用，导致Main Render和Sub Render出现纹理访问冲突的问题。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">diff --git a/src/mesa/state_tracker/st_sampler_view.c b/src/mesa/state_tracker/st_sampler_view.c</div><div class="line">index e4add1bd2c6.<span class="number">.61</span>b3ffe2e33 <span class="number">100644</span></div><div class="line">--- a/src/mesa/state_tracker/st_sampler_view.c</div><div class="line">+++ b/src/mesa/state_tracker/st_sampler_view.c</div><div class="line">@@ <span class="number">-642</span>,<span class="number">7</span> +<span class="number">642</span>,<span class="number">15</span> @@ st_get_texture_sampler_view_from_stobj(struct st_context *st,</div><div class="line">...</div><div class="line">       struct pipe_sampler_view *view = sv-&gt;view;</div><div class="line">+</div><div class="line">+      <span class="keyword">static</span> <span class="keyword">int</span> counter = <span class="number">0</span>;</div><div class="line">+      <span class="keyword">while</span> (counter++ &lt; <span class="number">20</span>) &#123;</div><div class="line">+         sleep(<span class="number">5</span>);</div><div class="line">+      &#125;</div><div class="line">+      </div><div class="line">       assert(stObj-&gt;pt == view-&gt;texture);</div><div class="line">       assert(!check_sampler_swizzle(st, stObj, view, glsl130_or_later));</div><div class="line">       assert(get_sampler_view_format(st, stObj, srgb_skip_decode) == view-&gt;format);</div></pre></td></tr></table></figure>
<h1 id="0x8-参考资料"><a href="#0x8-参考资料" class="headerlink" title="0x8 参考资料"></a>0x8 参考资料</h1><p><a href="https://source.android.google.cn/devices/graphics/arch-st?hl=zh-cn" target="_blank" rel="external">https://source.android.google.cn/devices/graphics/arch-st?hl=zh-cn</a><br><a href="https://zhuanlan.zhihu.com/p/444440326" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/444440326</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/02/13/Linux Memory Management/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2022/02/13/Linux Memory Management/" itemprop="url">Linux Memory Management</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-02-13T18:10:10+09:00">
                2022-02-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2022/02/13/Linux Memory Management/" class="leancloud_visitors" data-flag-title="Linux Memory Management">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="/2022/02/13/Linux Memory Management/1.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/2.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/3.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/4.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/5.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/6.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/7.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/8.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/9.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/10.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/11.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/12.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/13.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/14.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/15.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/16.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/17.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/18.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/19.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/20.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/21.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/22.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/23.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/24.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/25.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/26.png" alt=""><br><img src="/2022/02/13/Linux Memory Management/27.png" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/06/13/Thread Model of Unreal Engine/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/06/13/Thread Model of Unreal Engine/" itemprop="url">Thread Model of Unreal Engine</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-06-13T20:10:10+09:00">
                2021-06-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2021/06/13/Thread Model of Unreal Engine/" class="leancloud_visitors" data-flag-title="Thread Model of Unreal Engine">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="0x1-数据组织"><a href="#0x1-数据组织" class="headerlink" title="0x1 数据组织"></a>0x1 数据组织</h1><p>Unreal Engine的数据组织是典型的Scene Graph数据结构。</p>
<p>Scene拥有Component。</p>
<p>Component是各种渲染节点的抽象。</p>
<p>Render通过访问Scene拥有的Component来完成各种渲染操作。</p>
<p><img src="/2021/06/13/Thread Model of Unreal Engine/Unreal Engine-scene graph structure.svg" alt=""></p>
<h1 id="0x2-线程模型"><a href="#0x2-线程模型" class="headerlink" title="0x2 线程模型"></a>0x2 线程模型</h1><p>Unreal Engine代码中封装了典型的Thread/Looper机制来支持多线程。</p>
<p>多线程之间的通信采用Post Task的方式来进行，避免了加锁操作。</p>
<p>下图说明了Unreal Engine三个线程之间的交互。</p>
<p>Unreal Engine的三个线程分别是GameThread, RenderThread, RHIThread。</p>
<p>GameThread可以理解为Controller线程，完成整个渲染流程的控制。</p>
<p>RenderThread是典型的渲染流程，从Scene中读入数据，完成各种效果的处理，然后调用RHIThread完成绘制。</p>
<p>RHIThread是具体调用图形API(OpenGL, DirectX, Vulkan, Metal)来完成绘制的线程。</p>
<p><img src="/2021/06/13/Thread Model of Unreal Engine/Unreal Engine-thread model.svg" alt=""></p>
<p>下图说明了Unreal Engine绘制的简要流程。<br><img src="/2021/06/13/Thread Model of Unreal Engine/Unreal Engine-scene_update.svg" alt=""></p>
<p>下图说明了Unreal Engine渲染模块的层次调用关系。</p>
<p>Slate是Unreal Engine中包括的UI渲染框架。</p>
<p>Renderer里面包括两种渲染器。</p>
<p>然后是RenderCore模块。包括各种渲染效果的处理。</p>
<p>最底层是具体调用图形API的调用。</p>
<p><img src="/2021/06/13/Thread Model of Unreal Engine/Unreal Engine-render module.svg" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/04/06/VVC Decoder Analysis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/04/06/VVC Decoder Analysis/" itemprop="url">VVC Decoder Analysis</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-04-06T19:20:30+09:00">
                2021-04-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2021/04/06/VVC Decoder Analysis/" class="leancloud_visitors" data-flag-title="VVC Decoder Analysis">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-目前VVC-Codec现状"><a href="#1-目前VVC-Codec现状" class="headerlink" title="1. 目前VVC Codec现状"></a>1. 目前VVC Codec现状</h1><p>VVC标准已经于2020年正式成为国际标准，我们很想知道到目前为至VVC codec在产业界和学术界的实现情况是怎样的呢？<br>最新的JVET-V0021文档列举了VVC标准的最新实现进展。下面选取了JVET-V0021文档中对这部分的总结介绍, 更详细的信息请参考该文档。</p>
<h2 id="1-1-Publicly-available-software-source-code"><a href="#1-1-Publicly-available-software-source-code" class="headerlink" title="1.1 Publicly available software source code"></a>1.1 Publicly available software source code</h2><p>1) JVET has developed the VVC Test Model (VTM) as its reference software encoder and decoder codebase [5]. It is intended primarily to demonstrate coding efficiency capability and proper interpretation of the syntax and decoding process specified in the standard (but not as a speed-optimized implementation), and is intended to be usable as a starting basis for product implementations. The software is available under a BSD copyright licence.</p>
<p>2) InterDigital developed a multi-threaded VTM decoder, and reported 6–10× speed-up relative to the single-threaded reference software [6]. It is intended to support all features of the VTM. The software was later placed in an accessible repository, and it is available under the same BSD copyright licence as the VTM software [7].</p>
<p>3) Fraunhofer HHI announced the VVenC encoder and VVdeC decoder open-source software (release 0.1) in September 2020 [8][9][10][11][12]. It includes support for multithreading operation, single-pass rate control, perceptual QP adaptation, and motion-compensated temporal filtering (MCTF). The software has four defined presets for quality/speed tradeoff (called “slow”, “medium”, “fast”, and “faster”). Subjective testing reported in October 2020 indicated that the VVenC encoder had about the same or better subjective compression performance as the VTM encoder when operating in its “medium” speed configuration (operating with MCTF and QP adaptation disabled in the VTM and enabled in VVenC and with rate control disabled in both) with encoding speed more than 100× that of the VTM, for 4K UHD SDR video content [12][13]. As of December 2020, a “slower” preset was added, along with an improved single-pass rate control and a new two-pass rate control [14]. The “slower” preset mode reportedly achieves approximately the same BD-rate coding efficiency as the VTM while providing a speedup of more than 8.6x for UHD and 5.2x for HD sequences relative to the VTM. As of December 2020, with release 0.2, the software is available under a BSD copyright licence. Release 0.3 of March 2021 includes substantial further speed and multithreading improvements [15].</p>
<p>4) Friedrich–Alexander University Erlangen–Nürnberg released an open-source bitstream analyser as an add-on for the VTM decoder [16][17]. The analyzer counts the occurrence of coding tools and coding modes used in a decoded bitstream and can be used for evaluating the decoding energy and time demands of VVC features. The software is available under a BSD copyright licence.</p>
<h2 id="1-2-Software-decoders"><a href="#1-2-Software-decoders" class="headerlink" title="1.2 Software decoders"></a>1.2 Software decoders</h2><p>1) Sharp announced a real-time software decoder in June 2020, and issued a corresponding press release in December 2020 [18][19]. As of June 2020, it was reportedly capable of decoding 4K CTC UHD bitstreams at up to 40 Mbps at more than 60 fps.</p>
<p>2) Tencent announced its O266dec software decoder with SIMD and multithreading support and an associated FFmpeg/VLC-based video player in October 2020 [12][20][21]. As of December 2020, it is reportedly more than 3× the speed of the VTM reference software decoder when tested under VVC common test conditions (CTC) in single-threaded operation and about 20× the VTM decoder speed in 8-thread operation. It could reportedly decode UHD video at more than 60 fps at up to 40 Mbps and decode full HD video at more than 200 fps. In December 2020, a version with mobile platform support based on Arm Neon technology was reported. On an Apple A14 processor (iPhone 12pro) in single-threaded operation, it could reportedly decode 8-bit 1080p CTC bitstreams at more than 50 fps, and in multi-threaded operation it could decode such bitstreams at more than 100 fps and could decode 8-bit 4K UHD bitstreams at more than 30 fps in the RA configuration [22]. Although 8-bit operation was more optimized, the decoder also supports 10-bit operation.</p>
<p>3) Alibaba announced its Ali266 decoder for mobile devices (e.g., Android and iPhone) in December 2020 [23]. It includes optimizations for multi-threading, ARM assembly, cache efficiency, and memory usage, particularly for 8 bit video content. Real-time speed is reported for 8 bit 720p, 1080p (using 2–4 threads for up to 60 fps) and 4K (up to 7 Mbps) video content with the ALF feature disabled.</p>
<h2 id="1-3-Bitstream-analyser-products"><a href="#1-3-Bitstream-analyser-products" class="headerlink" title="1.3 Bitstream analyser products"></a>1.3 Bitstream analyser products</h2><p>1) Elecard announced support for VVC in its StreamEye and StreamAnalyzer products in April 2020 [24].</p>
<p>2) ViCueSoft supports VVC in its VQ Analyzer bitstream analysis product, as of late 2020 [25].</p>
<h2 id="1-4-Conformance-test-sets"><a href="#1-4-Conformance-test-sets" class="headerlink" title="1.4 Conformance test sets"></a>1.4 Conformance test sets</h2><p>1)  A conformance test set is under development by JVET. It reached the CD stage of the ISO/IEC approval process in October 2020 [26].</p>
<p>2)  Allegro DVT began offering a conformance test set for VVC as early as January 2020 (i.e., initially in preliminary form before the finalization of the standard) [27][28][29].</p>
<h2 id="1-5-Encoding-products-and-services"><a href="#1-5-Encoding-products-and-services" class="headerlink" title="1.5 Encoding products and services"></a>1.5 Encoding products and services</h2><p>1)  KDDI Research announced a real-time VVC encoder with 4K @60 fps capability in September 2020 [30].</p>
<p>2)  Ateme launched support for VVC in its Titan family of products, and demonstrated the technology in an OTT channel launched in November 2020 [31].</p>
<p>3)  Bitmovin, in partnership with Fraunhofer HHI based on VVencC as described in item 3, announced support of VVC in its video encoding platform in November 2020 [32].</p>
<h1 id="2-VVDec流程介绍"><a href="#2-VVDec流程介绍" class="headerlink" title="2. VVDec流程介绍"></a>2. VVDec流程介绍</h1><p>VVDec是Fraunhofer HHI开发的VVC解码器，实现了VVC解码器和进一步的优化，包括多线程优化和x86 SIMD优化。本文后面部分重点介绍一下VVDec中有关多线程解码的部分。</p>
<h2 id="2-1-解码流程介绍"><a href="#2-1-解码流程介绍" class="headerlink" title="2.1 解码流程介绍"></a>2.1 解码流程介绍</h2><p>VVC codec标准也是采用了传统的编解码器框架，由帧内预测，帧间预测，变换编码，量化，熵编码，环内滤波等子算法组成。VVC能提升编码压缩率的原因是对上述的子算法都进行了fine tuned，采用了复杂度更高，计算量更大的方法来提高压缩率。<br>VVC decoder的解码过程也是和传统的video decoder框架一致。首先是parser阶段，采用熵解码对基本的语法元素进行解码，然后是反量化过程，反量化的结果作为变换解码的输入，变换解码输出为残差值。这个残差值和解码得到的预测值相加就得到了解码数据。预测值解码数据又分成帧内预测解码和帧间预测解码两种，分别从时间域和空间域得到相应的预测数据。解码数据最后还需要进行滤波处理才能作为最后的解码输出和帧间预测解码的输入数据。</p>
<h2 id="2-2-CTU粒度多线程解码"><a href="#2-2-CTU粒度多线程解码" class="headerlink" title="2.2 CTU粒度多线程解码"></a>2.2 CTU粒度多线程解码</h2><p>我们知道video decoder的并行处理方式有GOP并行，frame并行，slice并行等。这些并行处理方式的实现相对简单，也是比较通用，不同的codec可以采取类似的机制来实现，如ffmpeg就把frame并行和slice并行做成了简单的框架，然后各个codec再调用这个通用的框架来实现并行处理。前面说的并行处理的缺点是并行处理的任务分配可能不均匀，不能很好地利用目前CPU多核的架构来进行充分地codec优化。VVdec实现的是另外一种并行处理机制。该机制把一帧图片的解码分别分成几部分并行执行，每个部分对应一个CTU行或者几个CTU行。我们把这个并行出来任务称为CTU task。这种并行处理方式粒度更小，更能充分利用多核的能力。<br>CTU task的划分如下图所示。<br><img src="/2021/04/06/VVC Decoder Analysis/ctu task.svg" alt=""><br>每个CTU task的解码过程再分成下面这些子任务。</p>
<pre><code><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">enum</span> TaskType</div><div class="line">&#123;</div><div class="line">    <span class="comment">/*TRAFO=-1,*/</span> MIDER, LF_INIT, INTER, INTRA, RSP, LF_V, LF_H, PRESAO, SAO, ALF, DONE, DMVR</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
</code></pre><p> <img src="/2021/04/06/VVC Decoder Analysis/splitted tasks.svg" alt=""></p>
<p>每个子任务开始之前都需要检查当前子任务的依赖是否已经执行完。如果依赖已经完成，则继续往下执行。如果依赖没有完成，则把该任务重新放入线程池中等待下次调度。在任务执行的每个阶段开始执行的时候都需要判断当前阶段对应的依赖有没有完成，如果没有，则退出当前任务执行，把任务重新放入线程池中等待下次调度。这个过程如下图所示。</p>
<p>下面来看一下这些子任务的依赖分别是什么。首先把图片划分成多个ctu task, 每个ctu task包括若干个ctu。每个ctu task是一个线程执行任务的最小单位。每个ctu task都有一个对应的TaskType来表示当前task对应解码状态，也就是说表示当前解码进行到哪一步了。这样我们可以通过比较依赖ctutask的TaskType来判断当前ctu task的依赖条件是否满足。</p>
<ol>
<li><p>INTER的依赖<br>数组thisLine和lineAbove分别表示当前ctu task行和上一个ctu task行的子任务状态。下面的代码表示当前ctu task需要等待</p>
   <figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span>( <span class="built_in">std</span>::all_of( cs.picture-&gt;slices.begin(), cs.picture-&gt;slices.end(), []( <span class="keyword">const</span> Slice* pcSlice ) &#123; <span class="keyword">return</span> pcSlice-&gt;isIntra(); &#125; ) )</div><div class="line">&#123;</div><div class="line">  <span class="comment">// not really necessary, but only for optimizing the wave-fronts</span></div><div class="line">  <span class="keyword">if</span>( col &gt; <span class="number">1</span> &amp;&amp; thisLine[col - <span class="number">2</span>] &lt;= INTER )</div><div class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">  <span class="keyword">if</span>( line &gt; <span class="number">0</span> &amp;&amp; lineAbove[col] &lt;= INTER )</div><div class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">&#125;</div><div class="line"><span class="keyword">if</span>( <span class="built_in">std</span>::any_of( cs.picture-&gt;refPicExtDepBarriers.cbegin(), cs.picture-&gt;refPicExtDepBarriers.cend(), []( <span class="keyword">const</span> Barrier* b ) &#123; <span class="keyword">return</span> b-&gt;isBlocked(); &#125; ) )</div><div class="line">&#123;</div><div class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
<li><p>INTRA的依赖<br> 数组thisLine和lineAbove分别表示当前ctu task行和上一个ctu task行的子任务状态。下面的代码表示当前ctu task需要等待左边和右上的ctu task执行完成INTRA子任务才能开始执行(好像漏了正上方ctu task的判断？后续需要进一步确认)。</p>
   <figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span>( col &gt; <span class="number">0</span> &amp;&amp; thisLine[col - <span class="number">1</span>] &lt;= INTRA )</div><div class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line"><span class="keyword">if</span>( line &gt; <span class="number">0</span> &amp;&amp; lineAbove[<span class="built_in">std</span>::min( col + <span class="number">1</span>, widthInCtus - <span class="number">1</span> )] &lt;= INTRA )</div><div class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</div></pre></td></tr></table></figure>
</li>
<li><p>LF_V的依赖<br>垂直滤波需要等待左边ctu task完成了INTRA才能开始。</p>
 <figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span>( col &gt; <span class="number">0</span> &amp;&amp; thisLine[col - <span class="number">1</span>] &lt; LF_V )</div><div class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</div></pre></td></tr></table></figure>
</li>
<li><p>LF_H的依赖<br>水平滤波需要等待右边，上边和右上的ctu task完成了垂直滤波才能开始。</p>
 <figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span>( line &gt; <span class="number">0</span> &amp;&amp; lineAbove[col] &lt; LF_H )</div><div class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line"><span class="keyword">if</span>( line &gt; <span class="number">0</span> &amp;&amp; col + <span class="number">1</span> &lt; widthInCtus &amp;&amp; lineAbove[col + <span class="number">1</span>] &lt; LF_H )</div><div class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line"><span class="keyword">if</span>( col + <span class="number">1</span> &lt; widthInCtus &amp;&amp; thisLine[col + <span class="number">1</span>] &lt; LF_H )</div><div class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="2-3-ThreadPool的设计"><a href="#2-3-ThreadPool的设计" class="headerlink" title="2.3 ThreadPool的设计"></a>2.3 ThreadPool的设计</h2><p><img src="/2021/04/06/VVC Decoder Analysis/threadpool.svg" alt="">  </p>
<p>为了实现CTU task的并行，vvdec中设计了一个ThreadPool来完成线程的调度和执行。这个ThreadPool初始化的时候创建N个执行线程，N通常设置为通过std::thread::hardware_concurrency()得到的CPU核数。为了完成无锁化设计，这个线程池提供了类似Fence的机制Barrier来保证前后task之间的依赖关系。也就是说一个task被push到线程池中来执行的时候，其带有特定的Barrier，这个Barrier就是该task执行之前需要保证的条件。<br>ThreadPool的定义如下所示。<br>下面来简单介绍一下这个类的定义。</p>
<ol>
<li>ChunkedTaskQueue是用来保存task的队列。每个task的定义保存在结构体Slot中。task的func是需要真正执行任务的回调函数。readyCheck是task任务执行之前用来判断是否前置条件是否ready的回调函数。barriers也是task执行之前需要满足的前置条件。也就是说task可以被执行的前置条件是readyCheck回调函数需要返回true，加上barriers不能是block的。<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">using</span> TaskFunc = <span class="keyword">bool</span> ( * )( <span class="keyword">int</span>, <span class="keyword">void</span> * );</div><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Slot</span></span></div><div class="line">&#123;</div><div class="line">  TaskFunc               func      &#123; <span class="literal">nullptr</span> &#125;;</div><div class="line">  TaskFunc               readyCheck&#123; <span class="literal">nullptr</span> &#125;;</div><div class="line">  <span class="keyword">void</span>*                  param     &#123; <span class="literal">nullptr</span> &#125;;</div><div class="line">  WaitCounter*           counter   &#123; <span class="literal">nullptr</span> &#125;;</div><div class="line">  Barrier*               done      &#123; <span class="literal">nullptr</span> &#125;;</div><div class="line">  CBarrierVec            barriers;</div><div class="line">  <span class="built_in">std</span>::atomic&lt;TaskState&gt; state     &#123; FREE &#125;;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
</li>
</ol>
<p>ChunkedTaskQueue的定义如下。<br>先定义了一个包含128的Slot结构体数组的Chunk来保存task。在定义一个指向Chunk的单链表来把更多的task任务链接到一起。<br>   <figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"> <span class="class"><span class="keyword">class</span> <span class="title">ChunkedTaskQueue</span></span></div><div class="line"> &#123;</div><div class="line">  <span class="keyword">constexpr</span> <span class="keyword">static</span> <span class="keyword">int</span> ChunkSize = <span class="number">128</span>;</div><div class="line">  <span class="class"><span class="keyword">class</span> <span class="title">Chunk</span></span></div><div class="line">  &#123;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">array</span>&lt;Slot, ChunkSize&gt; m_slots;</div><div class="line">    <span class="built_in">std</span>::atomic&lt;Chunk*&gt;         m_next&#123; <span class="literal">nullptr</span> &#125;;</div><div class="line">    Chunk&amp;                      m_firstChunk;</div><div class="line">    Chunk( Chunk* firstPtr ) : m_firstChunk&#123; *firstPtr &#125; &#123;&#125;</div><div class="line">    <span class="keyword">friend</span> <span class="class"><span class="keyword">class</span> <span class="title">ChunkedTaskQueue</span>;</span></div><div class="line">  &#125;;</div><div class="line"><span class="keyword">private</span>:</div><div class="line">  Chunk  m_firstChunk&#123; &amp;m_firstChunk &#125;;</div><div class="line">  Chunk* m_lastChunk = &amp;m_firstChunk;</div><div class="line">  <span class="built_in">std</span>::mutex m_resizeMutex;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>完整的ThreadPool接口定义如下。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ThreadPool</span></span></div><div class="line">&#123;</div><div class="line">  <span class="keyword">typedef</span> <span class="keyword">enum</span></div><div class="line">  &#123;</div><div class="line">    FREE = <span class="number">0</span>,</div><div class="line">    PREPARING,</div><div class="line">    WAITING,</div><div class="line">    RUNNING</div><div class="line">  &#125; TaskState;</div><div class="line">  <span class="keyword">using</span> TaskFunc = <span class="keyword">bool</span> ( * )( <span class="keyword">int</span>, <span class="keyword">void</span> * );</div><div class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">Slot</span></span></div><div class="line">  &#123;</div><div class="line">    TaskFunc               func      &#123; <span class="literal">nullptr</span> &#125;;</div><div class="line">    TaskFunc               readyCheck&#123; <span class="literal">nullptr</span> &#125;;</div><div class="line">    <span class="keyword">void</span>*                  param     &#123; <span class="literal">nullptr</span> &#125;;</div><div class="line">    WaitCounter*           counter   &#123; <span class="literal">nullptr</span> &#125;;</div><div class="line">    Barrier*               done      &#123; <span class="literal">nullptr</span> &#125;;</div><div class="line">    CBarrierVec            barriers;</div><div class="line">    <span class="built_in">std</span>::atomic&lt;TaskState&gt; state     &#123; FREE &#125;;</div><div class="line">  &#125;;</div><div class="line">  <span class="class"><span class="keyword">class</span> <span class="title">ChunkedTaskQueue</span></span></div><div class="line">  &#123;</div><div class="line">    <span class="keyword">constexpr</span> <span class="keyword">static</span> <span class="keyword">int</span> ChunkSize = <span class="number">128</span>;</div><div class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Chunk</span></span></div><div class="line">    &#123;</div><div class="line">      <span class="built_in">std</span>::<span class="built_in">array</span>&lt;Slot, ChunkSize&gt; m_slots;</div><div class="line">      <span class="built_in">std</span>::atomic&lt;Chunk*&gt;         m_next&#123; <span class="literal">nullptr</span> &#125;;</div><div class="line">      Chunk&amp;                      m_firstChunk;</div><div class="line">      Chunk( Chunk* firstPtr ) : m_firstChunk&#123; *firstPtr &#125; &#123;&#125;</div><div class="line">      <span class="keyword">friend</span> <span class="class"><span class="keyword">class</span> <span class="title">ChunkedTaskQueue</span>;</span></div><div class="line">    &#125;;</div><div class="line">  <span class="keyword">public</span>:</div><div class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Iterator</span> :</span> <span class="keyword">public</span> <span class="built_in">std</span>::iterator&lt;<span class="built_in">std</span>::forward_iterator_tag, Slot&gt;</div><div class="line">    &#123;</div><div class="line">      Slot*  m_slot  = <span class="literal">nullptr</span>;</div><div class="line">      Chunk* m_chunk = <span class="literal">nullptr</span>;</div><div class="line">    <span class="keyword">public</span>:</div><div class="line">      Iterator() = <span class="keyword">default</span>;</div><div class="line">      Iterator( Slot* slot, Chunk* chunk ) : m_slot( slot ), m_chunk( chunk ) &#123;&#125;</div><div class="line">      Iterator&amp; <span class="keyword">operator</span>++();</div><div class="line">      <span class="comment">// increment iterator and wrap around, if end is reached</span></div><div class="line">      <span class="function">Iterator&amp; <span class="title">incWrap</span><span class="params">()</span></span>;</div><div class="line">      <span class="keyword">bool</span> <span class="keyword">operator</span>==( <span class="keyword">const</span> Iterator&amp; rhs ) <span class="keyword">const</span> &#123; <span class="keyword">return</span> m_slot == rhs.m_slot; &#125; <span class="comment">// don't need to compare m_chunk, because m_slot is a pointer</span></div><div class="line">      <span class="keyword">bool</span> <span class="keyword">operator</span>!=( <span class="keyword">const</span> Iterator&amp; rhs ) <span class="keyword">const</span> &#123; <span class="keyword">return</span> m_slot != rhs.m_slot; &#125; <span class="comment">// don't need to compare m_chunk, because m_slot is a pointer</span></div><div class="line">      Slot&amp; <span class="keyword">operator</span>*() &#123; <span class="keyword">return</span> *m_slot; &#125;</div><div class="line">      <span class="function"><span class="keyword">bool</span> <span class="title">isValid</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> m_slot != <span class="literal">nullptr</span> &amp;&amp; m_chunk != <span class="literal">nullptr</span>; &#125;</div><div class="line">    &#125;;</div><div class="line">    ChunkedTaskQueue() = <span class="keyword">default</span>;</div><div class="line">    ~ChunkedTaskQueue();</div><div class="line">    ChunkedTaskQueue( <span class="keyword">const</span> ChunkedTaskQueue&amp; ) = <span class="keyword">delete</span>;</div><div class="line">    ChunkedTaskQueue( ChunkedTaskQueue&amp;&amp; )      = <span class="keyword">delete</span>;</div><div class="line">    <span class="comment">// grow the queue by adding a chunk and return an iterator to the first new task-slot</span></div><div class="line">    <span class="function">Iterator <span class="title">grow</span><span class="params">()</span></span>;</div><div class="line">    <span class="function">Iterator <span class="title">begin</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> Iterator&#123; &amp;m_firstChunk.m_slots.front(), &amp;m_firstChunk &#125;; &#125;</div><div class="line">    <span class="function">Iterator <span class="title">end</span><span class="params">()</span>   </span>&#123; <span class="keyword">return</span> Iterator&#123; <span class="literal">nullptr</span>, <span class="literal">nullptr</span> &#125;; &#125;</div><div class="line">  <span class="keyword">private</span>:</div><div class="line">    Chunk  m_firstChunk&#123; &amp;m_firstChunk &#125;;</div><div class="line">    Chunk* m_lastChunk = &amp;m_firstChunk;</div><div class="line">    <span class="built_in">std</span>::mutex m_resizeMutex;</div><div class="line">  &#125;;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">  ThreadPool( <span class="keyword">int</span> numThreads = <span class="number">1</span>, <span class="keyword">const</span> <span class="keyword">char</span> *threadPoolName = <span class="literal">nullptr</span> );</div><div class="line">  ~ThreadPool();</div><div class="line">  <span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">TParam</span>&gt;</span></div><div class="line">  <span class="title">bool</span> <span class="title">addBarrierTask</span>( <span class="title">bool</span>       ( *<span class="title">func</span> )( <span class="title">int</span>, <span class="title">TParam</span>* ),</div><div class="line">                       <span class="title">TParam</span>*       <span class="title">param</span>,</div><div class="line">                       <span class="title">WaitCounter</span>*  <span class="title">counter</span>                      = <span class="title">nullptr</span>,</div><div class="line">                       <span class="title">Barrier</span>*      <span class="title">done</span>                         = <span class="title">nullptr</span>,</div><div class="line">                       <span class="title">CBarrierVec</span>&amp;&amp; <span class="title">barriers</span>                     = &#123;&#125;,</div><div class="line">                       <span class="keyword">bool</span>       ( *readyCheck )( <span class="keyword">int</span>, TParam* ) = <span class="literal">nullptr</span> )</div><div class="line">  &#123;</div><div class="line">    <span class="keyword">if</span>( m_threads.empty() )</div><div class="line">    &#123;</div><div class="line">      <span class="comment">// in the single threaded case try to exectute the task directly</span></div><div class="line">      <span class="keyword">if</span>( bypassTaskQueue( (TaskFunc)func, param, counter, done, barriers, (TaskFunc)readyCheck ) )</div><div class="line">      &#123;</div><div class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">else</span></div><div class="line">    &#123;</div><div class="line">      checkAndThrowThreadPoolException();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">while</span>( <span class="literal">true</span> )</div><div class="line">    &#123;</div><div class="line"><span class="meta">#<span class="meta-keyword">if</span> ADD_TASK_THREAD_SAFE</span></div><div class="line">      <span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; l(m_nextFillSlotMutex);</div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></div><div class="line">      CHECKD( !m_nextFillSlot.isValid(), <span class="string">"Next fill slot iterator should always be valid"</span> );</div><div class="line">      <span class="keyword">const</span> <span class="keyword">auto</span> startIt = m_nextFillSlot;</div><div class="line"><span class="meta">#<span class="meta-keyword">if</span> ADD_TASK_THREAD_SAFE</span></div><div class="line">      l.unlock();</div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></div><div class="line">      <span class="keyword">bool</span> first = <span class="literal">true</span>;</div><div class="line">      <span class="keyword">for</span>( <span class="keyword">auto</span> it = startIt; it != startIt || first; it.incWrap() )</div><div class="line">      &#123;</div><div class="line">        first = <span class="literal">false</span>;</div><div class="line">        <span class="keyword">auto</span>&amp; t = *it;</div><div class="line">        <span class="keyword">auto</span> expected = FREE;</div><div class="line">        <span class="keyword">if</span>( t.state.load( <span class="built_in">std</span>::memory_order_relaxed ) == FREE &amp;&amp; t.state.compare_exchange_strong( expected, PREPARING ) )</div><div class="line">        &#123;</div><div class="line">          <span class="keyword">if</span>( counter )</div><div class="line">          &#123;</div><div class="line">            counter-&gt;<span class="keyword">operator</span>++();</div><div class="line">          &#125;</div><div class="line">          t.func       = (TaskFunc)func;</div><div class="line">          t.readyCheck = (TaskFunc)readyCheck;</div><div class="line">          t.param      = param;</div><div class="line">          t.done       = done;</div><div class="line">          t.counter    = counter;</div><div class="line">          t.barriers   = <span class="built_in">std</span>::move( barriers );</div><div class="line">          t.state      = WAITING;</div><div class="line"><span class="meta">#<span class="meta-keyword">if</span> ADD_TASK_THREAD_SAFE</span></div><div class="line">          l.lock();</div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></div><div class="line">          m_nextFillSlot.incWrap();</div><div class="line">          m_poolPause.unpauseIfPaused();</div><div class="line">          <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line"><span class="meta">#<span class="meta-keyword">if</span> ADD_TASK_THREAD_SAFE</span></div><div class="line">      l.lock();</div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></div><div class="line">      m_nextFillSlot = m_tasks.grow();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">  &#125;</div><div class="line">  <span class="function"><span class="keyword">bool</span> <span class="title">processTasksOnMainThread</span><span class="params">()</span></span>;</div><div class="line">  <span class="function"><span class="keyword">void</span> <span class="title">checkAndThrowThreadPoolException</span><span class="params">()</span></span>;</div><div class="line">  <span class="function"><span class="keyword">void</span> <span class="title">shutdown</span><span class="params">( <span class="keyword">bool</span> block )</span></span>;</div><div class="line">  <span class="function"><span class="keyword">void</span> <span class="title">waitForThreads</span><span class="params">()</span></span>;</div><div class="line">  <span class="function"><span class="keyword">int</span> <span class="title">numThreads</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> (<span class="keyword">int</span>)m_threads.size(); &#125;</div><div class="line"><span class="keyword">private</span>:</div><div class="line">  <span class="keyword">using</span> TaskIterator = ChunkedTaskQueue::Iterator;</div><div class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">TaskException</span>;</span></div><div class="line">  <span class="comment">// members</span></div><div class="line">  <span class="built_in">std</span>::<span class="built_in">string</span>              m_poolName;</div><div class="line">  <span class="built_in">std</span>::<span class="keyword">atomic_bool</span>         m_exitThreads&#123; <span class="literal">false</span> &#125;;</div><div class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::thread&gt; m_threads;</div><div class="line">  ChunkedTaskQueue         m_tasks;</div><div class="line">  TaskIterator             m_nextFillSlot = m_tasks.begin();</div><div class="line"><span class="meta">#<span class="meta-keyword">if</span> ADD_TASK_THREAD_SAFE</span></div><div class="line">  <span class="built_in">std</span>::mutex               m_nextFillSlotMutex;</div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></div><div class="line">  <span class="built_in">std</span>::mutex               m_idleMutex;</div><div class="line">  <span class="built_in">std</span>::<span class="keyword">atomic_bool</span>         m_exceptionFlag&#123; <span class="literal">false</span> &#125;;</div><div class="line">  <span class="built_in">std</span>::exception_ptr       m_threadPoolException;</div><div class="line">  PoolPause m_poolPause;</div><div class="line">  <span class="comment">// internal functions</span></div><div class="line">  <span class="function"><span class="keyword">void</span>         <span class="title">threadProc</span>     <span class="params">( <span class="keyword">int</span> threadId )</span></span>;</div><div class="line">  <span class="function"><span class="keyword">static</span> <span class="keyword">bool</span>  <span class="title">checkTaskReady</span> <span class="params">( <span class="keyword">int</span> threadId, CBarrierVec&amp; barriers, TaskFunc readyCheck, <span class="keyword">void</span>* taskParam )</span></span>;</div><div class="line">  <span class="function">TaskIterator <span class="title">findNextTask</span>   <span class="params">( <span class="keyword">int</span> threadId, TaskIterator startSearch )</span></span>;</div><div class="line">  <span class="function"><span class="keyword">static</span> <span class="keyword">bool</span>  <span class="title">processTask</span>    <span class="params">( <span class="keyword">int</span> threadId, Slot&amp; task )</span></span>;</div><div class="line">  <span class="function"><span class="keyword">bool</span>         <span class="title">bypassTaskQueue</span><span class="params">( TaskFunc func, <span class="keyword">void</span>* param, WaitCounter* counter, Barrier* done, CBarrierVec&amp; barriers, TaskFunc readyCheck )</span></span>;</div><div class="line">  <span class="function"><span class="keyword">static</span> <span class="keyword">void</span>  <span class="title">handleTaskException</span><span class="params">( <span class="keyword">const</span> <span class="built_in">std</span>::exception_ptr e, Barrier* done, WaitCounter* counter, <span class="built_in">std</span>::atomic&lt;TaskState&gt;* slot_state )</span></span>;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>其中的核心函数定义如下。<br>addBarrierTask()提供接口把外部任务push到ThreadPool中来异步执行。</p>
<p>threadProc()是每个线程的loop执行函数，每个线程创建好了以后，threadProc就会在一个while循环中不停地从queue中取出task(如果有的话)来执行。如果queue里面没有task需要执行了，threadProc会进入等待状态。</p>
<p>findNextTask()用于从queue找到一个可以被执行的task。其会调用checkTaskReady()函数用来确保task可以被执行。</p>
<p>checkTaskReady()函数用于检查Barrier和readCheck是否已经准备好。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">bool</span> ThreadPool::checkTaskReady( <span class="keyword">int</span> threadId, CBarrierVec&amp; barriers, ThreadPool::TaskFunc readyCheck, <span class="keyword">void</span>* taskParam )</div><div class="line">&#123;</div><div class="line">    <span class="keyword">if</span>( !barriers.empty() )</div><div class="line">    &#123;</div><div class="line">        <span class="comment">// don't break early, because isBlocked() also checks exception state</span></div><div class="line">        <span class="keyword">if</span>( <span class="built_in">std</span>::count_if( barriers.cbegin(), barriers.cend(), []( <span class="keyword">const</span> Barrier* b ) &#123; <span class="keyword">return</span> b &amp;&amp; b-&gt;isBlocked(); &#125; ) )</div><div class="line">        &#123;</div><div class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// don't clear the barriers, even if they are all unlocked, because exceptions could still be singalled through them</span></div><div class="line">    <span class="comment">// barriers.clear();</span></div><div class="line">    <span class="keyword">if</span>( readyCheck &amp;&amp; readyCheck( threadId, taskParam ) == <span class="literal">false</span> )</div><div class="line">    &#123;</div><div class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>processTask()用来调用task的执行回调函数执行真正的任务。如果任务没有执行完成(返回false)，则该task会重新送入queue中等待下一步再被调用到来执行回调函数。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">bool</span> ThreadPool::processTask( <span class="keyword">int</span> threadId, ThreadPool::Slot&amp; task )</div><div class="line">&#123;</div><div class="line">    <span class="keyword">try</span></div><div class="line">    &#123;</div><div class="line">        <span class="keyword">const</span> <span class="keyword">bool</span> success = task.func( threadId, task.param );</div><div class="line">        <span class="keyword">if</span>( !success )</div><div class="line">        &#123;</div><div class="line">            task.state = WAITING;</div><div class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">if</span>( task.done != <span class="literal">nullptr</span> )</div><div class="line">        &#123;</div><div class="line">            task.done-&gt;unlock();</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">if</span>( task.counter != <span class="literal">nullptr</span> )</div><div class="line">        &#123;</div><div class="line">            --(*task.counter);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">catch</span>( ... )</div><div class="line">    &#123;</div><div class="line">        <span class="keyword">throw</span> TaskException( <span class="built_in">std</span>::current_exception(), task );</div><div class="line">    &#125;</div><div class="line">    task.state = FREE;</div><div class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>下面这个图详细说明了ctu解码过程中是如何利用thread pool进行task的调度的。<br>DecLibRecon把ctu task push到threadpool中的queue中，这些task都带有前置条件。<br>threadpool中的线程启动loop函数threadProc, threadProc会去queue中取task。如果取得的task的前置条件都满足，则该thread可以去执行对应的task。在执行的过程中某一个子任务完成后会去更新task type。并判断下一步的子任务是否可以启动，如果不行的话该线程退出执行任务，并把任务重新push到queue中，如果可以下一步的子任务可以启动则继续往下执行直至该任务完全结束。</p>
<p><img src="/2021/04/06/VVC Decoder Analysis/thread flow.svg" alt=""> </p>
<h1 id="3-参考"><a href="#3-参考" class="headerlink" title="3 参考"></a>3 参考</h1><p><a href="https://jvet-experts.org/doc_end_user/documents/20_Teleconference/wg11/JVET-T2001-v2.zip" target="_blank" rel="external">JVET-V0021-v1, Deployment status of the VVC standard</a><br><a href="https://github.com/fraunhoferhhi/vvdec" target="_blank" rel="external">vvdec</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/03/27/Apple M1 GPU Analysis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/03/27/Apple M1 GPU Analysis/" itemprop="url">Apple M1 GPU分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-03-27T18:20:31+09:00">
                2021-03-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2021/03/27/Apple M1 GPU Analysis/" class="leancloud_visitors" data-flag-title="Apple M1 GPU分析">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="0x1-介绍"><a href="#0x1-介绍" class="headerlink" title="0x1 介绍"></a>0x1 介绍</h1><p>随着Apple M1 Soc的问世，大家对其集成的GPU也是充满了好奇，根据专业软件的评测，该GPU的性能也是相当强悍。<br>但是秉承Apple封闭的特性，人们很难直接对其有更深入的了解。但是这个阻挡不了hacker借助各种手段来对其进行逆向分析。<br>本文就是对目前Apple M1 GPU的逆向分析进展的一个总结。</p>
<p>我们知道Mesa是Linux上开源的图形驱动，支持了Intel，AMD，Broadcom VideoCore，Qualcomm Adreno, ARM Mali, Vivante等厂家的GPU驱动，对了，好像被你看出来了少了谁，这就是Imagination GPU，是的Imagination内部支持Mesa的工程师跳槽到Intel以后，mesa中Imagination GPU的支持就一直没有进展。</p>
<p>Mesa开发模式简单说来有两种，一种是企业支持的开发，如Intel Open source center是Mesa最大的贡献者，开发了Mesa框架，编译器，Intel Gen GPU驱动等。Broadcom也支持了内部工程师来开发Mesa中有关VideoCore GPU的驱动。采用这种模式开发的话可以访问该公司内部完整的技术文档，包括GPU spec，GPU ISA document等。这种开发模式基本是follow对应closed source的GPU驱动流程，根据内部的GPU参考代码，在Mesa中做移植，没有涉及到逆向工程的概念。</p>
<p>另外一种是独立开发模式，这种主要通过逆向工程来分析GPU的特征。这种模式开发的驱动，一看这个取名就很有意思，freedreno，etnaviv，lima，一看就是野路子，就是把人家的名字反过来叫。采用这种模式开发的GPU驱动是在没有参考代码对GPU的特性做逆向分析，然后归纳总结出QPU驱动的流程来，需要完成GPU ISA的总结，开发GPU ISA编译器后端，开发GPU command stream的构造器。使其可以对接到kernel驱动中。采用这种模式开发可以参考的是GPU kernel driver的代码，因为Linux kernel driver代码一般是GPL协议的，可以在网上找到对应的源代码。下面要说的Apple M1 GPU就是通过这种方式开发的。通过了解这个过程，我们可以知道怎样通过逆向分析来完成一个GPU用户态驱动的开发。</p>
<p>这个逆向分析过程由Alyssa Rosenzweig提供，Alyssa Rosenzweig因为负责Mesa中Mali GPU(Panfrost)驱动的逆向开发工作而获得了2021年度的杰出自由软件贡献者奖。</p>
<p>其开发过程如下。</p>
<p>   <img src="/2021/03/27/Apple M1 GPU Analysis/gpu driver reverse engineering.png" alt=""></p>
<p>开发Linux or Android逆向GPU驱动的过程如下。<br>写一个hook库，该hook库用来hook ioctl和mmap接口，然后通过LD_PRELOAD加载进测试程序中，然后在hook的ioctl和mmap函数中分析GPU用户态发送到<br>内核态的内容，一旦“submit command buffer”被触发，就把内存中的内容dump到文件中，可以用来做进一步分析。</p>
<p>Apple系统上逆向过程如下。<br>M1 GPU的逆向分析过程也和上面的过程类似，只是macOS上没有LD_PRELOAD，只有类似的机制DYLD_INSERT_LIBRARIES，另外ioctl也是没有的，需要用<br>macOS上的IOKit framework来代替。IOKit framework是macOS上GPU用户态驱动到内核态驱动的桥梁，其中和ioctl类似的入口函数是IOConnectCallMethod。</p>
<p>下面来详细介绍一下这个逆向过程</p>
<ol>
<li><p>提供对IOKit中函数IOConnectCallMethod的包装，也就是说对IOKit进行了hook。</p>
</li>
<li><p>重点关注下面三处调用。memory allocation, command buffer creation, and command buffer submission</p>
</li>
<li><p>把上面的hook接好了以后，就可以利用上面的hook机制来分析驱动了。下面说了这个标准过程，就是利用一个简单的Metal测试程序，<br>然后在hook中dump驱动的二进制输出，然后对Metal测试程序做一个小修改，然后dump驱动的二进制输出，并和修改前的dump输出进行比较，从而推断出某一个二进制GPU指令对应的含义。</p>
</li>
<li><p>通过上面的分析，可以得出M1 GPU的大概特性。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">One, the architecture is scalar. Unlike some GPUs that are scalar for 32-bits but vectorized for 16-bits, </div><div class="line">     the M1’s GPU is scalar at all bit sizes. Yet Metal optimization resources imply 16-bit arithmetic </div><div class="line">     should be significantly faster, in addition to a reduction of register usage leading to higher thread </div><div class="line">     count (occupancy). This suggests the hardware is superscalar, with more 16-bit ALUs than 32-bit ALUs, </div><div class="line">     allowing the part to benefit from low-precision graphics shaders much more than competing chips can, </div><div class="line">     while removing a great deal of complexity from the compiler.</div><div class="line"></div><div class="line">Two, the architecture seems to handle scheduling in hardware, common among desktop GPUs but less so in the embedded space. </div><div class="line">     This again makes the compiler simpler at the expense of more hardware. Instructions seem to have minimal encoding </div><div class="line">     overhead, unlike other architectures which need to pad out instructions with nop’s to accommodate highly constrained</div><div class="line">     instruction sets.</div><div class="line"></div><div class="line">Three, various modifiers are supported. Floating-point ALUs can do clamps (saturate), negates, and absolute value </div><div class="line">       modifiers “for free”, a common shader architecture trait. Further, most (all?) instructions can type-convert</div><div class="line">       between 16-bit and 32-bit “for free” on both the destination and the sources, which allows the compiler</div><div class="line">       to be much more aggressive about using 16-bit operations without risking conversion overheads. </div><div class="line">       On the integer side, various bitwise complements and shifts are allowed on certain instructions for free. </div><div class="line">       None of this is unique to Apple’s design, but it’s worth noting all the same.</div><div class="line"></div><div class="line">Finally, not all ALU instructions have the same timing. Instructions like imad, used to multiply two integers and</div><div class="line">         add a third, are avoided in favour of repeated iadd integer addition instructions where possible. </div><div class="line">         This also suggests a superscalar architecture; software-scheduled designs like those I work on for my day</div><div class="line">         job cannot exploit differences in pipeline length, inadvertently slowing down simple instructions to match</div><div class="line">         the speed of complex ones.</div></pre></td></tr></table></figure>
</li>
<li><p>分析command stream的构建过程，完成以后，我们可以编写一个简单的测试程序跑起来。</p>
</li>
</ol>
<h1 id="0x2-GPU驱动分析"><a href="#0x2-GPU驱动分析" class="headerlink" title="0x2 GPU驱动分析"></a>0x2 GPU驱动分析</h1><p>下面来介绍一下这个通过逆向分析得到的GPU驱动。</p>
<h2 id="0x21-wrap"><a href="#0x21-wrap" class="headerlink" title="0x21 wrap"></a>0x21 wrap</h2><p>   <img src="/2021/03/27/Apple M1 GPU Analysis/wrap.png" alt=""></p>
<p>wrap模块定义了下面hook导出函数供应用程序调用，用来接管IOKit中对应的函数。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">DYLD_INTERPOSE(wrap_IOConnectCallMethod, IOConnectCallMethod);</div><div class="line">DYLD_INTERPOSE(wrap_IOConnectCallAsyncMethod, IOConnectCallAsyncMethod);</div><div class="line">DYLD_INTERPOSE(wrap_IOConnectCallStructMethod, IOConnectCallStructMethod);</div><div class="line">DYLD_INTERPOSE(wrap_IOConnectCallAsyncStructMethod, IOConnectCallAsyncStructMethod);</div><div class="line">DYLD_INTERPOSE(wrap_IOConnectCallScalarMethod, IOConnectCallScalarMethod);</div><div class="line">DYLD_INTERPOSE(wrap_IOConnectCallAsyncScalarMethod, IOConnectCallAsyncScalarMethod);</div><div class="line">DYLD_INTERPOSE(wrap_IOConnectSetNotificationPort, IOConnectSetNotificationPort);</div><div class="line"><span class="comment">//DYLD_INTERPOSE(wrap_IOSetNotificationPort, IOSetNotificationPort);</span></div><div class="line">DYLD_INTERPOSE(wrap_IONotificationPortCreate, IONotificationPortCreate);</div><div class="line">DYLD_INTERPOSE(wrap_IONotificationPortSetDispatchQueue, IONotificationPortSetDispatchQueue);</div><div class="line">DYLD_INTERPOSE(wrap_IODataQueueAllocateNotificationPort, IODataQueueAllocateNotificationPort);</div><div class="line">DYLD_INTERPOSE(wrap_IODataQueueSetNotificationPort, IODataQueueSetNotificationPort);</div></pre></td></tr></table></figure>
<p>然后在图形测试程序运行的时候，会先调用到wrap实现的hook函数中，然后在hook中内存分配(AGX_SELECTOR_ALLOCATE_MEM)和cmd buffer创建(AGX_SELECTOR_CREATE_CMDBUF)被调用的时候记录相应的buffer内存地址，在command命令提交的时候(AGX_SELECTOR_SUBMIT_COMMAND_BUFFERS)把前面保存的buffer保存到文件中。hook函数在完成前述的hook任务以后，再调用真正的IOKit函数，完成对MacOS系统GPU kernel驱动的调用。</p>
<h2 id="0x22-disasm"><a href="#0x22-disasm" class="headerlink" title="0x22 disasm"></a>0x22 disasm</h2><p>前面已经把所有包含GPU渲染命令的buffer都保存到文件了，下一步就是要分析这些文件了，这个时候需要disasm发挥作用了。<br>我们知道M1 GPU是没有公开的文档，开发disasm也是需要反复修改测试程序，然后通过wrap收集到修改后测试程序的命令。通过仔细比较差异来推测这些buffer里面对应的二进制的含义。目前disasm只是对部分GPU ISA进行了解析，对command stream部分的解析没有完成。<br>目前已经分析出来的部分GPU ISA的opcode如下所示。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">enum</span> agx_opcodes &#123;</div><div class="line">    OPC_FFMA_CMPCT_16 = <span class="number">0x36</span>,</div><div class="line">    OPC_FFMA_CMPCT_SAT_16 = <span class="number">0x76</span>,</div><div class="line">    OPC_FMUL_16 = <span class="number">0x96</span>,</div><div class="line">    OPC_FADD_16 = <span class="number">0xA6</span>,</div><div class="line">    OPC_FFMA_16 = <span class="number">0xB6</span>,</div><div class="line">    OPC_FMUL_SAT_16 = <span class="number">0xD6</span>,</div><div class="line">    OPC_FADD_SAT_16 = <span class="number">0xE6</span>,</div><div class="line">    OPC_FFMA_SAT_16 = <span class="number">0xF6</span>,</div><div class="line"></div><div class="line">    OPC_FROUND_32 = <span class="number">0x0A</span>,</div><div class="line">    OPC_FFMA_CMPCT_32 = <span class="number">0x3A</span>,</div><div class="line">    OPC_FFMA_CMPCT_SAT_32 = <span class="number">0x7A</span>,</div><div class="line">    OPC_FMUL_32 = <span class="number">0x9A</span>,</div><div class="line">    OPC_FADD_32 = <span class="number">0xAA</span>,</div><div class="line">    OPC_FFMA_32 = <span class="number">0xBA</span>,</div><div class="line">    OPC_FMUL_SAT_32 = <span class="number">0xDA</span>,</div><div class="line">    OPC_FADD_SAT_32 = <span class="number">0xEA</span>,</div><div class="line">    OPC_FFMA_SAT_32 = <span class="number">0xFA</span>,</div><div class="line"></div><div class="line">    OPC_IADD = <span class="number">0x0E</span>,</div><div class="line">    OPC_IMAD = <span class="number">0x1E</span>,</div><div class="line">    OPC_ISHL = <span class="number">0x2E</span>,</div><div class="line">    <span class="comment">/* 0x3e seen with reverse_bits, and used in clz */</span></div><div class="line">    OPC_IADDSAT = <span class="number">0x4E</span>,</div><div class="line">    OPC_ISHR = <span class="number">0xAE</span>,</div><div class="line">    OPC_I2F = <span class="number">0xBE</span>,</div><div class="line"></div><div class="line">    OPC_LOAD = <span class="number">0x05</span>, <span class="comment">// todo</span></div><div class="line">    OPC_STORE = <span class="number">0x45</span>, <span class="comment">// todo</span></div><div class="line">    OPC_FCSEL = <span class="number">0x02</span>,</div><div class="line">    OPC_ICSEL = <span class="number">0x12</span>,</div><div class="line">    OPC_MOVI = <span class="number">0x62</span>,</div><div class="line">    OPC_LD_COMPUTE = <span class="number">0x72</span>,</div><div class="line">    OPC_BITOP = <span class="number">0x7E</span>,</div><div class="line">    OPC_UNK38 = <span class="number">0x38</span>, <span class="comment">// seen after loads?</span></div><div class="line">    OPC_STOP = <span class="number">0x08</span>,</div><div class="line"></div><div class="line">    OPC_LD_VAR_NO_PERSPECTIVE = <span class="number">0xA1</span>,</div><div class="line">    OPC_LD_VAR = <span class="number">0xE1</span>, <span class="comment">// perspective</span></div><div class="line">    OPC_ST_VAR = <span class="number">0x11</span>,</div><div class="line">    OPC_UNKB1 = <span class="number">0xB1</span>, <span class="comment">// seen in aux frag shader</span></div><div class="line">    OPC_UNK48 = <span class="number">0x48</span>, <span class="comment">// seen before blending</span></div><div class="line">    OPC_BLEND = <span class="number">0x09</span>,</div><div class="line"></div><div class="line">    <span class="comment">// branching instructions, not understood</span></div><div class="line">    OPC_UNKD2 = <span class="number">0xD2</span>,</div><div class="line">    OPC_UNK42 = <span class="number">0x42</span>,</div><div class="line">    OPC_UNK52 = <span class="number">0x52</span>,</div><div class="line"></div><div class="line">    <span class="comment">// not sure what this does, but appears to be 4 bytes</span></div><div class="line">    OPC_UNK80 = <span class="number">0x80</span>,</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h2 id="0x23-demo"><a href="#0x23-demo" class="headerlink" title="0x23 demo"></a>0x23 demo</h2><p>demo是hack一个简单的测试程序，来驱动M1 GPU kernel driver完成绘制工作。我们前面的wrap有点类似record的意思，这个demo是把record的东西playback出来，playback的输入有些是直接从record的buffer中得到的，有些是通过分析已经大概知道了命令的格式，可以自由地配置出来。</p>
<p>demo启动后首先要通过open类似的接口IOServiceOpen()打开GPU kernel驱动，然后就可以往kernel driver发送内容了。<br>发送渲染内容到kernel driver的完整代码如下。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">demo</span><span class="params">(<span class="keyword">mach_port_t</span> connection, <span class="keyword">bool</span> offscreen)</span></span></div><div class="line">&#123;</div><div class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">agx_command_queue</span> <span class="title">command_queue</span> = <span class="title">agx_create_command_queue</span>(<span class="title">connection</span>);</span></div><div class="line"></div><div class="line">    <span class="comment">// <span class="doctag">XXX:</span> why do BO ids below 6 mess things up..?</span></div><div class="line">    <span class="keyword">for</span> (<span class="keyword">unsigned</span> i = <span class="number">0</span>; i &lt; <span class="number">6</span>; ++i) &#123;</div><div class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">agx_allocation</span> <span class="title">dummy</span> = <span class="title">agx_alloc_mem</span>(<span class="title">connection</span>, 4096, <span class="title">AGX_MEMORY_TYPE_FRAMEBUFFER</span>, <span class="title">false</span>);</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">agx_allocation</span> <span class="title">shader</span> = <span class="title">agx_alloc_mem</span>(<span class="title">connection</span>, 0<span class="title">x10000</span>, <span class="title">AGX_MEMORY_TYPE_SHADER</span>, <span class="title">false</span>);</span></div><div class="line"></div><div class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">agx_allocator</span> <span class="title">shader_pool</span> = &#123;</span> .backing = shader, &#125;;</div><div class="line"></div><div class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">agx_allocation</span> <span class="title">bo</span> = <span class="title">agx_alloc_mem</span>(<span class="title">connection</span>, 1920*1080*4*2, <span class="title">AGX_MEMORY_TYPE_FRAMEBUFFER</span>, <span class="title">false</span>);</span></div><div class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">agx_allocator</span> <span class="title">allocator</span> = &#123;</span> .backing = bo &#125;;</div><div class="line"></div><div class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">agx_allocation</span> <span class="title">vsbuf</span> = <span class="title">agx_alloc_mem</span>(<span class="title">connection</span>, 0<span class="title">x8000</span>, <span class="title">AGX_MEMORY_TYPE_CMDBUF_32</span>, <span class="title">false</span>);</span></div><div class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">agx_allocation</span> <span class="title">fsbuf</span> = <span class="title">agx_alloc_mem</span>(<span class="title">connection</span>, 0<span class="title">x8000</span>, <span class="title">AGX_MEMORY_TYPE_CMDBUF_32</span>, <span class="title">false</span>);</span></div><div class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">agx_allocation</span> <span class="title">framebuffer</span> = <span class="title">agx_alloc_mem</span>(<span class="title">connection</span>, 1024 * 1024 * 4, <span class="title">AGX_MEMORY_TYPE_FRAMEBUFFER</span>, <span class="title">false</span>);</span></div><div class="line"></div><div class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">agx_allocation</span> <span class="title">cmdbuf</span> = <span class="title">agx_alloc_cmdbuf</span>(<span class="title">connection</span>, 0<span class="title">x4000</span>, <span class="title">true</span>);</span></div><div class="line"></div><div class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">agx_allocation</span> <span class="title">memmap</span> = <span class="title">agx_alloc_cmdbuf</span>(<span class="title">connection</span>, 0<span class="title">x4000</span>, <span class="title">false</span>);</span></div><div class="line"></div><div class="line">    <span class="keyword">uint32_t</span> unk6 = agx_cmdbuf_unk6(connection);</div><div class="line"></div><div class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">agx_allocation</span> <span class="title">allocs</span>[] = &#123;</span></div><div class="line">        shader,</div><div class="line">        bo,</div><div class="line">        vsbuf,</div><div class="line">        fsbuf,</div><div class="line">        framebuffer</div><div class="line">    &#125;;</div><div class="line"></div><div class="line">    demo_mem_map(memmap.<span class="built_in">map</span>, allocs, <span class="keyword">sizeof</span>(allocs) / <span class="keyword">sizeof</span>(allocs[<span class="number">0</span>]), unk6 + <span class="number">1</span>);</div><div class="line"></div><div class="line">    <span class="keyword">uint32_t</span> *linear = <span class="built_in">malloc</span>(<span class="number">800</span> * <span class="number">600</span> * <span class="number">4</span>);</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (!offscreen)</div><div class="line">        slowfb_init((<span class="keyword">uint8_t</span> *) linear, <span class="number">800</span>, <span class="number">600</span>);</div><div class="line"></div><div class="line">    <span class="keyword">for</span> (;;) &#123;</div><div class="line">        demo_cmdbuf(cmdbuf.<span class="built_in">map</span>, &amp;allocator, &amp;vsbuf, &amp;fsbuf, &amp;framebuffer, &amp;shader_pool);</div><div class="line">        agx_submit_cmdbuf(connection, &amp;cmdbuf, &amp;memmap, command_queue.id);</div><div class="line"></div><div class="line">        <span class="comment">/* Block until it's done */</span></div><div class="line">        IOReturn ret = IODataQueueWaitForAvailableData(command_queue.notif.<span class="built_in">queue</span>, command_queue.notif.port);</div><div class="line">        <span class="keyword">while</span> (IODataQueueDataAvailable(command_queue.notif.<span class="built_in">queue</span>))</div><div class="line">            ret = IODataQueueDequeue(command_queue.notif.<span class="built_in">queue</span>, <span class="literal">NULL</span>, <span class="number">0</span>);</div><div class="line"></div><div class="line">        <span class="comment">/* Dump the framebuffer */</span></div><div class="line">        ash_detile(framebuffer.<span class="built_in">map</span>, linear,</div><div class="line">                <span class="number">800</span>, <span class="number">32</span>, <span class="number">800</span>,</div><div class="line">                <span class="number">0</span>, <span class="number">0</span>, <span class="number">800</span>, <span class="number">600</span>);</div><div class="line"></div><div class="line">        shader_pool.offset = <span class="number">0</span>;</div><div class="line">        allocator.offset = <span class="number">0</span>;</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (offscreen) &#123;</div><div class="line">            FILE *fp = fopen(<span class="string">"fb.bin"</span>, <span class="string">"wb"</span>);</div><div class="line">            fwrite(linear, <span class="number">1</span>, <span class="number">800</span> * <span class="number">600</span> * <span class="number">4</span>, fp);</div><div class="line">            fclose(fp);</div><div class="line"></div><div class="line">            <span class="keyword">break</span>;</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            slowfb_update(<span class="number">800</span>, <span class="number">600</span>);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>上述过程简单说明如下。</p>
<p>a. 通过AGX_SELECTOR_CREATE_COMMAND_QUEUE创建command queue。<br>b. 通过AGX_SELECTOR_ALLOCATE_MEM分配buffer，包括AGX_MEMORY_TYPE_FRAMEBUFFER，AGX_MEMORY_TYPE_SHADER，AGX_MEMORY_TYPE_CMDBUF_32等类型的buffer。<br>c. 通过AGX_SELECTOR_CREATE_CMDBUF分配cmd buffer。<br>d. 下面开始往前面分配的buffer中填充具体的渲染数据了。这些渲染数据有的是前面通过wrap方式保存下来的，有的是分析后知道格式后自己配置的。这些渲染数据包括shader数据，其中包括了GPU指令，另外就是command stream控制命令。<br>e. 数据都准备好了，下面就是可以调用AGX_SELECTOR_SUBMIT_COMMAND_BUFFERS提交到GPU执行了。<br>f. 等等GPU执行完成以后，就可以把framebuffer中的内容读取出来了，直接读取framebuffer.map地址所对应的内容即可，需要注意的是framebuffer里面的内容是tile格式的，需要完成到raster格式的转换才能正确地显示出来。</p>
<h1 id="0x3-总结"><a href="#0x3-总结" class="headerlink" title="0x3  总结"></a>0x3  总结</h1><p>目前的驱动基本上是record + playback + kernel的模式，对Shader source code -&gt; GPU ISA的生成和Command Stream的动态配置没有涉及到。其实是为后续通过逆向分析来开发GPU ISA和Command Stream的动态生成提供了框架。后续的开发工作可以在这个框架的基础上继续开发。</p>
<h1 id="0x4-参考"><a href="#0x4-参考" class="headerlink" title="0x4 参考"></a>0x4 参考</h1><p><a href="https://rosenzweig.io/blog/asahi-gpu-part-1.html" target="_blank" rel="external">asahi-gpu-part-1</a><br><a href="https://rosenzweig.io/blog/asahi-gpu-part-2.html" target="_blank" rel="external">asahi-gpu-part-2</a><br><a href="https://www.fsf.org/news/free-software-awards-winners-announced-civicrm-bradley-kuhn-and-alyssa-rosenzweig" target="_blank" rel="external">free-software-awards-winners</a><br><a href="https://github.com/AsahiLinux/gpu" target="_blank" rel="external">AsahiLinux GPU</a><br><a href="https://dougallj.github.io/applegpu/docs.html" target="_blank" rel="external">Apple GPU M1 ISA</a><br><a href="https://developer.apple.com/library/archive/documentation/DeviceDrivers/Conceptual/AccessingHardware/AH_IOKitLib_API/AH_IOKitLib_API.html" target="_blank" rel="external">IOKit参考</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/10/07/Neural network coding tool in VVC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/10/07/Neural network coding tool in VVC/" itemprop="url">Neural network coding tool in VVC</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-10-07T18:20:10+09:00">
                2020-10-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2020/10/07/Neural network coding tool in VVC/" class="leancloud_visitors" data-flag-title="Neural network coding tool in VVC">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="0x1-VVC"><a href="#0x1-VVC" class="headerlink" title="0x1 VVC"></a>0x1 VVC</h1><p>VVC是Versatile Video Coding的简写，也称为H.266，是下一代视频压缩标准，VVC已经于今年7月份完成标准的制定。VVC虽然没有突破传统的block based hybird的视频编码架构，但是借助于各种coding tools优化效果的累积效果，其编码效率比上一代视频压缩标准HEVC提升50%左右，也就是说VVC和HEVC达到相同的编码质量，VVC的码率能比HEVC节省50%。<br>对于VVC中的各种coding tools，笔者会在后续的文章中介绍。<br>本文介绍一下VVC标准中没有包含的一种coding tool，就是借助于Neural Network来优化视频压缩的方法。在VVC的多次会议的提案中都包括了借助于Neural Network来优化视频压缩的方法。至于这些提案最后没有进入标准，一个原因是这些方案的压缩效率提升不少很明显，而且适用范围有限。另外也可能和计算的复杂度有关，例如有些提案在CPU上的解码时间会增加好几倍。笔者觉得对于未来的视频标准(H.267?)来说，可能会采纳类似的方案，也许那个时候GPU解码会成为标配，为了追求极致的压缩效率，复杂度的增加也许会变得可以接受。</p>
<p>笔者分析了VVC提案中Neural Network的有关提案，发现基本集中在Loop Filter部分较多，这个和目前热门的Super Resolution技术解决的问题类似，也就是通过NN的方法把图像中失真的信息尽量还原回来，VVC中失真是指通过编码器量化过程以后，码流中包括的信息和源图像是有失真，而NN Filter可以很好的完整失真信息的还原。<br>另外VVC的提案中也包括了采用Neural Network来优化Intra Prediction和Rate Control编码效率的方案。</p>
<p>下面对VVC中有关Neural Network的提案进行总结归类。</p>
<h1 id="0x2-关于Neural-Network-based-Loop-Filter的提案"><a href="#0x2-关于Neural-Network-based-Loop-Filter的提案" class="headerlink" title="0x2 关于Neural Network based Loop Filter的提案"></a>0x2 关于Neural Network based Loop Filter的提案</h1><p>Neural Network based Loop Filter的提案又包括了下面这几种。</p>
<h2 id="0x21-JVET-I0022-Convolution-Neural-Network-Filter-CNNF-for-Intra-Frame"><a href="#0x21-JVET-I0022-Convolution-Neural-Network-Filter-CNNF-for-Intra-Frame" class="headerlink" title="0x21 JVET-I0022 Convolution Neural Network Filter (CNNF) for Intra Frame"></a>0x21 JVET-I0022 Convolution Neural Network Filter (CNNF) for Intra Frame</h2><h3 id="0x211-JVET-I0022-Convolution-Neural-Network-Filter-CNNF-for-Intra-Frame-Hikvision"><a href="#0x211-JVET-I0022-Convolution-Neural-Network-Filter-CNNF-for-Intra-Frame-Hikvision" class="headerlink" title="0x211 JVET-I0022 Convolution Neural Network Filter (CNNF) for Intra Frame (Hikvision)"></a>0x211 JVET-I0022 Convolution Neural Network Filter (CNNF) for Intra Frame (Hikvision)</h3><p>VCC中包括了BF/DF/SAO filter这几个传统filter，这几个filter的作用是remove artifacts or improve coding performance。<br>CNNF用于替换这些传统filter。<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-I0022.png" alt=""></p>
<p>网络结构如下图所示<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-I0022-network.png" alt=""></p>
<h3 id="0x212-JVET-J0043-Convolutional-Neural-Network-Filter-for-inter-frame-Hikvision"><a href="#0x212-JVET-J0043-Convolutional-Neural-Network-Filter-for-inter-frame-Hikvision" class="headerlink" title="0x212 JVET-J0043 Convolutional Neural Network Filter for inter frame (Hikvision)"></a>0x212 JVET-J0043 Convolutional Neural Network Filter for inter frame (Hikvision)</h3><p>为了避免over-filter造成artifacts，采用RDO方法来选择是采用传统的Filter还是CNN filter。选择filter的flag通过CABAC编码。<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-J0043.png" alt=""></p>
<h3 id="0x213-JVET-N0169-Convolutional-Neural-Network-Filter-CNNF-for-Intra-Frame-Hikvision"><a href="#0x213-JVET-N0169-Convolutional-Neural-Network-Filter-CNNF-for-Intra-Frame-Hikvision" class="headerlink" title="0x213 JVET-N0169 Convolutional Neural Network Filter (CNNF) for Intra Frame (Hikvision)"></a>0x213 JVET-N0169 Convolutional Neural Network Filter (CNNF) for Intra Frame (Hikvision)</h3><p>对CNNF放置在deblocking的不同位置的编码性能进行比较。<br>Comparison of intra decoding scheme between different positions of CNN filter<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-N0169.png" alt=""></p>
<p>优化结论如下。<br>Driven by the advances of deep learning, a CNN-based filter for intra frame is proposed to remove the artifacts. Simulation results report -3.48%, -5.18%, -6.77% BD-rate savings for luma, and both chroma components for VTM-4.0 with AI configuration as the CNNF before the SAO. As the DF and SAO are turned off, the CNNF brings -4.65%, -6.73%, -7.92% BD-rate savings with ALF behind. Even though all the conventional filters are turned off, the CNNF still brings 4.14%, -5.49%, -6.70% BD-rate savings. </p>
<h3 id="0x214-JVET-K0158-Separable-Convolutional-Neural-Network-Filter-with-Squeeze-and-Excitation-block-Sharp"><a href="#0x214-JVET-K0158-Separable-Convolutional-Neural-Network-Filter-with-Squeeze-and-Excitation-block-Sharp" class="headerlink" title="0x214 JVET-K0158 Separable Convolutional Neural Network Filter with Squeeze-and-Excitation block(Sharp)"></a>0x214 JVET-K0158 Separable Convolutional Neural Network Filter with Squeeze-and-Excitation block(Sharp)</h3><p>对JVET-I0022进行进一步优化，减少CNN网络参数，可以达到和JVET-I0022类似的编码优化效果。</p>
<h2 id="0x22-JVET-K0222-Convolution-neural-network-loop-filter-MediaTek"><a href="#0x22-JVET-K0222-Convolution-neural-network-loop-filter-MediaTek" class="headerlink" title="0x22 JVET-K0222 Convolution neural network loop filter (MediaTek)"></a>0x22 JVET-K0222 Convolution neural network loop filter (MediaTek)</h2><p>设计了CNN Loop Filter，对reconstructed samples进行loop filter处理。<br>如下描述，这个CNN的parameter是在encoder的过程中通过online的方式生成的。 不像其他几种提案完全是通过offline的方式来生成。<br>only those pictures with temporal ID equal to 0 or 1 are used to derive CNNLF parameters in the training process. That is, only these pictures are required to be encoded twice. The first round is to generate the required data for CNNLF training process and derive the CNNLF parameters. The second round is to generate the final bitstream by enabling CNNLF with the derived parameters.</p>
<p>如下图所示，这个CNNLF添加在adaptive loop filter (ALF)的后面, CNNLF的输入是ALF输出的reconstructed samples。CNNLF的输出被称为 restored samples.</p>
<p><img src="/2020/10/07/Neural network coding tool in VVC/JVET-K0222.png" alt=""></p>
<p>JVET-M0159, Convolutional neural network loop filter  (MediaTek)<br>其对K0222进行了优化，主要是简化NN网络。JVET-M0159和JVET-K0222的差异如下。</p>
<p><img src="/2020/10/07/Neural network coding tool in VVC/JVET-M0159.png" alt=""></p>
<h2 id="0x23-JVET-K0391-Dense-Residual-Convolutional-Neural-Network-based-In-Loop-Filter-Tencent-WHU"><a href="#0x23-JVET-K0391-Dense-Residual-Convolutional-Neural-Network-based-In-Loop-Filter-Tencent-WHU" class="headerlink" title="0x23 JVET-K0391 Dense Residual Convolutional Neural Network based In-Loop Filter (Tencent, WHU)"></a>0x23 JVET-K0391 Dense Residual Convolutional Neural Network based In-Loop Filter (Tencent, WHU)</h2><p>在SAO前面加入dense residual convolutional network based in-loop filter (DRNLF)</p>
<p>In-loop filters, such as DF (deblocking filter), sample adaptive offset (SAO), are employed in VTM for suppressing compression artifacts, which contributes to coding performance improvement.<br>In this contribution, the proposed DRNLF is introduced as an additional filter before SAO</p>
<p>Proposed decoding scheme in VTM<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-K0391.png" alt=""></p>
<p>JVET-L0242 Dense Residual Convolutional Neural Network based In-Loop Filter(Tencent, WHU)<br>JVET-L0242对JVET-K0391进一步优化，减少了NN网络的参数。另外为了防止over-filter，采用如下图所示的RDO方法来决策是否采用DRN。</p>
<p><img src="/2020/10/07/Neural network coding tool in VVC/JVET-L0242.png" alt=""></p>
<h2 id="0x24-JVET-L383-Convolution-Neural-Network-Filter-KDDI"><a href="#0x24-JVET-L383-Convolution-Neural-Network-Filter-KDDI" class="headerlink" title="0x24 JVET-L383 Convolution Neural Network Filter(KDDI)"></a>0x24 JVET-L383 Convolution Neural Network Filter(KDDI)</h2><p>提案也是采用Convolution Neural Network Filter去替换目前的multiple filter such as deblocking filter (DBF), sample adaptive offset (SAO) and adaptive loop filter (ALF)。另外CNN Filter参数在encoder端和decoder端是相同的。</p>
<p>优化结论如下。<br>The simulation results show the BD-rate for luma is -0.93% for AI where CNNF is replaced by DBF, SAO and ALF though the BD-rate is -2.21% for AI where CNNF is replaced by DBF and SAO only.<br>The filter structure is shown in Figure 1. This filter has four layers with 3x3 taps. The input of sum block is residual signal from the left and reconstructed signal before all in-loop filters from the bottom. The output of sum block is filtered pixels. Actual output is weighted sum of after filtered and before filtered pixels based on the distance of edge.</p>
<p>提出的CNNF的结构图如下所示。<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-L383.png" alt=""></p>
<h2 id="0x25-JVET-M0510-CNN-based-In-Loop-Filter-proposed-by-USTC"><a href="#0x25-JVET-M0510-CNN-based-In-Loop-Filter-proposed-by-USTC" class="headerlink" title="0x25 JVET-M0510  CNN-based In-Loop Filter proposed by USTC"></a>0x25 JVET-M0510  CNN-based In-Loop Filter proposed by USTC</h2><p>这个提案中提出的CNN filter具有如下特点。</p>
<ol>
<li>Lightweight deep convolutional neural networks</li>
<li>Locate between DF and SAO</li>
<li>-0.96%, -0.32%, -0.45% BD-rate savings for Y, Cb, and Cr components compared with VTM3.0 under AI configuration</li>
</ol>
<h2 id="0x26-JVET-M0566-Adaptive-convolutional-neural-network-loop-filter-Intel"><a href="#0x26-JVET-M0566-Adaptive-convolutional-neural-network-loop-filter-Intel" class="headerlink" title="0x26 JVET-M0566  Adaptive convolutional neural network loop filter (Intel)"></a>0x26 JVET-M0566  Adaptive convolutional neural network loop filter (Intel)</h2><p>该提案提出了ACNNLF的设计，通过online training的方式得到3 CNN based loop filters。每个filter都是a small 2 layer CNN with total 692 parameters。在编码过程中为每个CTB的luma、chroma选择3个ACNNLFs之一作为loop filter。这三个ACNNLFs的网络参数会被写入到slice header中，然后每个CTB要选择哪个ACNNLF的话，只需要一个index指定到slice header的ACNNLFs的网络参数即可。</p>
<p>ACNNLF在解码流程中的位置如下图所示。<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-M0566.png" alt=""></p>
<p>下面说明了ACNNLF的设计思想，主要体现了adaptive的online training的思想。<br>The ALF filter can be considered as a special one-layer CNN with linear activation. However, the number of filter coefficients in an ALF filter is too small to capture relevant features in the video. In order to match different video content, many ALF filters are used. Therefore, ALF makes up the deficiency of small number of filter coefficients by increasing the number of filter classes used.<br>As we try to further reduce the number of CNNLF parameters, we increase the number of CNNLFs to choose from to ensure the design can adapt to diverse video content without sacrificing performance. In this document, we propose an ACNNLF design: </p>
<ol>
<li>Small Deep-CNN loop filter with minimum number of hidden layers (2 CNN layers);</li>
<li>3 set of CNN loop filters trained online for luma and chroma respectively to better adapt to the content.<br>Since the number of ACNNLF filters (3) is small, it is possible to conduct exhaustive search for the optimal ACNNLF in the encoding process. The ACNNLF selection is indicated in the coded stream to the decoder. ACNNLF is applied after ALF in the decoding process.   </li>
</ol>
<p>采用了ACNNLF的优化结论如下。<br>This contribution presents an ACNNLF design with 3 classes of CNN based loop filters, where each filter has only 2 CNN layers and 692 parameters. The 3 ACNNLFs are adaptively trained with video sequence data. The best ACNNLF is selected for luma and chroma respectively for each CTB at encoder and indicated to decoder in coded stream with 2 bit indicator at CTB level. Compared with VTM-4.0-RA, the proposed ACNNLF achieves -1.14%, -0.21%, and -1.18% BD-rates for Y, U, and V, respectively, for Class A1 video sequences; -0.98%, -14.37%, and -16.96% BD-rates for Y, U, and V, respectively, for Class A2 video sequences; -0.55%, -21.79%, and -20.04% BD-rates for Y, U, and V, respectively, for Class B video sequences; and 0.09%, -2.75%, and -1.43% BD-rates for Y, U, and V, respectively, for Class C video sequences. The decoding time in the RA is 127% on VTM 4.0. </p>
<h2 id="0x27-JVET-O0079-Integrated-in-loop-filter-based-on-CNN-Tests-2-1-2-2-and-2-3"><a href="#0x27-JVET-O0079-Integrated-in-loop-filter-based-on-CNN-Tests-2-1-2-2-and-2-3" class="headerlink" title="0x27 JVET-O0079  Integrated in-loop filter based on CNN (Tests 2.1, 2.2 and 2.3)"></a>0x27 JVET-O0079  Integrated in-loop filter based on CNN (Tests 2.1, 2.2 and 2.3)</h2><p>Northwestern Polytechnical University (NPU), Xidian University, Guangdong OPPO Mobile Telecommunications Corp., Ltd</p>
<p>提出采用WSE-CNNLF(Wide-activated Squeeze-and-Excitation Convolutional Neural Network Loop Filter)作为in loop filter，具有下面的特点。</p>
<ol>
<li>It includes six inputs: three reconstructed components (Y, U, V) and three auxiliary inputs (QPmap, CUmap for luma, CUmap for chroma).</li>
<li>It consists of three stages to make the luma and chroma components jointly processed and separately fused with the corresponding CUmap before generating outputs.</li>
<li>It can replace and even outperform the multiple filters in current VVC. </li>
</ol>
<p>Main structure of the proposed CNNLF<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-O0079.png" alt=""></p>
<p>该提案的优化结论如下。<br>For test 2.1, it can be seen that converting weights from 32bit-float to 8bit-int leads to lower gains (from -0.46% to 0.79% for BD-rate saving on luma).<br>For test 2.2, in AI configuration, the BD-rate saving on luma of in-loop filter (-3.93%) is higher than that of post filter (-3.05%). In RA configuration, the BD-rate saving on luma of post filter (-1.89%) is higher than that of in-loop filter (-0.26%). It is noted that the proposed NN filter completely replaces the original in-loop filter (i.e., DBF+SAO+ALF ) when test 2.2a is performed to evaluate the in-loop situation, while it is added as a post filter with DBF+SAO+ALF all on in 2.2.b. It is concluded that the proposed NN filter reportedly outperforms DBF+SAO+ALF if used as the only in-loop filter, and is also useful if used as an extra post-loop filter.<br>For test 2.3, it’s shown that the proposed WSE-CNNLF has generalization capability on higher QP. The BD-rate saving is -0.46%, -4.11%, -2.80% when the test QP is the same as training QP, and -1.52%, -6.15%, -4.31% when the test QP equals to training QP+5. The CNN-based loop filter seems to be more effective on lower video qualities.</p>
<h1 id="0x3-采用Neural-Network来加速CTU-partition加速和优化编码效率"><a href="#0x3-采用Neural-Network来加速CTU-partition加速和优化编码效率" class="headerlink" title="0x3 采用Neural Network来加速CTU partition加速和优化编码效率"></a>0x3 采用Neural Network来加速CTU partition加速和优化编码效率</h1><p>JVET-J0034 CNN-based driving of block partitioning for intra slices encoding</p>
<p>该提案的算法描述如下。</p>
<p>for driving the encoder by estimating probabilities of blocks or Coding Units (CU) splitting in intra slices. The approach is primarily based on a texture analysis of the original blocks, and partly replaces the costly Rate Distortion Optimization (RDO) potentially involved for testing all potential partitioning configurations.</p>
<p>Overview of the split prediction process<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-J0034-split.png" alt=""></p>
<p>This module precedes the usual RDO process, and pre-selects the split configurations to be tested by the RDO. It is composed of the following 3 steps:</p>
<ol>
<li>CNN-based analysis – In the first step, each input 65×65 patch is analyzed by a CNN-based texture analyzer. The output of this step consists in a vector of probabilities associated to each one of the elementary boundaries that separate elementary sub-blocks. Figure 2 illustrates the mapping between elementary boundary locations and the vector of probabilities. The size of elementary blocks being 4×4, the vector contains n=480 probability values. The CNN is described in section 3.</li>
<li>Probable split selection – The second step takes as input the probability of each elementary boundary and outputs a first set of splitting modes among all possible options, which are: no split, QT, BT (vertical, horizontal), ABT (top, bottom, left, right). This step is further detailed in section 4.1.</li>
<li>Encoder constraints and speed-ups –  The third step selects the final set of splitting modes to be checked by classical RDO, depending on the first set provided by step 2, the contextual split constraints described in JVET-J0022 section 3.1.1.3 and the encoder speed-ups described in JVET-J0022, section 3.1.2.1. This step is further detailed in section 4.2.</li>
</ol>
<p>该提案的优化结论如下。<br>在AI configuration情况下，在相关的编码时间情况下，比基准(JEM7)取得6%的BD-rate gain，在相同的BD-rate gain情况下，编码时间可以减少4.3倍。<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-J0034-perf.png" alt=""></p>
<h1 id="0x4-采用Neural-Network来优化Intra-Prediction"><a href="#0x4-采用Neural-Network来优化Intra-Prediction" class="headerlink" title="0x4 采用Neural Network来优化Intra Prediction"></a>0x4 采用Neural Network来优化Intra Prediction</h1><p>JVET-J0037 Intra prediction modes based on neural networks</p>
<p>如下图所示，通过NN的方法来得当前Intra block的预测像素值。<br>Prediction of MxN intra block from reconstructed samples using a neural network<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-J0037-sample.png" alt=""></p>
<p>如下图所示，通过NN的方法来得当前Intra block的预测mode值。<br>Prediction of mode probabilities from reconstructed samples using a neural network<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-J0037-mode.png" alt=""></p>
<h1 id="0x5-采用Neural-Network来优化Rate-Control"><a href="#0x5-采用Neural-Network来优化Rate-Control" class="headerlink" title="0x5 采用Neural Network来优化Rate Control"></a>0x5 采用Neural Network来优化Rate Control</h1><p>JVET-M0215 CNN-based lambda-domain rate control for intra frames</p>
<p>This contribution proposes a CNN-based λ-domain rate control approach for intra frame coding. Compared with the exiting SATD-based intra rate control approach in VTM, we reuse the R-lambda model in VTM inter frame rate control and train one convolutional neural network to simultaneously predict the two model parameters, alpha and beta. Compared with the rate control method in VTM 3.0, the proposed method can achieve an average bd-rate reduction of 1.8% under All Intra configuration. When considering the mismatch between target bitrate and actually coded bit rate, the CNN-based method can achieve a smaller rate control error, especially for the first I frame.</p>
<p>通过下面的NN网络训练得到两个参数，这两个参数作为Rate Control的后续输入参数。</p>
<p>We propose to reuse the   model and train one convolutional neural networks to simultaneously predict the two parameters. The network architecture is depicted in Fig.1. Specifically, before the encoding for one Intra frame, we extract the luma component, as well as the chroma components of each CTU and feed them into the two trained CNN, from the CNN output we can obtain the corresponding  and   for each CTU. </p>
<p>CNN-based rate control的网络结构图如下所示，从图中可以看到是用一个网络来预测两个参数。</p>
<p><img src="/2020/10/07/Neural network coding tool in VVC/JVET-M0215.png" alt=""></p>
<h1 id="0x6-有关Neural-Network的参数传递"><a href="#0x6-有关Neural-Network的参数传递" class="headerlink" title="0x6 有关Neural Network的参数传递"></a>0x6 有关Neural Network的参数传递</h1><p>JVET-N0065 Comments on carriage of coding tool parameters in Adaptation Parameter Set</p>
<p>采用Adaptation Parameter Set (APS)用于动态传输neural network的参数。</p>
<p>In 13th JVET meeting, Adaptation Parameter Set (APS) has been introduced into Versatile Video Coding (VVC) standard text. A few years ago, the APS was once adopted into High Efficiency Video Coding (HEVC) standard for carrying coding tool parameters, such as Adaptive Loop Filter (ALF) parameters; but the APS was removed from HEVC standard along with the removal of ALF as a coding tool at a final HEVC standardisation stage. The APS was designed to carry coding tool parameters as a picture level adaptive nature and alternatively the APS data can also be maintained as unchanged for the whole video sequence for avoiding resending them unnecessarily. This contribution is for information only and it is commented and recommended to use the APS to carry the coding tool data, such as neural networks parameters and affine linear weighted intra prediction parameters, etc., if some associated coding tools are indeed to be adopted into VVC standard. If more coding tool data need to be carried by APS in the future, it commented that further study on updating parameters of multiple tools using APS would be needed.</p>
<p>It is recommended that APS can be considered as the carrier for coding tool parameters, such as neural networks coding parameters, etc., to convey these parameters in bitstreams to a VVC decoder. When more types of coding tool parameters are needed to be carried by APS, updating parameters of multiple tools using APS would need to be further studied for achieving more efficient use of the APS.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/06/28/Intel vulkan driver introduction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/06/28/Intel vulkan driver introduction/" itemprop="url">Intel vulkan driver introduction</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-06-28T19:10:10+09:00">
                2020-06-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2020/06/28/Intel vulkan driver introduction/" class="leancloud_visitors" data-flag-title="Intel vulkan driver introduction">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="0x1-Overview"><a href="#0x1-Overview" class="headerlink" title="0x1 Overview"></a>0x1 Overview</h1><p>As we know, mesa has supported vulkan driver for four different platforms, these four platforms are Intel，AMD，Qualcomm Adreno，Broadcom V3D. Currently vulkan driver support in mesa is not using Gallium architecture like OpenGL，its architecture seems child stage, the four vulkan drivers don’t have much shared common codes, the abstraction of the four vulkan drivers is the architecture optimization of mesa vulkan driver in the next stage.It has widely discussed in the mesa dev community.And the coming optimized architecture will accelerate the supporting for more GPU platforms like Mali GPU and Imagination GPU.</p>
<p><img src="/2020/06/28/Intel vulkan driver introduction/vulkan_driver_of_mesa.png" alt=""></p>
<p>In this article, I will show you how Intel Vulkan driver is supported in mesa.</p>
<p>Let’s have a look of Intel GEN GPU hardware architecture.</p>
<p>The following diagram is about the hardware block of the <a href="http://kiwitree.net/~chadv/intel-gfx-docs/prm/gen11.0-icl/intel-gfx-prm-osrc-icllp-vol09-renderengine_0.pdf" target="_blank" rel="external">Intel GEN GPU</a></p>
<p><img src="/2020/06/28/Intel vulkan driver introduction/GPU-block.png" alt=""><br><img src="/2020/06/28/Intel vulkan driver introduction/GPU-block1.png" alt=""></p>
<p>Here is the 3D pipeline block of <a href="https://01.org/sites/default/files/documentation/snb_ihd_os_vol2_part1_0.pdf" target="_blank" rel="external">Intel Gen GPU</a>. the left part is the 3D pipleine, the right part is the GPU hardware block.</p>
<p><img src="/2020/06/28/Intel vulkan driver introduction/GPU-pipeline.png" alt=""><br><img src="/2020/06/28/Intel vulkan driver introduction/GPU-pipeline1.png" alt=""></p>
<p>The GPU driver (userspace and kernel space) will configure the above hardware block according to graphics API’s input, then trigger gpu hardware to execute as its configuration. So GPU driver’s task is simple, just to configure the GPU hardware!</p>
<h1 id="0x2-Component-overview"><a href="#0x2-Component-overview" class="headerlink" title="0x2 Component overview"></a>0x2 Component overview</h1><p>We know mesa includes several abstraction layers. it supports different graphics api,different compiler frontend, different gpu hardware code generation.</p>
<p>In mesa, Intel vulkan driver’s module name is ANV.Here is the diagram about how ANV driver is built from different sub component.<br><img src="/2020/06/28/Intel vulkan driver introduction/component_overview.png" alt=""></p>
<p>And here is the relationship of intel vulkan driver library and its dpendencies.<br><img src="/2020/06/28/Intel vulkan driver introduction/component_overview_1.png" alt=""></p>
<h1 id="0x3-Mem-interface"><a href="#0x3-Mem-interface" class="headerlink" title="0x3 Mem interface"></a>0x3 Mem interface</h1><p>GPU harware needs serveral input data for further processing, like vertex buffer, texture buffer, uniform buffer and surface, these buffer will be accessed by CPU and GPU together. so mesa should provide interface to alloc/release buffer, set these buffer’s address to GPU hardware then issue hardware to execute it.</p>
<p>Let’s have brief explanation about how buffer alloc/release happen in ANV vulkan driver.</p>
<p>Here is the sequence about allocating gem buffer.</p>
<p><img src="/2020/06/28/Intel vulkan driver introduction/gem_alloc.png" alt=""></p>
<p>Here is the sequence about releasing buffer.</p>
<p><img src="/2020/06/28/Intel vulkan driver introduction/gem_release.png" alt=""></p>
<p>Here is the sequence about issuing command to kernel driver.</p>
<p><img src="/2020/06/28/Intel vulkan driver introduction/gem_execbuffer.png" alt=""></p>
<p>For performance optimization, ANV can use a cache mechansim to boost the performance since the memory alloc/release is resource heavy operation. In broadcom close source v3d driver, it uses a similar mechansim like linux slab to cache buffer in userland driver.</p>
<h1 id="0x4-Typical-objects-in-vulkan"><a href="#0x4-Typical-objects-in-vulkan" class="headerlink" title="0x4 Typical objects in vulkan"></a>0x4 Typical objects in vulkan</h1><p>Here are several important objects of vulkan concepts. RenderPass object and ShaderModule object are passed to Pipeline through VkGraphicsPipelineCreateInfo when creating Pipeline object. then Pipeline is binded to CommandBuffer using VkCmdBindPipeline api, after that the commanbuffer can use the passing Pipeline object, RenderPass object and ShaderModule object.<br><img src="/2020/06/28/Intel vulkan driver introduction/architecture.png" alt=""></p>
<h1 id="0x5-GPU-codegen"><a href="#0x5-GPU-codegen" class="headerlink" title="0x5 GPU codegen"></a>0x5 GPU codegen</h1><p>Here is the diagram about generating gpu code from SPIRV code.<br><img src="/2020/06/28/Intel vulkan driver introduction/spirv_to_nir_to_gpucode.png" alt=""></p>
<p>The gpu code is the code which will run on Intel GPU’s EUs(execution unit), it is programmable shader unit, likes broadcom v3d’s QPU.</p>
<p>The input of the pipeline is SPIRV code, the SPIRV format is the standard IR for different shader formats like glsl,opencl. </p>
<p>Then ANV driver will convert it to mesa internal IR format(NIR) code.</p>
<p>Then it will be optimized by different passes, this idea is similar as other compiler’s optimization passes.</p>
<p>The last step is gpu code generation.It uses typical graphic coloring algorithm. at this stage,we must read the GPU programmer guide carefully,then learn how to generate effective code for intel gen gpu.</p>
<h1 id="0x6-Framebuffer-dump"><a href="#0x6-Framebuffer-dump" class="headerlink" title="0x6 Framebuffer dump"></a>0x6 Framebuffer dump</h1><p>This feature is useful for us to check the render result in the framebuffer. it is similar as we can use glReadPixels to read back framebuffer’s content on OpenGL.</p>
<p>Currently mesa’s anv dump code has bug to blit framebuffer to write image, and I have fixed it to make this feature can work well.</p>
<p>Here is the diagram about how to dump framebuffer.<br><img src="/2020/06/28/Intel vulkan driver introduction/anv_dump.png" alt=""></p>
<p>It uses gdb call method to dump data, here is the use instruction about it.</p>
<ul>
<li>To dump the framebuffers of an application after each render pass, all you</li>
<li>have to do is the following<br>*</li>
<li>1) Start the application in GDB</li>
<li>2) Run until you get to the point where the rendering errors occur</li>
<li>3) Pause in GDB and set a breakpoint in anv_QueuePresentKHR</li>
<li>4) Continue until it reaches anv_QueuePresentKHR</li>
<li>5) Call anv_dump_start(queue-&gt;device, ANV_DUMP_FRAMEBUFFERS_BIT)</li>
<li>6) Continue until the next anv_QueuePresentKHR call</li>
<li>7) Call anv_dump_finish() to complete the dump and write files</li>
</ul>
<p>Here is the dump result with the above method.<br><img src="/2020/06/28/Intel vulkan driver introduction/anv_dump_result.png" alt=""></p>
<h1 id="0x7-Hardware-state-dump"><a href="#0x7-Hardware-state-dump" class="headerlink" title="0x7 Hardware state dump"></a>0x7 Hardware state dump</h1><p>It uses preload method to hook api, the hook api will dump state to a file.</p>
<p>Here is the diagram about it.<br><img src="/2020/06/28/Intel vulkan driver introduction/intel_gpu_dump.png" alt=""></p>
<p>Here is the gdb command for capturing data</p>
<p>gdb -iex “set exec-wrapper env LD_PRELOAD=/home/kevin/mesa/mesa_build_vulkan/libexec/libintel_dump_gpu.so INTEL_DUMP_GPU_CONFIG=/home/kevin/mesa/test_intel_dump_gpu/dump_config” –args “/home/kevin/vulkan/build/bin/multithreading”</p>
<p>Then we can use Aubinator Viewer to check the dumped states. please notice that this dump mechansim is also working for Opengl case, and the dump items are the same as Vulkan’s since the dump is for getting content of gpu hardware statue.</p>
<p>The dump item shows what vulkan driver program the hardware. we can see the following states’s content like 3DSTATE_VS and other states.</p>
<p><img src="/2020/06/28/Intel vulkan driver introduction/intel_gpu_dump_result.png" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/30/EGL in Mesa/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/05/30/EGL in Mesa/" itemprop="url">EGL in Mesa</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-30T18:10:10+09:00">
                2020-05-30
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2020/05/30/EGL in Mesa/" class="leancloud_visitors" data-flag-title="EGL in Mesa">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="0x1-EGL介绍"><a href="#0x1-EGL介绍" class="headerlink" title="0x1 EGL介绍"></a>0x1 EGL介绍</h1><p>我们知道通过OpenGL来绘制的时候需要和EGL配合才能完成渲染，本文主要来介绍一下mesa中的EGL驱动实现。下面先来简单介绍一下EGL。<br>EGL用于管理绘图表面，其主要提供了下列几种功能，</p>
<p>a 与设备平台的原生窗口系统进行交互。</p>
<p>b 查询可用的绘制类似和相关配置。</p>
<p>c 创建和管理绘制surface。</p>
<p>d 创建和管理绘制context。</p>
<p>e 提供present接口eglSwapBuffers，一般通过交换前后缓存区来实现。</p>
<p>EGL驱动中包括了对下面这些EGL API的封装，应用调用这些API来和EGL驱动交互。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line">eglBindAPI</div><div class="line">eglBindTexImage</div><div class="line">eglChooseConfig</div><div class="line">eglClientWaitSync</div><div class="line">eglCopyBuffers</div><div class="line">eglCreateContext</div><div class="line">eglCreateImage</div><div class="line">eglCreatePbufferFromClientBuffer</div><div class="line">eglCreatePbufferSurface</div><div class="line">eglCreatePixmapSurface</div><div class="line">eglCreatePlatformPixmapSurface</div><div class="line">eglCreatePlatformWindowSurface</div><div class="line">eglCreateSync</div><div class="line">eglCreateWindowSurface</div><div class="line">eglDestroyContext</div><div class="line">eglDestroyImage</div><div class="line">eglDestroySurface</div><div class="line">eglDestroySync</div><div class="line">eglGetConfigAttrib</div><div class="line">eglGetConfigs</div><div class="line">eglGetCurrentContext</div><div class="line">eglGetCurrentDisplay</div><div class="line">eglGetCurrentSurface</div><div class="line">eglGetDisplay</div><div class="line">eglGetError</div><div class="line">eglGetPlatformDisplay</div><div class="line">eglGetProcAddress</div><div class="line">eglGetSyncAttrib</div><div class="line">eglInitialize</div><div class="line">eglMakeCurrent</div><div class="line">eglQueryAPI</div><div class="line">eglQueryContext</div><div class="line">eglQueryString</div><div class="line">eglQuerySurface</div><div class="line">eglReleaseTexImage</div><div class="line">eglReleaseThread</div><div class="line">eglSurfaceAttrib</div><div class="line">eglSwapBuffers</div><div class="line">eglSwapInterval</div><div class="line">eglTerminate</div><div class="line">eglWaitClient</div><div class="line">eglWaitGL</div><div class="line">eglWaitNative</div><div class="line">eglWaitSync</div><div class="line">MesaGLInteropEGLQueryDeviceInfo</div><div class="line">MesaGLInteropEGLExportObject</div></pre></td></tr></table></figure></p>
<p>mesa中egl架构如下图所示。</p>
<p><img src="/2020/05/30/EGL in Mesa/mesa_egl-architecture.svg" alt="EGL in Mesa"></p>
<p>对上图简单说明如下，<br>从上图左上角可以看到，EGL需要和具体显示平台的窗口NativeWindow交互。这个NativeWindow需要在应用侧创建好，创建的NativeWindow是根据具体的平台(如Android， X11， Wayland)的不同而不同。这个应用创建好的NativeWindow通过调用eglCreateWindowSurface()传入到egl驱动中。</p>
<p>EGL还需要和绘制缓冲区对象(framebuffer)进行交互，这些缓冲区一般由EGL驱动调用外部窗口系统的提供的接口(如android上的surface)来分配和释放。绘制之前需要先得到空闲的buffer，绘制完成以后需要把buffer送给下一级pipeline，交出控制权。这里面一般会创建2~3个buffer，和下一级pipeline一起循环使用。这些buffer在pipeline的不同阶段流动，控制权也在各个阶段中流转，所以需要一种同步机制来保证buffer何时可读，何时可写，在android上是通过fence机制来保证的。</p>
<p>GL Driver调用EGL的内部接口(getBuffers)来得到当前绘制的目标buffer，然后GL Driver就可以发送绘制命令给GPU硬件，GPU硬件把渲染结果绘制到目标buffer中。</p>
<p>笔者的测试平台是Intel i3，GPU是Gen5xx，通过配置mesa的编译参数，可以编译出GPU平台相关的库是iris_dri.so。<br>这种配置下mesa中代码调用关系如下图所示。<br>从下图可以看出，mesa把驱动进行了分层，上面是通用的实现，对具体gpu平台相关实现都封装在xxx_dri.so中，这里Gen5xx平台对应的是iris_dri.so，对broadcom vc4 gpu来说，对应的是vc4_dri.so。</p>
<p><img src="/2020/05/30/EGL in Mesa/code_architecture.svg" alt="EGL in Mesa"></p>
<h1 id="0x2-mesa中egl流程介绍"><a href="#0x2-mesa中egl流程介绍" class="headerlink" title="0x2 mesa中egl流程介绍"></a>0x2 mesa中egl流程介绍</h1><p>下图说明了一个OpenGL ES应用程序调用EGL接口来绘制的基本流程。<br><img src="/2020/05/30/EGL in Mesa/mesa_egl.svg" alt="EGL in Mesa"></p>
<p>下面对流程中的egl api调用做详细的说明，</p>
<h2 id="0x21-创建X11平台对应的Display和Window"><a href="#0x21-创建X11平台对应的Display和Window" class="headerlink" title="0x21 创建X11平台对应的Display和Window"></a>0x21 创建X11平台对应的Display和Window</h2><p>首先在应用程序中通过下面的代码来创建x11平台上的display和window。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// create display and window for x11 platform</span></div><div class="line">x_display = XOpenDisplay(<span class="literal">NULL</span>);</div><div class="line"><span class="keyword">if</span> ( x_display == <span class="literal">NULL</span> )</div><div class="line">&#123;</div><div class="line">    <span class="keyword">return</span> EGL_FALSE;</div><div class="line">&#125;</div><div class="line"></div><div class="line">root = DefaultRootWindow(x_display);</div><div class="line"></div><div class="line">win = XCreateWindow(</div><div class="line">            x_display, root,</div><div class="line">            <span class="number">0</span>, <span class="number">0</span>, esContext-&gt;width, esContext-&gt;height, <span class="number">0</span>,</div><div class="line">            CopyFromParent, InputOutput,</div><div class="line">            CopyFromParent, CWEventMask,</div><div class="line">            &amp;swa );</div></pre></td></tr></table></figure></p>
<h2 id="0x21-调用eglInitialize"><a href="#0x21-调用eglInitialize" class="headerlink" title="0x21 调用eglInitialize"></a>0x21 调用eglInitialize</h2><p>该函数的调用堆栈如下。</p>
<p><img src="/2020/05/30/EGL in Mesa/eglInitialize.png" alt="EGL in Mesa"></p>
<p>eglInitialize的参数是display，这就是前面调用<br>平台相关接口得到的x_display。</p>
<p>上面调用堆栈最后调用的函数是iris_screen_create，这是mesa的gallium架构下初始化具体gpu型号的硬件驱动的入口函数。<br>这个在后续的文章中会做详细的介绍，这里我们知道了应用调用eglInitialize()的时候会去调用具体的gpu型号的硬件驱动。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// src/gallium/winsys/iris/drm/iris_drm_winsys.c</span></div><div class="line"><span class="function"><span class="keyword">extern</span> struct pipe_screen *<span class="title">iris_screen_create</span><span class="params">(<span class="keyword">int</span> fd, <span class="keyword">const</span> struct pipe_screen_config *config)</span></span>;</div><div class="line"></div><div class="line"><span class="function">struct pipe_screen *</span></div><div class="line"><span class="title">iris_drm_screen_create</span><span class="params">(<span class="keyword">int</span> fd, <span class="keyword">const</span> struct pipe_screen_config *config)</span></div><div class="line">&#123;</div><div class="line">   <span class="keyword">return</span> iris_screen_create(os_dupfd_cloexec(fd), config);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>下图的调用堆栈说明了eglInitialize调用过程中的gem buffer分配操作。这个操作最后会调用到kernel 驱动中完成内存分配动作。<br><img src="/2020/05/30/EGL in Mesa/eglInitialize_alloc_buffer.png" alt="EGL in Mesa"></p>
<h2 id="0x22-eglCreateContext的调用流程"><a href="#0x22-eglCreateContext的调用流程" class="headerlink" title="0x22 eglCreateContext的调用流程"></a>0x22 eglCreateContext的调用流程</h2><p>eglCreateContext的调用堆栈如下<br><img src="/2020/05/30/EGL in Mesa/eglCreateContext.png" alt="EGL in Mesa"></p>
<p>EGL驱动最后会调用到iris driver中创建context的代码中，其中包括了初始化各种函数指针的代码，包括program, clear, blit等操作。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// src/gallium/drivers/iris/iris_context.c</span></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Create a context.</div><div class="line"> *</div><div class="line"> * This is where each context begins.</div><div class="line"> */</div><div class="line"><span class="function">struct pipe_context *</span></div><div class="line"><span class="title">iris_create_context</span><span class="params">(struct pipe_screen *pscreen, <span class="keyword">void</span> *priv, <span class="keyword">unsigned</span> flags)</span></div><div class="line">&#123;</div><div class="line">   <span class="class"><span class="keyword">struct</span> <span class="title">iris_screen</span> *<span class="title">screen</span> = (<span class="title">struct</span> <span class="title">iris_screen</span>*)<span class="title">pscreen</span>;</span></div><div class="line">   <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">gen_device_info</span> *<span class="title">devinfo</span> = &amp;<span class="title">screen</span>-&gt;<span class="title">devinfo</span>;</span></div><div class="line">   <span class="class"><span class="keyword">struct</span> <span class="title">iris_context</span> *<span class="title">ice</span> = <span class="title">rzalloc</span>(<span class="title">NULL</span>, <span class="title">struct</span> <span class="title">iris_context</span>);</span></div><div class="line">   ......</div><div class="line">   iris_init_context_fence_functions(ctx);</div><div class="line">   iris_init_blit_functions(ctx);</div><div class="line">   iris_init_clear_functions(ctx);</div><div class="line">   iris_init_program_functions(ctx);</div><div class="line">   iris_init_resource_functions(ctx);</div><div class="line">   iris_init_flush_functions(ctx);</div><div class="line">   iris_init_perfquery_functions(ctx);</div><div class="line"></div><div class="line">   iris_init_program_cache(ice);</div><div class="line">   iris_init_border_color_pool(ice);</div><div class="line">   iris_init_binder(ice);</div><div class="line"></div><div class="line">   slab_create_child(&amp;ice-&gt;transfer_pool, &amp;screen-&gt;transfer_pool);</div><div class="line"></div><div class="line">   ice-&gt;state.surface_uploader =</div><div class="line">      u_upload_create(ctx, <span class="number">16384</span>, PIPE_BIND_CUSTOM, PIPE_USAGE_IMMUTABLE,</div><div class="line">                      IRIS_RESOURCE_FLAG_SURFACE_MEMZONE);</div><div class="line">   ice-&gt;state.dynamic_uploader =</div><div class="line">      u_upload_create(ctx, <span class="number">16384</span>, PIPE_BIND_CUSTOM, PIPE_USAGE_IMMUTABLE,</div><div class="line">                      IRIS_RESOURCE_FLAG_DYNAMIC_MEMZONE);</div><div class="line"></div><div class="line">   ice-&gt;query_buffer_uploader =</div><div class="line">      u_upload_create(ctx, <span class="number">4096</span>, PIPE_BIND_CUSTOM, PIPE_USAGE_STAGING,</div><div class="line">                      <span class="number">0</span>);</div><div class="line"></div><div class="line">   genX_call(devinfo, init_state, ice);</div><div class="line">   genX_call(devinfo, init_blorp, ice);</div><div class="line">   genX_call(devinfo, init_query, ice);</div><div class="line">   ......</div><div class="line">   <span class="keyword">return</span> ctx;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>下面是iris创建context的时候初始化state相关函数指针的代码。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// src/gallium/drivers/iris/iris_state.c</span></div><div class="line"><span class="function"><span class="keyword">void</span></span></div><div class="line"><span class="title">genX</span><span class="params">(init_state)</span><span class="params">(struct iris_context *ice)</span></div><div class="line">&#123;</div><div class="line">   <span class="class"><span class="keyword">struct</span> <span class="title">pipe_context</span> *<span class="title">ctx</span> = &amp;<span class="title">ice</span>-&gt;<span class="title">ctx</span>;</span></div><div class="line">   <span class="class"><span class="keyword">struct</span> <span class="title">iris_screen</span> *<span class="title">screen</span> = (<span class="title">struct</span> <span class="title">iris_screen</span> *)<span class="title">ctx</span>-&gt;<span class="title">screen</span>;</span></div><div class="line"></div><div class="line">   ctx-&gt;create_blend_state = iris_create_blend_state;</div><div class="line">   ctx-&gt;create_depth_stencil_alpha_state = iris_create_zsa_state;</div><div class="line">   ctx-&gt;create_rasterizer_state = iris_create_rasterizer_state;</div><div class="line">   ctx-&gt;create_sampler_state = iris_create_sampler_state;</div><div class="line">   ctx-&gt;create_sampler_view = iris_create_sampler_view;</div><div class="line">   ctx-&gt;create_surface = iris_create_surface;</div><div class="line">   ctx-&gt;create_vertex_elements_state = iris_create_vertex_elements;</div><div class="line">   ctx-&gt;bind_blend_state = iris_bind_blend_state;</div><div class="line">   ctx-&gt;bind_depth_stencil_alpha_state = iris_bind_zsa_state;</div><div class="line">   ctx-&gt;bind_sampler_states = iris_bind_sampler_states;</div><div class="line">   ctx-&gt;bind_rasterizer_state = iris_bind_rasterizer_state;</div><div class="line">   ctx-&gt;bind_vertex_elements_state = iris_bind_vertex_elements_state;</div><div class="line">   ctx-&gt;delete_blend_state = iris_delete_state;</div><div class="line">   ctx-&gt;delete_depth_stencil_alpha_state = iris_delete_state;</div><div class="line">   ctx-&gt;delete_rasterizer_state = iris_delete_state;</div><div class="line">   ctx-&gt;delete_sampler_state = iris_delete_state;</div><div class="line">   ctx-&gt;delete_vertex_elements_state = iris_delete_state;</div><div class="line">   ctx-&gt;set_blend_color = iris_set_blend_color;</div><div class="line">   ctx-&gt;set_clip_state = iris_set_clip_state;</div><div class="line">   ctx-&gt;set_constant_buffer = iris_set_constant_buffer;</div><div class="line">   ctx-&gt;set_shader_buffers = iris_set_shader_buffers;</div><div class="line">   ctx-&gt;set_shader_images = iris_set_shader_images;</div><div class="line">   ctx-&gt;set_sampler_views = iris_set_sampler_views;</div><div class="line">   ctx-&gt;set_compute_resources = iris_set_compute_resources;</div><div class="line">   ctx-&gt;set_global_binding = iris_set_global_binding;</div><div class="line">   ctx-&gt;set_tess_state = iris_set_tess_state;</div><div class="line">   ctx-&gt;set_framebuffer_state = iris_set_framebuffer_state;</div><div class="line">   ctx-&gt;set_polygon_stipple = iris_set_polygon_stipple;</div><div class="line">   ctx-&gt;set_sample_mask = iris_set_sample_mask;</div><div class="line">   ctx-&gt;set_scissor_states = iris_set_scissor_states;</div><div class="line">   ctx-&gt;set_stencil_ref = iris_set_stencil_ref;</div><div class="line">   ctx-&gt;set_vertex_buffers = iris_set_vertex_buffers;</div><div class="line">   ctx-&gt;set_viewport_states = iris_set_viewport_states;</div><div class="line">   ctx-&gt;sampler_view_destroy = iris_sampler_view_destroy;</div><div class="line">   ctx-&gt;surface_destroy = iris_surface_destroy;</div><div class="line">   ctx-&gt;draw_vbo = iris_draw_vbo;</div><div class="line">   ctx-&gt;launch_grid = iris_launch_grid;</div><div class="line">   ctx-&gt;create_stream_output_target = iris_create_stream_output_target;</div><div class="line">   ctx-&gt;stream_output_target_destroy = iris_stream_output_target_destroy;</div><div class="line">   ctx-&gt;set_stream_output_targets = iris_set_stream_output_targets;</div><div class="line">   ctx-&gt;set_frontend_noop = iris_set_frontend_noop;</div><div class="line"></div><div class="line">   screen-&gt;vtbl.destroy_state = iris_destroy_state;</div><div class="line">   screen-&gt;vtbl.init_render_context = iris_init_render_context;</div><div class="line">   screen-&gt;vtbl.init_compute_context = iris_init_compute_context;</div><div class="line">   screen-&gt;vtbl.upload_render_state = iris_upload_render_state;</div><div class="line">   screen-&gt;vtbl.update_surface_base_address = iris_update_surface_base_address;</div><div class="line">   screen-&gt;vtbl.upload_compute_state = iris_upload_compute_state;</div><div class="line">   screen-&gt;vtbl.emit_raw_pipe_control = iris_emit_raw_pipe_control;</div><div class="line">   screen-&gt;vtbl.emit_mi_report_perf_count = iris_emit_mi_report_perf_count;</div><div class="line">   screen-&gt;vtbl.rebind_buffer = iris_rebind_buffer;</div><div class="line">   screen-&gt;vtbl.load_register_reg32 = iris_load_register_reg32;</div><div class="line">   screen-&gt;vtbl.load_register_reg64 = iris_load_register_reg64;</div><div class="line">   screen-&gt;vtbl.load_register_imm32 = iris_load_register_imm32;</div><div class="line">   screen-&gt;vtbl.load_register_imm64 = iris_load_register_imm64;</div><div class="line">   screen-&gt;vtbl.load_register_mem32 = iris_load_register_mem32;</div><div class="line">   screen-&gt;vtbl.load_register_mem64 = iris_load_register_mem64;</div><div class="line">   screen-&gt;vtbl.store_register_mem32 = iris_store_register_mem32;</div><div class="line">   screen-&gt;vtbl.store_register_mem64 = iris_store_register_mem64;</div><div class="line">   screen-&gt;vtbl.store_data_imm32 = iris_store_data_imm32;</div><div class="line">   screen-&gt;vtbl.store_data_imm64 = iris_store_data_imm64;</div><div class="line">   screen-&gt;vtbl.copy_mem_mem = iris_copy_mem_mem;</div><div class="line">   screen-&gt;vtbl.derived_program_state_size = iris_derived_program_state_size;</div><div class="line">   screen-&gt;vtbl.store_derived_program_state = iris_store_derived_program_state;</div><div class="line">   screen-&gt;vtbl.create_so_decl_list = iris_create_so_decl_list;</div><div class="line">   screen-&gt;vtbl.populate_vs_key = iris_populate_vs_key;</div><div class="line">   screen-&gt;vtbl.populate_tcs_key = iris_populate_tcs_key;</div><div class="line">   screen-&gt;vtbl.populate_tes_key = iris_populate_tes_key;</div><div class="line">   screen-&gt;vtbl.populate_gs_key = iris_populate_gs_key;</div><div class="line">   screen-&gt;vtbl.populate_fs_key = iris_populate_fs_key;</div><div class="line">   screen-&gt;vtbl.populate_cs_key = iris_populate_cs_key;</div><div class="line">   screen-&gt;vtbl.lost_genx_state = iris_lost_genx_state;</div><div class="line"></div><div class="line">   ice-&gt;state.dirty = ~<span class="number">0u</span>ll;</div><div class="line">   ice-&gt;state.stage_dirty = ~<span class="number">0u</span>ll;</div><div class="line"></div><div class="line">   ice-&gt;state.statistics_counters_enabled = <span class="literal">true</span>;</div><div class="line"></div><div class="line">   ice-&gt;state.sample_mask = <span class="number">0xffff</span>;</div><div class="line">   ice-&gt;state.num_viewports = <span class="number">1</span>;</div><div class="line">   ice-&gt;state.prim_mode = PIPE_PRIM_MAX;</div><div class="line">   ice-&gt;state.genx = <span class="built_in">calloc</span>(<span class="number">1</span>, <span class="keyword">sizeof</span>(struct iris_genx_state));</div><div class="line">   ice-&gt;draw.derived_params.drawid = <span class="number">-1</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="0x23-和外部NativeWindow的交互"><a href="#0x23-和外部NativeWindow的交互" class="headerlink" title="0x23 和外部NativeWindow的交互"></a>0x23 和外部NativeWindow的交互</h2><p>主要是buffer的管理, 通过dequeueBuffer取得空闲buffer供本次绘制使用，在绘制完成了以后，再调用queueBuffer把buffer送去显示。另外外部NativeWindow大小发生变化的时候，也需要调用相应的接口来通知mesa，这个时候一般的流程是先把前面分配的旧的大小的buffer释放掉，然后重新去分配新的大小的buffer，另外还需要调用glViewPort重新设置draw区域的viewport大小。</p>
<h2 id="0x24-gl-driver如何取得当前绘制的buffer"><a href="#0x24-gl-driver如何取得当前绘制的buffer" class="headerlink" title="0x24 gl driver如何取得当前绘制的buffer"></a>0x24 gl driver如何取得当前绘制的buffer</h2><p>GL Driver调用EGL的内部接口(getBuffers)来得到当前绘制的目标buffer。</p>
<p>下图是eglMakeCurrent函数执行的时候分配绘制buffer的堆栈。</p>
<p><img src="/2020/05/30/EGL in Mesa/eglMakeCurrent.png" alt="EGL in Mesa"></p>
<p>具体的调用代码如下所示，外部通过getBuffers来调用具体egl driver的buffer接口。对x11_dr3而言，最后调用的函数是loader_dri3_get_buffers，在这个时候会返回需要的buffer，如果有必要也会重新分配buffer。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// src/egl/drivers/dri2/platform_x11_dri3.c</span></div><div class="line"><span class="keyword">const</span> __DRIimageLoaderExtension dri3_image_loader_extension = &#123;</div><div class="line">   .base = &#123; __DRI_IMAGE_LOADER, <span class="number">1</span> &#125;,</div><div class="line"></div><div class="line">   .getBuffers          = loader_dri3_get_buffers,</div><div class="line">   .flushFrontBuffer    = dri3_flush_front_buffer,</div><div class="line">&#125;;</div><div class="line"></div><div class="line"><span class="comment">// src/loader/loader_dri3_helper.c</span></div><div class="line"></div><div class="line"><span class="comment">/** loader_dri3_get_buffers</span></div><div class="line"> *</div><div class="line"> * The published buffer allocation API.</div><div class="line"> * Returns all of the necessary buffers, allocating</div><div class="line"> * as needed.</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">int</span></span></div><div class="line"><span class="title">loader_dri3_get_buffers</span><span class="params">(__DRIdrawable *driDrawable,</span></div><div class="line">                        <span class="keyword">unsigned</span> <span class="keyword">int</span> format,</div><div class="line">                        <span class="keyword">uint32_t</span> *stamp,</div><div class="line">                        <span class="keyword">void</span> *loaderPrivate,</div><div class="line">                        <span class="keyword">uint32_t</span> buffer_mask,</div><div class="line">                        struct __DRIimageList *buffers)</div><div class="line">&#123;</div><div class="line">   ......</div><div class="line">   <span class="keyword">if</span> (!dri3_update_drawable(draw))</div><div class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line"></div><div class="line">   dri3_update_num_back(draw);</div><div class="line"></div><div class="line">   <span class="comment">/* Free no longer needed back buffers */</span></div><div class="line">   <span class="keyword">for</span> (buf_id = draw-&gt;num_back; buf_id &lt; LOADER_DRI3_MAX_BACK; buf_id++) &#123;</div><div class="line">      <span class="keyword">if</span> (draw-&gt;cur_blit_source != buf_id &amp;&amp; draw-&gt;buffers[buf_id]) &#123;</div><div class="line">         dri3_free_render_buffer(draw, draw-&gt;buffers[buf_id]);</div><div class="line">         draw-&gt;buffers[buf_id] = <span class="literal">NULL</span>;</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="comment">/* pixmaps always have front buffers.</span></div><div class="line">    * Exchange swaps also mandate fake front buffers.</div><div class="line">    */</div><div class="line">   <span class="keyword">if</span> (draw-&gt;is_pixmap || draw-&gt;swap_method == __DRI_ATTRIB_SWAP_EXCHANGE)</div><div class="line">      buffer_mask |= __DRI_IMAGE_BUFFER_FRONT;</div><div class="line"></div><div class="line">   <span class="keyword">if</span> (buffer_mask &amp; __DRI_IMAGE_BUFFER_FRONT) &#123;</div><div class="line">      <span class="comment">/* All pixmaps are owned by the server gpu.</span></div><div class="line">       * When we use a different gpu, we can't use the pixmap</div><div class="line">       * as buffer since it is potentially tiled a way</div><div class="line">       * our device can't understand. In this case, use</div><div class="line">       * a fake front buffer. Hopefully the pixmap</div><div class="line">       * content will get synced with the fake front</div><div class="line">       * buffer.</div><div class="line">       */</div><div class="line">      <span class="keyword">if</span> (draw-&gt;is_pixmap &amp;&amp; !draw-&gt;is_different_gpu)</div><div class="line">         front = dri3_get_pixmap_buffer(driDrawable,</div><div class="line">                                               format,</div><div class="line">                                               loader_dri3_buffer_front,</div><div class="line">                                               draw);</div><div class="line">      <span class="keyword">else</span></div><div class="line">         front = dri3_get_buffer(driDrawable,</div><div class="line">                                        format,</div><div class="line">                                        loader_dri3_buffer_front,</div><div class="line">                                        draw);</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (!front)</div><div class="line">         <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">   &#125; <span class="keyword">else</span> &#123;</div><div class="line">      dri3_free_buffers(driDrawable, loader_dri3_buffer_front, draw);</div><div class="line">      draw-&gt;have_fake_front = <span class="number">0</span>;</div><div class="line">   &#125;</div><div class="line">   ......</div><div class="line">   <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="0x25-glClear"><a href="#0x25-glClear" class="headerlink" title="0x25 glClear"></a>0x25 glClear</h2><p>glClear的调用堆栈如下，可以看到这个时候也需要分配buffer。</p>
<p><img src="/2020/05/30/EGL in Mesa/glClear.png" alt="EGL in Mesa"></p>
<h2 id="0x26-eglswapbuffer流程"><a href="#0x26-eglswapbuffer流程" class="headerlink" title="0x26 eglswapbuffer流程"></a>0x26 eglswapbuffer流程</h2><p><img src="/2020/05/30/EGL in Mesa/eglSwapBuffers.png" alt="EGL in Mesa"><br>通过调用相关的OpenGL ES API，把需要的绘制资源，如顶点数据(VBO/VAO等)，纹理资源(glTexImage2D)等准备好，mesa内部也构造好了对应GPU需要执行的command，这个时候可以启动GPU来绘制了。在函数submit_batch中通过调用DRM_IOCTL_I915_GEM_EXECBUFFER2 ioctl命令来启动kernel的绘制动作。</p>
<h2 id="0x27-egl驱动中实现的其他功能，如chooseConfig"><a href="#0x27-egl驱动中实现的其他功能，如chooseConfig" class="headerlink" title="0x27 egl驱动中实现的其他功能，如chooseConfig"></a>0x27 egl驱动中实现的其他功能，如chooseConfig</h2><p>这部分主要是软件逻辑，根据硬件平台的能力，对configure进行管理。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/26/About SceneGraph/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/26/About SceneGraph/" itemprop="url">About SceneGraph</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-04-26T20:10:10+09:00">
                2020-04-26
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2020/04/26/About SceneGraph/" class="leancloud_visitors" data-flag-title="About SceneGraph">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="0x1-什么是SceneGraph"><a href="#0x1-什么是SceneGraph" class="headerlink" title="0x1 什么是SceneGraph"></a>0x1 什么是SceneGraph</h1><p>渲染引擎需要解决的问题是如何把需要绘制的各种对象高效地组织起来并绘制出来，这其中很重要的概念是SceneGraph。目前各种渲染引擎包括2D UI引擎到3D引擎都实现了类似的概念。<br>其实SceneGraph应该称为SceneTree更合适，因为其中的数据组织一般是采用Tree的形式。</p>
<p>qt中采用的SceneGraph介绍如下<br><a href="https://doc.qt.io/qt-5/qtquick-visualcanvas-scenegraph.html" target="_blank" rel="external">https://doc.qt.io/qt-5/qtquick-visualcanvas-scenegraph.html</a></p>
<p>cocos2d也有类似的概念如下<br><a href="https://docs.cocos2d-x.org/cocos2d-x/v4/en/basic_concepts/scene.html" target="_blank" rel="external">https://docs.cocos2d-x.org/cocos2d-x/v4/en/basic_concepts/scene.html</a></p>
<p>ogre中对SceneGraph的介绍如下<br><a href="https://ogrecave.github.io/ogre/api/latest/_the-_core-_objects.html" target="_blank" rel="external">https://ogrecave.github.io/ogre/api/latest/_the-_core-_objects.html</a></p>
<h1 id="0x2-SceneGraph包括哪些功能"><a href="#0x2-SceneGraph包括哪些功能" class="headerlink" title="0x2 SceneGraph包括哪些功能"></a>0x2 SceneGraph包括哪些功能</h1><p>典型的SceneGraph包括了SceneManager，RenderManager，ResourceManager， Camera， RenderTarget，Animation， Particle子模块，下面来简单介绍一下这些概念。</p>
<p>SceneManager提供对场景图的组织和管理，具体可以采用二叉分割树，八叉树等。<br>RenderManager提供了绘制相关操作，也就是通常所说的各种Backend，如OpenGL,Directx,Metal,Vulkan等。<br>ResourceManager提供了对资源的管理，包括Material, Mesh等。<br>Camera提供了在SceneGraph中模拟眼睛的功能。<br>Viewer是在SceneGraph遨游时的眼睛，通过变化Camera的位置，我们可以看到SceneGraph中不同的风景。其中提供lookAt()类似的函数来指定场景中眼睛的位置。</p>
<h1 id="0x3-SceneGraph的设计"><a href="#0x3-SceneGraph的设计" class="headerlink" title="0x3 SceneGraph的设计"></a>0x3 SceneGraph的设计</h1><h2 id="0x31-数据结构设计"><a href="#0x31-数据结构设计" class="headerlink" title="0x31 数据结构设计"></a>0x31 数据结构设计</h2><p>渲染引擎一般采用场景节点和场景内容分离的机制，也就是说场景内容作为场景节点的成员变量，而不是把场景内容作为场景节点的子类。场景节点一般包含了类似位置，旋转等信息，场景内容指需要绘制的Mesh和渲染属性等。<br>另外一种实现方式是把场景内容作为场景节点的子类，这种实现方式把场景内容和场景节点耦合在一起，不利于添加新的场景内容的支持。<br>场景节点和场景内容分离机制带来了SceneGraph中数据松耦合的好处，场景内容添加到一个场景节点中，也可以从一个场景节点中移除。SceneManager控制的是场景节点，不需要关心具体的场景内容。我们可以精心设计场景节点的接口，这样可以保持SceneManager对场景节点的灵活控制。</p>
<p>下面是典型的SceneGraph数据结构图。</p>
<p><img src="/2020/04/26/About SceneGraph/Data_Structure.png" alt="Data_Structure"></p>
<p>SceneNode表示场景节点。<br>Object表示场景内容。一个Object可以包括多个RenderObject，如房间可以表示为一个Object，房间里的一张桌子是RenderObject。<br>RenderObject表示可被渲染的内容。RenderObject需要通过Mesh和Material来绘制。如前所述，一张桌子是RenderObject，然后我们需要知道桌子的Mesh，需要知道如何设置Mesh的渲染属性如shader，color等。</p>
<h2 id="0x32-场景图管理器"><a href="#0x32-场景图管理器" class="headerlink" title="0x32 场景图管理器"></a>0x32 场景图管理器</h2><p>场景图管理器实现的功能有，<br>第一类是数据对象管理相关的功能，包括如下功能。</p>
<ol>
<li><p>创建/删除SceneNode。</p>
</li>
<li><p>创建/删除Camera。</p>
</li>
<li><p>创建/删除各种Light。</p>
</li>
<li><p>创建/删除Object，前面提到Object作为场景内容节点挂接到SceneNode上。</p>
</li>
<li><p>创建删除各种绘制对象，设置各种绘制属性。</p>
</li>
<li><p>创建/删除ParticleSystem。</p>
</li>
<li><p>创建/删除AnimationSystem。</p>
</li>
</ol>
<p>另外是渲染流程相关功能，包括如下，</p>
<ol>
<li><p>查找当前Camera可见的渲染Object。</p>
</li>
<li><p>渲染前面查找到的渲染Object</p>
</li>
</ol>
<p>场景图管理器的结构图如下所示，<br><img src="/2020/04/26/About SceneGraph/SceneManager.png" alt="SceneManager"></p>
<p>Core下面的SceneManager提供了基本的框架和系统中其他模块交互，对应于具体的SceneManager而言，如上图所示的BspScenemanager和OctTreeSceneManager，其核心功能是解决如何高效地查找到当前Camera可见范围内的渲染Object，因为场景图中包括了很多数据，如在关卡游戏中，场景图中包括了很多游戏关卡，如果都去渲染，性能可能很差，所以通过SceneManager快速找到Camera可见范围内的渲染Object，然后只需要渲染这些Object。</p>
<h2 id="0x33-渲染管理器"><a href="#0x33-渲染管理器" class="headerlink" title="0x33 渲染管理器"></a>0x33 渲染管理器</h2><p>渲染管理器的结构图如下所示，<br><img src="/2020/04/26/About SceneGraph/RenderManager.png" alt="RenderManager"></p>
<p>渲染管理器也称为渲染的后端，这里来谈一下如何设计渲染管理器的接口使特定后端的代码量最少。也就是说如何把功能尽量放在Core中，Backend只保留特定平台相关的实现，这部分也是比较各种渲染引擎的跨平台技术做的好坏的评价标准之一。</p>
<p>RenderManager需要抽象出下面的模块作为通用的接口，这些是所有Backend都具备的特性，是公共的模块。在具体的Backend模块中中去继承这些接口从而实现各个Backend的对接。</p>
<ol>
<li><p>Texture操作接口。</p>
</li>
<li><p>HardwareBuffer操作接口，包括Index bufer/Vertex buffer/Uniform buffer/Texture buffer等。</p>
</li>
<li><p>Shader/Program操作接口。</p>
</li>
<li><p>DrawCall操作接口。</p>
</li>
</ol>
<h1 id="0x4-渲染流程设计及优化"><a href="#0x4-渲染流程设计及优化" class="headerlink" title="0x4 渲染流程设计及优化"></a>0x4 渲染流程设计及优化</h1><h2 id="0x41-数据准备"><a href="#0x41-数据准备" class="headerlink" title="0x41 数据准备"></a>0x41 数据准备</h2><p>绘制内容的设置<br>绘制内容包括各种资源，如Mesh，Skelton，Shader等。他们通过各种ReaourceManager加载进来。</p>
<p>绘制坐标的设置<br>如果SceneNode存在父子关系，有两种方法来设置绘制坐标，第一种是在生成绘制内容的时候，根据父节点的坐标计算好当前节点的坐标，然后设置到SceneNode中。另外一种方法是给SceneNode设置一个TransformNode作为SceneNode的成员，这个TransformNode是计算好的本地坐标系坐标(没有考虑父子关系)，这样在包括所有SceneNode的tree创建好了以后，再去从根节点开始遍历这颗树，根据父子关系，计算出每个SceneNode的世界坐标。具体实现中推荐采用第一种方法，因为如果SceneNode的层次太深，递归遍历节点的时候可能会出现栈溢出。</p>
<p>具有父子关系的SceneNode结构图如下所示。</p>
<p><img src="/2020/04/26/About SceneGraph/SceneNode_Strucutre.png" alt="SceneNode_Strucutre"></p>
<h2 id="0x42-数据绘制"><a href="#0x42-数据绘制" class="headerlink" title="0x42 数据绘制"></a>0x42 数据绘制</h2><p>场景绘制的完整流程如下，</p>
<p><img src="/2020/04/26/About SceneGraph/Rendering_Process.png" alt="Rendering_Process"></p>
<ol>
<li><p>首先是设置好场景数据，这些场景数据可以是通过离线工具如Blender，由美工来制作完成并导出，然后再加载进来。渲染引擎也可以提供在线实时生成场景数据的功能，如生成矩形，球形，立方体等。设置好的场景数据封装成RenderObject，再由RenderObject组成Object。</p>
</li>
<li><p>然后是需要把场景数据挂接到场景图的SceneNode中，这样场景图管理器就拥有了场景数据了，可以根据视点在场景图中执行查询等操作。</p>
</li>
<li><p>然后开始根据Camera的位置找到可见范围内的RenderObject，这个也就是前面提到的SceneManager发挥作用的地方，可以简单地称为Culling操作。</p>
</li>
<li><p>找到了需要渲染的RenderObject集合，可以对这些RenderObject的渲染顺序进行Bactch优化，如果两个RenderObject需要的渲染Maerial是一样地，可以合并成一个drawcall，这种优化方式我们称为动态Batch。如果由美工在素材制作阶段对场景数据的组织进行优化，把能用一个drawcall进行渲染的物体合并起来，这种优化被称为静态Batch。</p>
</li>
<li><p>优化好了以后就开始调用具体的Backend进行渲染了。</p>
</li>
</ol>
<h2 id="0x43-流程优化"><a href="#0x43-流程优化" class="headerlink" title="0x43 流程优化"></a>0x43 流程优化</h2><p>如下图所示，可以把渲染过程划分成两个线程并行处理，这样在数据加载阶段可以做上一帧的绘制动作，等数据加载完成再同步给渲染线程。</p>
<p><img src="/2020/04/26/About SceneGraph/Pipeline_Optimization.png" alt="Pipeline_Optimization"></p>
<p>另外一个优化是资源的异步加载，如果前面的Load Thread同时要响应用户操作，如果长时间在运行，会造成UI卡死，这个时候可以通过开启异步线程来处理。</p>
<h1 id="0x5-SceneGraph的发展方向思考"><a href="#0x5-SceneGraph的发展方向思考" class="headerlink" title="0x5 SceneGraph的发展方向思考"></a>0x5 SceneGraph的发展方向思考</h1><p>SceneGraph技术作为各种渲染引擎的根基，目前是很完善的技术了。包括光线跟踪渲染引擎，其中也包含了SceneGraph的实现。如果要考虑未来方向，是否可以和其他方向结合，如人工智能等？搞出一套智能的渲染引擎。如是否可以用CNN来加速特大场景图的可见渲染物体查询？</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/15/clDNN Introduction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/03/15/clDNN Introduction/" itemprop="url">clDNN Introduction</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-03-15T20:20:31+09:00">
                2020-03-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2020/03/15/clDNN Introduction/" class="leancloud_visitors" data-flag-title="clDNN Introduction">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="0x1-总体结构"><a href="#0x1-总体结构" class="headerlink" title="0x1 总体结构"></a>0x1 总体结构</h1><p>clDNN(Compute Library for Deep Neural Networks)是采用OpenCL来加速DNN(Deep Neural Networks)的framework。目标平台是Intel® HD and Iris™ Pro Graphics。clDNN目前已经是Intel OpenVINO的一部分。OpenVINO还包括了其它各种硬件平台的加速库，如CPU上的加速库mklDNN等。clDNN当然也可以改造成在NVIDIA和AMD的GPU上运行，虽然这个时候的性能可能需要进一步tuning。</p>
<p>clDNN对DNN中有关概念进行了抽象，其中有关数据类型的层次结构如下。</p>
<p><img src="/2020/03/15/clDNN Introduction/cldnn.png" alt=""></p>
<p>这些数据类型的定义简单说明如下。</p>
<p>Kernel - 算子计算的OpenCL实现。<br>Primitive - DNN中基本运算单元，如convolution, pooling, softmax等，也就是通常所说的算子。<br>Data - 特殊的算子，用来表示运算过程中的参数，如weights和biases, 也指DNN的输入和输出。<br>Engine - DNN中运行的加速器的类型，目前只有OpenCL engine一种。<br>Topology - 指DNN中的graph，其中包括了primitives, data和他们之间的关系。<br>Program - 位于Topology和Network之间(可选项)，是编译好的graph网络但是没有分配内存。<br>Network - 编译好的graph网络并且已经分配内存，可以运行，在编译网络的过程中，网络参数可以进行特殊的优化如fusing，data reordering等。</p>
<p>clDNN的执行<a href="https://intel.github.io/clDNN/index.html" target="_blank" rel="external">流程图</a>如下所示。</p>
<p><img src="/2020/03/15/clDNN Introduction/workflow.jpg" alt=""></p>
<p>执行过程包括下面的步骤<br>a.Create Engine.<br>b.Declare or define primitives parameters (weights and biases) if needed.<br>c.Create primitives. It is required to provide name for each primitive.<br>d.Create topology<br>e.Add primitives to topology<br>f.Build Network from topology<br>h.Set Inputs data<br>g.Execute Network</p>
<p>本文后续对这些过程进行详细的说明。</p>
<h1 id="0x2-LoadNetwork流程分析"><a href="#0x2-LoadNetwork流程分析" class="headerlink" title="0x2 LoadNetwork流程分析"></a>0x2 LoadNetwork流程分析</h1><p>   <img src="/2020/03/15/clDNN Introduction/loadnetwork.svg" alt=""><br>   LoadNetwork的执行流程如上图所示，下面详细来介绍一下其中涉及到的内容。</p>
<h2 id="0x21-kernel-selector"><a href="#0x21-kernel-selector" class="headerlink" title="0x21 kernel selector"></a>0x21 kernel selector</h2><p>  前面已经知道，clDNN是通过OpenCL来加速DNN的推理执行，就是说其中的算子是通过OpenCL来加速的，kernel就是指采用OpenCL内核实现的算子。<br>  kernel selector提供了如何选择最适合的kernel的接口，Primitive创建kernel的时候，调用kernel selector来得到最合适的kernel。</p>
<p>  上层不能直接操作OpenCL kernel，所以提供了对应的wrapper，这些wrapper都在下面这个目录中。<br>  inference-engine\thirdparty\clDNN\kernel_selector\core\actual_kernels<br>  另外wrapper还定义了kernel支持的输入和输出数据格式。</p>
<p>  对应的OpenCL kernel的定义都在这个目录下面。<br>  inference-engine\thirdparty\clDNN\kernel_selector\core\cl_kernels</p>
<p>  现在我们想知道OpenCL kernel是什么时候创建的呢？通过分析代码，我们可以知道OpenCL kernel的创建是在build_program的时候通过下面的循环来实现的。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">void</span> compile_graph::run(program_impl&amp; p) &#123;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; node : p.get_processing_order()) &#123;</div><div class="line">        <span class="keyword">if</span> (!node-&gt;is_type&lt;internal_primitive&gt;() &amp;&amp; !node-&gt;is_type&lt;data&gt;()) &#123;</div><div class="line">            node-&gt;get_output_layout();</div><div class="line">            <span class="keyword">if</span> (!node-&gt;is_type&lt;data&gt;() &amp;&amp; !(node-&gt;is_type&lt;mutable_data&gt;() &amp;&amp; node-&gt;get_dependencies().empty())) &#123;</div><div class="line">                node-&gt;selected_impl = node-&gt;type()-&gt;choose_impl(p.get_engine(), *node);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>上述代码中selected_impl的定义为primitive_impl类型的std::shared_ptr变量。<br>上述函数会调用到下面的create()函数。<br>这个函数再通过调用kernel_selector.GetBestKernels来创建最合适的OpenCL kernel。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">static</span> primitive_impl* <span class="title">create</span><span class="params">(<span class="keyword">const</span> scale_node&amp; arg)</span> </span>&#123;</div><div class="line">    ......</div><div class="line">    ew_params.layoutBased = <span class="literal">true</span>;</div><div class="line"></div><div class="line">    <span class="keyword">auto</span>&amp; kernel_selector = kernel_selector::eltwise_kernel_selector::Instance();</div><div class="line">    <span class="keyword">auto</span> best_kernels = kernel_selector.GetBestKernels(ew_params, ew_optional_params);</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> scale = <span class="keyword">new</span> scale_gpu(arg, best_kernels[<span class="number">0</span>]);</div><div class="line"></div><div class="line">    <span class="keyword">return</span> scale;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="0x22-primitive封装"><a href="#0x22-primitive封装" class="headerlink" title="0x22 primitive封装"></a>0x22 primitive封装</h2><p>primitive是对前面通过kernel selector取得的kernel的封装。<br>其中的primitive结构体都是通过typed_primitive_gpu_impl来定义的。</p>
<p>clDNN Library提供了下面这些<a href="https://intel.github.io/clDNN/index.html" target="_blank" rel="external">primitives</a>，</p>
<pre><code>Convolution
Fully connected (inner product)
Pooling
    average
    maximum
Normalization
    across channel
    within channel
    batch
Activation
    logistic
    tanh
    rectified linear unit (ReLU)
    softplus (softReLU)
    abs
    square
    sqrt
    linear
Softmax
Crop
Deconvolution
Depth concatenation
Eltwise
ROI pooling
Simpler NMS
Prior box
Detection output
</code></pre><p>通过对上述primitive的封装，clDNN提供了下面的topologies<br>    Alexnet<br>    Googlenet(v1-v3)<br>    ResNet<br>    VGG<br>    faster-rCNN and other.</p>
<h2 id="0x23-OpenCL接口的封装"><a href="#0x23-OpenCL接口的封装" class="headerlink" title="0x23 OpenCL接口的封装"></a>0x23 OpenCL接口的封装</h2><p>在目录inference-engine\thirdparty\clDNN\src\gpu\下面提供了OpenCL封装的代码，这些代码对OpenCL的底层api进行了封装，方便了clDNN其他模块的调用。</p>
<p>其中的gpu_queue类提供了对OpenCL command queue的封装，对外提供了command queue的创建和使用的接口。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">gpu_queue</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    ......</div><div class="line"><span class="keyword">private</span>:</div><div class="line">    <span class="keyword">uint32_t</span> id;</div><div class="line">    <span class="built_in">std</span>::weak_ptr&lt;gpu_toolkit&gt; _context;</div><div class="line">    cl::CommandQueue _command_queue;</div><div class="line">    <span class="built_in">std</span>::atomic&lt;<span class="keyword">uint64_t</span>&gt; _queue_counter&#123;<span class="number">0</span>&#125;;</div><div class="line">    <span class="built_in">std</span>::atomic&lt;<span class="keyword">uint64_t</span>&gt; _last_barrier&#123;<span class="number">0</span>&#125;;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;events_pool&gt; _events_pool;</div><div class="line">    cl::Event _last_barrier_ev;</div><div class="line">    <span class="keyword">bool</span> _output_event = <span class="literal">false</span>;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>gpu_toolkit类提供了OpenCL操作的统一接口，其他模块只需要调用gpu_toolkit就可以实现OpenCL的相关操作。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">gpu_toolkit</span> :</span> <span class="keyword">public</span> <span class="built_in">std</span>::enable_shared_from_this&lt;gpu_toolkit&gt; &#123;</div><div class="line">    ......</div><div class="line"><span class="keyword">private</span>:</div><div class="line">    configuration _configuration;</div><div class="line">    cl::Device _device;</div><div class="line">    cl::Context _context;</div><div class="line">    cl_platform_id _platform_id;</div><div class="line">    device_info_internal _device_info;</div><div class="line">    <span class="keyword">bool</span> _neo_driver = <span class="literal">false</span>;</div><div class="line">    kernels_cache _kernels_cache;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">map</span>&lt;<span class="keyword">uint32_t</span>, gpu_queue&gt; _command_queues_w;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;rapidjson::Document&gt; _device_cache;</div><div class="line">    kernels_binaries_container _binaries;</div><div class="line">    <span class="keyword">bool</span> _serialize = <span class="literal">false</span>;</div><div class="line"></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">string</span> _extensions;</div><div class="line"></div><div class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ocl_logger</span>;</span></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;ocl_logger&gt; _logger;</div><div class="line"></div><div class="line">    <span class="comment">// returns whether a barrier has been added</span></div><div class="line">    <span class="built_in">std</span>::<span class="function">ofstream&amp; <span class="title">open_log</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">    <span class="built_in">std</span>::<span class="function"><span class="built_in">string</span> <span class="title">get_device_version</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> _device.getInfo&lt;CL_DEVICE_VERSION&gt;(); &#125;</div><div class="line"></div><div class="line">    <span class="comment">// void build_command_queues();</span></div><div class="line">    <span class="function">gpu_queue&amp; <span class="title">get_command_queue</span><span class="params">(<span class="keyword">uint32_t</span> id)</span></span>;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h2 id="0x24-graph-optimizer"><a href="#0x24-graph-optimizer" class="headerlink" title="0x24 graph optimizer"></a>0x24 graph optimizer</h2><p>在build_program的时候会初始化graph，然后执行graph优化，包括pre_optimize_graph和post_optimize_graph。<br>执行步骤都是在下面的build_program函数中完成的。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">void</span> program_impl::build_program(<span class="keyword">bool</span> is_internal) &#123;</div><div class="line">    init_graph();</div><div class="line">    &#123; pre_optimize_graph(is_internal); &#125;</div><div class="line">    run_graph_compilation();</div><div class="line">    &#123; post_optimize_graph(is_internal); &#125;</div><div class="line">    prepare_memory_dependencies();</div><div class="line">    engine-&gt;compile_program(*<span class="keyword">this</span>);</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (!is_internal)</div><div class="line">        prim_info = get_current_stage_info();</div><div class="line"></div><div class="line">    cleanup();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>下面来分析一下pre_optimize_graph和post_optimize_graph分别是如何对graph进行优化的。<br>graph优化是通过调用apply_opt_pass来实现的。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">apply_opt_pass&lt;trim_to_outputs&gt;();</div></pre></td></tr></table></figure>
<p>apply_opt_pass是模板函数，模板参数trim_to_outputs是继承于base_pass的优化pass。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">trim_to_outputs</span> :</span> <span class="keyword">public</span> base_pass &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    trim_to_outputs() : base_pass(<span class="string">"trimmed"</span>) &#123;&#125;</div><div class="line"></div><div class="line"><span class="keyword">private</span>:</div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">(program_impl&amp; p)</span> override</span>;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>模板函数apply_opt_pass的定义如下。在模板函数中生成Pass对象，Pass对象的基类是base_pass，然后调用pass_manager的run函数执行优化操作。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">apply_opt_pass</span><span class="params">(base_pass&amp; pass)</span> </span>&#123; pm-&gt;run(*<span class="keyword">this</span>, pass); &#125;</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span> <span class="title">Pass</span>, <span class="title">typename</span>... <span class="title">Args</span>&gt;</span></div><div class="line"><span class="title">typename</span> <span class="title">std</span>::enable_if&lt;<span class="built_in">std</span>::is_base_of&lt;base_pass, Pass&gt;::value &amp;&amp;</div><div class="line">                        <span class="built_in">std</span>::is_constructible&lt;Pass, Args...&gt;::value&gt;::<span class="function">type</span></div><div class="line"><span class="title">apply_opt_pass</span><span class="params">(Args&amp;&amp;... args)</span> &#123;</div><div class="line">    <span class="keyword">auto</span> pass = Pass(<span class="built_in">std</span>::forward&lt;Args&gt;(args)...);</div><div class="line">    apply_opt_pass(pass);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>pass_manager的run函数定义如下。在run函数里会调用优化pass的run函数来执行具体的优化操作。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">void</span> pass_manager::run(program_impl&amp; p, base_pass&amp; pass) &#123;</div><div class="line">    ......</div><div class="line">    pass.run(p);</div><div class="line">    ......</div><div class="line">    pass_count++;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="0x25-program-node创建"><a href="#0x25-program-node创建" class="headerlink" title="0x25 program node创建"></a>0x25 program node创建</h2><p>program_node的定义如下，每一个program_node和一个primitive_impl相对应，primitive_impl是前面提到的OpenCL kernel函数的封装。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/*</span></div><div class="line">    Base class for all primitives which wraps API class and extends it to be used</div><div class="line">    in graph context.</div><div class="line">*/</div><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">program_node</span> &#123;</span></div><div class="line">    ......</div><div class="line"><span class="keyword">protected</span>:</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;primitive&gt; desc;</div><div class="line">    program_impl&amp; myprog;</div><div class="line"></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;primitive_impl&gt; selected_impl;</div><div class="line"></div><div class="line">    <span class="keyword">bool</span> valid_output_layout = <span class="literal">false</span>;</div><div class="line">    layout output_layout = layout(data_types::f32, format::bfyx, tensor());</div><div class="line"></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;program_node*&gt; dependencies;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">list</span>&lt;program_node*&gt; users;</div></pre></td></tr></table></figure>
<p>program_node的创建函数如下，创建好的node保存在nodes_map中。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// create all nodes from topology primitives, add dependencies among them and create inputs list</span></div><div class="line"><span class="keyword">void</span> program_impl::prepare_nodes(topology_impl <span class="keyword">const</span>&amp; topology) &#123;</div><div class="line">    <span class="keyword">auto</span> <span class="keyword">const</span>&amp; topo_map = topology.get_primitives();</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; prim : topo_map) &#123;</div><div class="line">        get_or_create(prim.second);</div><div class="line">    &#125;</div><div class="line">    ......</div><div class="line">&#125;</div><div class="line"></div><div class="line">program_node&amp; program_impl::get_or_create(<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;primitive&gt; prim) &#123;</div><div class="line">    <span class="keyword">auto</span> itr = nodes_map.lower_bound(prim-&gt;id);</div><div class="line">    <span class="keyword">if</span> (itr != nodes_map.end() &amp;&amp; itr-&gt;first == prim-&gt;id)</div><div class="line">        <span class="keyword">return</span> *itr-&gt;second;</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> new_node = prim-&gt;type-&gt;create_node(*<span class="keyword">this</span>, prim);</div><div class="line">    nodes_map.insert(itr, &#123;prim-&gt;id, new_node&#125;);</div><div class="line">    <span class="keyword">return</span> *new_node;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>typed_program_node是program_node的继承类，提供了对各种类型的program_node的封装。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">template</span> &lt;&gt;</div><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">typed_program_node</span>&lt;activation&gt; :</span> <span class="keyword">public</span> typed_program_node_base&lt;activation&gt; &#123;</div><div class="line">    <span class="keyword">using</span> parent = typed_program_node_base&lt;activation&gt;;</div><div class="line">    typed_program_node(<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;activation&gt; prim, program_impl&amp; prog) : parent(prim, prog) &#123;</div><div class="line">        support_padding_all(<span class="literal">true</span>);</div><div class="line">    &#125;</div><div class="line">    ......</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h1 id="0x3-Infer流程分析"><a href="#0x3-Infer流程分析" class="headerlink" title="0x3 Infer流程分析"></a>0x3 Infer流程分析</h1><p>前面网络加载好了以后，下面就开始真正的推理执行了，详细的流程如下。<br>   <img src="/2020/03/15/clDNN Introduction/infer.svg" alt=""><br>这个时候为了加速推理执行，如上图所示，采用了多线程的方法来提高执行的并行度，主线程把不同stage的task分配到不同的线程中去执行。<br>每个kernel执行的时候会调用enqueueNDRangeKernel来issue OpenCL驱动来执行计算。</p>
<p>我们知道一个推理网络执行的时候会有很多算子在执行，这些算子的执行在GPU上，如果每个算子执行完成以后都需要把结果从GPU读取到CPU中的话，效率会很低，这种执行模型如下所示，我们称之为sync执行模式。<br>   <img src="/2020/03/15/clDNN Introduction/execution_sync.png" alt=""></p>
<p>clDNN中采用的是如下图所示的async执行模型，各个算子之间的同步通过event来控制，每次算子执行完成以后，不需要把数据从GPU读取到CPU中。整个流程中只需要一次GPU buffer写入操作和一次GPU buffer读取操作。<br>   <img src="/2020/03/15/clDNN Introduction/execution_async.png" alt=""></p>
<p>下面是clDNN中enqueue kernel的代码。从代码中我们可以看到算子在每次执行enqueueNDRangeKernel的时候，需要等待一个算子执行完成的event被触发，这样算子之间的数据同步就不需要CPU的干预了。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line">event_impl::ptr gpu_queue::enqueue_kernel(cl::Kernel <span class="keyword">const</span>&amp; kern,</div><div class="line">                                          cl::NDRange <span class="keyword">const</span>&amp; global,</div><div class="line">                                          cl::NDRange <span class="keyword">const</span>&amp; local,</div><div class="line">                                          <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;event_impl::ptr&gt; <span class="keyword">const</span>&amp; deps) &#123;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;cl::Event&gt; dep_events;</div><div class="line">    <span class="keyword">auto</span> dep_events_ptr = &amp;dep_events;</div><div class="line">    <span class="keyword">if</span> (!context()-&gt;get_configuration().host_out_of_order) &#123;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; dep : deps)</div><div class="line">            <span class="keyword">if</span> (<span class="keyword">auto</span> ocl_ev = <span class="keyword">dynamic_cast</span>&lt;base_event*&gt;(dep.get()))</div><div class="line">                dep_events.push_back(ocl_ev-&gt;get());</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">        dep_events_ptr = <span class="literal">nullptr</span>;</div><div class="line"></div><div class="line">        sync_events(deps);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    cl::Event ret_ev;</div><div class="line"></div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        <span class="keyword">if</span> (!context()-&gt;get_configuration().host_out_of_order || _output_event ||</div><div class="line">            context()-&gt;get_configuration().enable_profiling) &#123;</div><div class="line">            _command_queue.enqueueNDRangeKernel(kern, cl::NullRange, global, local, dep_events_ptr, &amp;ret_ev);</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            _command_queue.enqueueNDRangeKernel(kern, cl::NullRange, global, local, dep_events_ptr, <span class="literal">nullptr</span>);</div><div class="line">        &#125;</div><div class="line">    &#125; <span class="keyword">catch</span> (cl::Error <span class="keyword">const</span>&amp; err) &#123;</div><div class="line">        <span class="keyword">throw</span> ocl_error(err);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> _events_pool-&gt;get_from_base_pool(context(), ret_ev, ++_queue_counter);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">void</span> gpu_queue::sync_events(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;event_impl::ptr&gt; <span class="keyword">const</span>&amp; deps) &#123;</div><div class="line">    <span class="keyword">bool</span> needs_barrier = <span class="literal">false</span>;</div><div class="line">    ......</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (needs_barrier) &#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            <span class="keyword">if</span> (_output_event)</div><div class="line">                _command_queue.enqueueBarrierWithWaitList(<span class="literal">nullptr</span>, &amp;_last_barrier_ev);</div><div class="line">            <span class="keyword">else</span></div><div class="line">                _command_queue.enqueueBarrierWithWaitList(<span class="literal">nullptr</span>, <span class="literal">nullptr</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (cl::Error <span class="keyword">const</span>&amp; err) &#123;</div><div class="line">            <span class="keyword">throw</span> ocl_error(err);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        _last_barrier = ++_queue_counter;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Kevin Wen" />
          <p class="site-author-name" itemprop="name">Kevin Wen</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">44</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">20</span>
                <span class="site-state-item-name">标签</span>
              
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Kevin Wen</span>
</div>


<div> <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
访问量 <span id="busuanzi_value_site_pv"></span>
访问人数 <span id="busuanzi_value_site_uv"></span>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("orq8xxsDQDXKiHdqSRcjlflB-gzGzoHsz", "ecCFdIcWDfbJKQOCiLFf1EBm");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  

  

  

</body>
</html>
