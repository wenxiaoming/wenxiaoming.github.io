<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta property="og:type" content="website">
<meta property="og:title" content="Kevin Wen&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Kevin Wen&#39;s Blog">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kevin Wen&#39;s Blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>Kevin Wen's Blog</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  















  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Kevin Wen's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/10/07/Neural network coding tool in VVC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/10/07/Neural network coding tool in VVC/" itemprop="url">Neural network coding tool in VVC</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-10-07T18:20:10+08:00">
                2020-10-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2020/10/07/Neural network coding tool in VVC/" class="leancloud_visitors" data-flag-title="Neural network coding tool in VVC">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="0x1-VVC"><a href="#0x1-VVC" class="headerlink" title="0x1 VVC"></a>0x1 VVC</h1><p>VVC是Versatile Video Coding的简写，也称为H.266，是下一代视频压缩标准，VVC已经于今年7月份完成标准的制定。VVC虽然没有突破传统的block based hybird的视频编码架构，但是借助于各种coding tools优化效果的累积效果，其编码效率比上一代视频压缩标准HEVC提升50%左右，也就是说VVC和HEVC达到相同的编码质量，VVC的码率能比HEVC节省50%。<br>对于VVC中的各种coding tools，笔者会在后续的文章中介绍。<br>本文介绍一下VVC标准中没有包含的一种coding tool，就是借助于Neural Network来优化视频压缩的方法。在VVC的多次会议的提案中都包括了借助于Neural Network来优化视频压缩的方法。至于这些提案最后没有进入标准，一个原因是这些方案的压缩效率提升不少很明显，而且适用范围有限。另外也可能和计算的复杂度有关，例如有些提案在CPU上的解码时间会增加好几倍。笔者觉得对于未来的视频标准(H.267?)来说，可能会采纳类似的方案，也许那个时候GPU解码会成为标配，为了追求极致的压缩效率，复杂度的增加也许会变得可以接受。</p>
<p>笔者分析了VVC提案中Neural Network的有关提案，发现基本集中在Loop Filter部分较多，这个和目前热门的Super Resolution技术解决的问题类似，也就是通过NN的方法把图像中失真的信息尽量还原回来，VVC中失真是指通过编码器量化过程以后，码流中包括的信息和源图像是有失真，而NN Filter可以很好的完整失真信息的还原。<br>另外VVC的提案中也包括了采用Neural Network来优化Intra Prediction和Rate Control编码效率的方案。</p>
<p>下面对VVC中有关Neural Network的提案进行总结归类。</p>
<h1 id="0x2-关于Neural-Network-based-Loop-Filter的提案"><a href="#0x2-关于Neural-Network-based-Loop-Filter的提案" class="headerlink" title="0x2 关于Neural Network based Loop Filter的提案"></a>0x2 关于Neural Network based Loop Filter的提案</h1><p>Neural Network based Loop Filter的提案又包括了下面这几种。</p>
<h2 id="0x21-JVET-I0022-Convolution-Neural-Network-Filter-CNNF-for-Intra-Frame"><a href="#0x21-JVET-I0022-Convolution-Neural-Network-Filter-CNNF-for-Intra-Frame" class="headerlink" title="0x21 JVET-I0022 Convolution Neural Network Filter (CNNF) for Intra Frame"></a>0x21 JVET-I0022 Convolution Neural Network Filter (CNNF) for Intra Frame</h2><h3 id="0x211-JVET-I0022-Convolution-Neural-Network-Filter-CNNF-for-Intra-Frame-Hikvision"><a href="#0x211-JVET-I0022-Convolution-Neural-Network-Filter-CNNF-for-Intra-Frame-Hikvision" class="headerlink" title="0x211 JVET-I0022 Convolution Neural Network Filter (CNNF) for Intra Frame (Hikvision)"></a>0x211 JVET-I0022 Convolution Neural Network Filter (CNNF) for Intra Frame (Hikvision)</h3><p>VCC中包括了BF/DF/SAO filter这几个传统filter，这几个filter的作用是remove artifacts or improve coding performance。<br>CNNF用于替换这些传统filter。<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-I0022.png" alt=""></p>
<p>网络结构如下图所示<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-I0022-network.png" alt=""></p>
<h3 id="0x212-JVET-J0043-Convolutional-Neural-Network-Filter-for-inter-frame-Hikvision"><a href="#0x212-JVET-J0043-Convolutional-Neural-Network-Filter-for-inter-frame-Hikvision" class="headerlink" title="0x212 JVET-J0043 Convolutional Neural Network Filter for inter frame (Hikvision)"></a>0x212 JVET-J0043 Convolutional Neural Network Filter for inter frame (Hikvision)</h3><p>为了避免over-filter造成artifacts，采用RDO方法来选择是采用传统的Filter还是CNN filter。选择filter的flag通过CABAC编码。<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-J0043.png" alt=""></p>
<h3 id="0x213-JVET-N0169-Convolutional-Neural-Network-Filter-CNNF-for-Intra-Frame-Hikvision"><a href="#0x213-JVET-N0169-Convolutional-Neural-Network-Filter-CNNF-for-Intra-Frame-Hikvision" class="headerlink" title="0x213 JVET-N0169 Convolutional Neural Network Filter (CNNF) for Intra Frame (Hikvision)"></a>0x213 JVET-N0169 Convolutional Neural Network Filter (CNNF) for Intra Frame (Hikvision)</h3><p>对CNNF放置在deblocking的不同位置的编码性能进行比较。<br>Comparison of intra decoding scheme between different positions of CNN filter<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-N0169.png" alt=""></p>
<p>优化结论如下。<br>Driven by the advances of deep learning, a CNN-based filter for intra frame is proposed to remove the artifacts. Simulation results report -3.48%, -5.18%, -6.77% BD-rate savings for luma, and both chroma components for VTM-4.0 with AI configuration as the CNNF before the SAO. As the DF and SAO are turned off, the CNNF brings -4.65%, -6.73%, -7.92% BD-rate savings with ALF behind. Even though all the conventional filters are turned off, the CNNF still brings 4.14%, -5.49%, -6.70% BD-rate savings. </p>
<h3 id="0x214-JVET-K0158-Separable-Convolutional-Neural-Network-Filter-with-Squeeze-and-Excitation-block-Sharp"><a href="#0x214-JVET-K0158-Separable-Convolutional-Neural-Network-Filter-with-Squeeze-and-Excitation-block-Sharp" class="headerlink" title="0x214 JVET-K0158 Separable Convolutional Neural Network Filter with Squeeze-and-Excitation block(Sharp)"></a>0x214 JVET-K0158 Separable Convolutional Neural Network Filter with Squeeze-and-Excitation block(Sharp)</h3><p>对JVET-I0022进行进一步优化，减少CNN网络参数，可以达到和JVET-I0022类似的编码优化效果。</p>
<h2 id="0x22-JVET-K0222-Convolution-neural-network-loop-filter-MediaTek"><a href="#0x22-JVET-K0222-Convolution-neural-network-loop-filter-MediaTek" class="headerlink" title="0x22 JVET-K0222 Convolution neural network loop filter (MediaTek)"></a>0x22 JVET-K0222 Convolution neural network loop filter (MediaTek)</h2><p>设计了CNN Loop Filter，对reconstructed samples进行loop filter处理。<br>如下描述，这个CNN的parameter是在encoder的过程中通过online的方式生成的。 不像其他几种提案完全是通过offline的方式来生成。<br>only those pictures with temporal ID equal to 0 or 1 are used to derive CNNLF parameters in the training process. That is, only these pictures are required to be encoded twice. The first round is to generate the required data for CNNLF training process and derive the CNNLF parameters. The second round is to generate the final bitstream by enabling CNNLF with the derived parameters.</p>
<p>如下图所示，这个CNNLF添加在adaptive loop filter (ALF)的后面, CNNLF的输入是ALF输出的reconstructed samples。CNNLF的输出被称为 restored samples.</p>
<p><img src="/2020/10/07/Neural network coding tool in VVC/JVET-K0222.png" alt=""></p>
<p>JVET-M0159, Convolutional neural network loop filter  (MediaTek)<br>其对K0222进行了优化，主要是简化NN网络。JVET-M0159和JVET-K0222的差异如下。</p>
<p><img src="/2020/10/07/Neural network coding tool in VVC/JVET-M0159.png" alt=""></p>
<h2 id="0x23-JVET-K0391-Dense-Residual-Convolutional-Neural-Network-based-In-Loop-Filter-Tencent-WHU"><a href="#0x23-JVET-K0391-Dense-Residual-Convolutional-Neural-Network-based-In-Loop-Filter-Tencent-WHU" class="headerlink" title="0x23 JVET-K0391 Dense Residual Convolutional Neural Network based In-Loop Filter (Tencent, WHU)"></a>0x23 JVET-K0391 Dense Residual Convolutional Neural Network based In-Loop Filter (Tencent, WHU)</h2><p>在SAO前面加入dense residual convolutional network based in-loop filter (DRNLF)</p>
<p>In-loop filters, such as DF (deblocking filter), sample adaptive offset (SAO), are employed in VTM for suppressing compression artifacts, which contributes to coding performance improvement.<br>In this contribution, the proposed DRNLF is introduced as an additional filter before SAO</p>
<p>Proposed decoding scheme in VTM<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-K0391.png" alt=""></p>
<p>JVET-L0242 Dense Residual Convolutional Neural Network based In-Loop Filter(Tencent, WHU)<br>JVET-L0242对JVET-K0391进一步优化，减少了NN网络的参数。另外为了防止over-filter，采用如下图所示的RDO方法来决策是否采用DRN。</p>
<p><img src="/2020/10/07/Neural network coding tool in VVC/JVET-L0242.png" alt=""></p>
<h2 id="0x24-JVET-L383-Convolution-Neural-Network-Filter-KDDI"><a href="#0x24-JVET-L383-Convolution-Neural-Network-Filter-KDDI" class="headerlink" title="0x24 JVET-L383 Convolution Neural Network Filter(KDDI)"></a>0x24 JVET-L383 Convolution Neural Network Filter(KDDI)</h2><p>提案也是采用Convolution Neural Network Filter去替换目前的multiple filter such as deblocking filter (DBF), sample adaptive offset (SAO) and adaptive loop filter (ALF)。另外CNN Filter参数在encoder端和decoder端是相同的。</p>
<p>优化结论如下。<br>The simulation results show the BD-rate for luma is -0.93% for AI where CNNF is replaced by DBF, SAO and ALF though the BD-rate is -2.21% for AI where CNNF is replaced by DBF and SAO only.<br>The filter structure is shown in Figure 1. This filter has four layers with 3x3 taps. The input of sum block is residual signal from the left and reconstructed signal before all in-loop filters from the bottom. The output of sum block is filtered pixels. Actual output is weighted sum of after filtered and before filtered pixels based on the distance of edge.</p>
<p>提出的CNNF的结构图如下所示。<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-L383.png" alt=""></p>
<h2 id="0x25-JVET-M0510-CNN-based-In-Loop-Filter-proposed-by-USTC"><a href="#0x25-JVET-M0510-CNN-based-In-Loop-Filter-proposed-by-USTC" class="headerlink" title="0x25 JVET-M0510  CNN-based In-Loop Filter proposed by USTC"></a>0x25 JVET-M0510  CNN-based In-Loop Filter proposed by USTC</h2><p>这个提案中提出的CNN filter具有如下特点。</p>
<ol>
<li>Lightweight deep convolutional neural networks</li>
<li>Locate between DF and SAO</li>
<li>-0.96%, -0.32%, -0.45% BD-rate savings for Y, Cb, and Cr components compared with VTM3.0 under AI configuration</li>
</ol>
<h2 id="0x26-JVET-M0566-Adaptive-convolutional-neural-network-loop-filter-Intel"><a href="#0x26-JVET-M0566-Adaptive-convolutional-neural-network-loop-filter-Intel" class="headerlink" title="0x26 JVET-M0566  Adaptive convolutional neural network loop filter (Intel)"></a>0x26 JVET-M0566  Adaptive convolutional neural network loop filter (Intel)</h2><p>该提案提出了ACNNLF的设计，通过online training的方式得到3 CNN based loop filters。每个filter都是a small 2 layer CNN with total 692 parameters。在编码过程中为每个CTB的luma、chroma选择3个ACNNLFs之一作为loop filter。这三个ACNNLFs的网络参数会被写入到slice header中，然后每个CTB要选择哪个ACNNLF的话，只需要一个index指定到slice header的ACNNLFs的网络参数即可。</p>
<p>ACNNLF在解码流程中的位置如下图所示。<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-M0566.png" alt=""></p>
<p>下面说明了ACNNLF的设计思想，主要体现了adaptive的online training的思想。<br>The ALF filter can be considered as a special one-layer CNN with linear activation. However, the number of filter coefficients in an ALF filter is too small to capture relevant features in the video. In order to match different video content, many ALF filters are used. Therefore, ALF makes up the deficiency of small number of filter coefficients by increasing the number of filter classes used.<br>As we try to further reduce the number of CNNLF parameters, we increase the number of CNNLFs to choose from to ensure the design can adapt to diverse video content without sacrificing performance. In this document, we propose an ACNNLF design: </p>
<ol>
<li>Small Deep-CNN loop filter with minimum number of hidden layers (2 CNN layers);</li>
<li>3 set of CNN loop filters trained online for luma and chroma respectively to better adapt to the content.<br>Since the number of ACNNLF filters (3) is small, it is possible to conduct exhaustive search for the optimal ACNNLF in the encoding process. The ACNNLF selection is indicated in the coded stream to the decoder. ACNNLF is applied after ALF in the decoding process.   </li>
</ol>
<p>采用了ACNNLF的优化结论如下。<br>This contribution presents an ACNNLF design with 3 classes of CNN based loop filters, where each filter has only 2 CNN layers and 692 parameters. The 3 ACNNLFs are adaptively trained with video sequence data. The best ACNNLF is selected for luma and chroma respectively for each CTB at encoder and indicated to decoder in coded stream with 2 bit indicator at CTB level. Compared with VTM-4.0-RA, the proposed ACNNLF achieves -1.14%, -0.21%, and -1.18% BD-rates for Y, U, and V, respectively, for Class A1 video sequences; -0.98%, -14.37%, and -16.96% BD-rates for Y, U, and V, respectively, for Class A2 video sequences; -0.55%, -21.79%, and -20.04% BD-rates for Y, U, and V, respectively, for Class B video sequences; and 0.09%, -2.75%, and -1.43% BD-rates for Y, U, and V, respectively, for Class C video sequences. The decoding time in the RA is 127% on VTM 4.0. </p>
<h2 id="0x27-JVET-O0079-Integrated-in-loop-filter-based-on-CNN-Tests-2-1-2-2-and-2-3"><a href="#0x27-JVET-O0079-Integrated-in-loop-filter-based-on-CNN-Tests-2-1-2-2-and-2-3" class="headerlink" title="0x27 JVET-O0079  Integrated in-loop filter based on CNN (Tests 2.1, 2.2 and 2.3)"></a>0x27 JVET-O0079  Integrated in-loop filter based on CNN (Tests 2.1, 2.2 and 2.3)</h2><p>Northwestern Polytechnical University (NPU), Xidian University, Guangdong OPPO Mobile Telecommunications Corp., Ltd</p>
<p>提出采用WSE-CNNLF(Wide-activated Squeeze-and-Excitation Convolutional Neural Network Loop Filter)作为in loop filter，具有下面的特点。</p>
<ol>
<li>It includes six inputs: three reconstructed components (Y, U, V) and three auxiliary inputs (QPmap, CUmap for luma, CUmap for chroma).</li>
<li>It consists of three stages to make the luma and chroma components jointly processed and separately fused with the corresponding CUmap before generating outputs.</li>
<li>It can replace and even outperform the multiple filters in current VVC. </li>
</ol>
<p>Main structure of the proposed CNNLF<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-O0079.png" alt=""></p>
<p>该提案的优化结论如下。<br>For test 2.1, it can be seen that converting weights from 32bit-float to 8bit-int leads to lower gains (from -0.46% to 0.79% for BD-rate saving on luma).<br>For test 2.2, in AI configuration, the BD-rate saving on luma of in-loop filter (-3.93%) is higher than that of post filter (-3.05%). In RA configuration, the BD-rate saving on luma of post filter (-1.89%) is higher than that of in-loop filter (-0.26%). It is noted that the proposed NN filter completely replaces the original in-loop filter (i.e., DBF+SAO+ALF ) when test 2.2a is performed to evaluate the in-loop situation, while it is added as a post filter with DBF+SAO+ALF all on in 2.2.b. It is concluded that the proposed NN filter reportedly outperforms DBF+SAO+ALF if used as the only in-loop filter, and is also useful if used as an extra post-loop filter.<br>For test 2.3, it’s shown that the proposed WSE-CNNLF has generalization capability on higher QP. The BD-rate saving is -0.46%, -4.11%, -2.80% when the test QP is the same as training QP, and -1.52%, -6.15%, -4.31% when the test QP equals to training QP+5. The CNN-based loop filter seems to be more effective on lower video qualities.</p>
<h1 id="0x3-采用Neural-Network来加速CTU-partition加速和优化编码效率"><a href="#0x3-采用Neural-Network来加速CTU-partition加速和优化编码效率" class="headerlink" title="0x3 采用Neural Network来加速CTU partition加速和优化编码效率"></a>0x3 采用Neural Network来加速CTU partition加速和优化编码效率</h1><p>JVET-J0034 CNN-based driving of block partitioning for intra slices encoding</p>
<p>该提案的算法描述如下。</p>
<p>for driving the encoder by estimating probabilities of blocks or Coding Units (CU) splitting in intra slices. The approach is primarily based on a texture analysis of the original blocks, and partly replaces the costly Rate Distortion Optimization (RDO) potentially involved for testing all potential partitioning configurations.</p>
<p>Overview of the split prediction process<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-J0034-split.png" alt=""></p>
<p>This module precedes the usual RDO process, and pre-selects the split configurations to be tested by the RDO. It is composed of the following 3 steps:</p>
<ol>
<li>CNN-based analysis – In the first step, each input 65×65 patch is analyzed by a CNN-based texture analyzer. The output of this step consists in a vector of probabilities associated to each one of the elementary boundaries that separate elementary sub-blocks. Figure 2 illustrates the mapping between elementary boundary locations and the vector of probabilities. The size of elementary blocks being 4×4, the vector contains n=480 probability values. The CNN is described in section 3.</li>
<li>Probable split selection – The second step takes as input the probability of each elementary boundary and outputs a first set of splitting modes among all possible options, which are: no split, QT, BT (vertical, horizontal), ABT (top, bottom, left, right). This step is further detailed in section 4.1.</li>
<li>Encoder constraints and speed-ups –  The third step selects the final set of splitting modes to be checked by classical RDO, depending on the first set provided by step 2, the contextual split constraints described in JVET-J0022 section 3.1.1.3 and the encoder speed-ups described in JVET-J0022, section 3.1.2.1. This step is further detailed in section 4.2.</li>
</ol>
<p>该提案的优化结论如下。<br>在AI configuration情况下，在相关的编码时间情况下，比基准(JEM7)取得6%的BD-rate gain，在相同的BD-rate gain情况下，编码时间可以减少4.3倍。<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-J0034-perf.png" alt=""></p>
<h1 id="0x4-采用Neural-Network来优化Intra-Prediction"><a href="#0x4-采用Neural-Network来优化Intra-Prediction" class="headerlink" title="0x4 采用Neural Network来优化Intra Prediction"></a>0x4 采用Neural Network来优化Intra Prediction</h1><p>JVET-J0037 Intra prediction modes based on neural networks</p>
<p>如下图所示，通过NN的方法来得当前Intra block的预测像素值。<br>Prediction of MxN intra block from reconstructed samples using a neural network<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-J0037-sample.png" alt=""></p>
<p>如下图所示，通过NN的方法来得当前Intra block的预测mode值。<br>Prediction of mode probabilities from reconstructed samples using a neural network<br><img src="/2020/10/07/Neural network coding tool in VVC/JVET-J0037-mode.png" alt=""></p>
<h1 id="0x5-采用Neural-Network来优化Rate-Control"><a href="#0x5-采用Neural-Network来优化Rate-Control" class="headerlink" title="0x5 采用Neural Network来优化Rate Control"></a>0x5 采用Neural Network来优化Rate Control</h1><p>JVET-M0215 CNN-based lambda-domain rate control for intra frames</p>
<p>This contribution proposes a CNN-based λ-domain rate control approach for intra frame coding. Compared with the exiting SATD-based intra rate control approach in VTM, we reuse the R-lambda model in VTM inter frame rate control and train one convolutional neural network to simultaneously predict the two model parameters, alpha and beta. Compared with the rate control method in VTM 3.0, the proposed method can achieve an average bd-rate reduction of 1.8% under All Intra configuration. When considering the mismatch between target bitrate and actually coded bit rate, the CNN-based method can achieve a smaller rate control error, especially for the first I frame.</p>
<p>通过下面的NN网络训练得到两个参数，这两个参数作为Rate Control的后续输入参数。</p>
<p>We propose to reuse the   model and train one convolutional neural networks to simultaneously predict the two parameters. The network architecture is depicted in Fig.1. Specifically, before the encoding for one Intra frame, we extract the luma component, as well as the chroma components of each CTU and feed them into the two trained CNN, from the CNN output we can obtain the corresponding  and   for each CTU. </p>
<p>CNN-based rate control的网络结构图如下所示，从图中可以看到是用一个网络来预测两个参数。</p>
<p><img src="/2020/10/07/Neural network coding tool in VVC/JVET-M0215.png" alt=""></p>
<h1 id="0x6-有关Neural-Network的参数传递"><a href="#0x6-有关Neural-Network的参数传递" class="headerlink" title="0x6 有关Neural Network的参数传递"></a>0x6 有关Neural Network的参数传递</h1><p>JVET-N0065 Comments on carriage of coding tool parameters in Adaptation Parameter Set</p>
<p>采用Adaptation Parameter Set (APS)用于动态传输neural network的参数。</p>
<p>In 13th JVET meeting, Adaptation Parameter Set (APS) has been introduced into Versatile Video Coding (VVC) standard text. A few years ago, the APS was once adopted into High Efficiency Video Coding (HEVC) standard for carrying coding tool parameters, such as Adaptive Loop Filter (ALF) parameters; but the APS was removed from HEVC standard along with the removal of ALF as a coding tool at a final HEVC standardisation stage. The APS was designed to carry coding tool parameters as a picture level adaptive nature and alternatively the APS data can also be maintained as unchanged for the whole video sequence for avoiding resending them unnecessarily. This contribution is for information only and it is commented and recommended to use the APS to carry the coding tool data, such as neural networks parameters and affine linear weighted intra prediction parameters, etc., if some associated coding tools are indeed to be adopted into VVC standard. If more coding tool data need to be carried by APS in the future, it commented that further study on updating parameters of multiple tools using APS would be needed.</p>
<p>It is recommended that APS can be considered as the carrier for coding tool parameters, such as neural networks coding parameters, etc., to convey these parameters in bitstreams to a VVC decoder. When more types of coding tool parameters are needed to be carried by APS, updating parameters of multiple tools using APS would need to be further studied for achieving more efficient use of the APS.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/06/28/Intel vulkan driver introduction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/06/28/Intel vulkan driver introduction/" itemprop="url">Intel vulkan driver introduction</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-06-28T19:10:10+08:00">
                2020-06-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2020/06/28/Intel vulkan driver introduction/" class="leancloud_visitors" data-flag-title="Intel vulkan driver introduction">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="0x1-Overview"><a href="#0x1-Overview" class="headerlink" title="0x1 Overview"></a>0x1 Overview</h1><p>As we know, mesa has supported vulkan driver for four different platforms, these four platforms are Intel，AMD，Qualcomm Adreno，Broadcom V3D. Currently vulkan driver support in mesa is not using Gallium architecture like OpenGL，its architecture seems child stage, the four vulkan drivers don’t have much shared common codes, the abstraction of the four vulkan drivers is the architecture optimization of mesa vulkan driver in the next stage.It has widely discussed in the mesa dev community.And the coming optimized architecture will accelerate the supporting for more GPU platforms like Mali GPU and Imagination GPU.</p>
<p><img src="/2020/06/28/Intel vulkan driver introduction/vulkan_driver_of_mesa.png" alt=""></p>
<p>In this article, I will show you how Intel Vulkan driver is supported in mesa.</p>
<p>Let’s have a look of Intel GEN GPU hardware architecture.</p>
<p>The following diagram is about the hardware block of the <a href="http://kiwitree.net/~chadv/intel-gfx-docs/prm/gen11.0-icl/intel-gfx-prm-osrc-icllp-vol09-renderengine_0.pdf" target="_blank" rel="external">Intel GEN GPU</a></p>
<p><img src="/2020/06/28/Intel vulkan driver introduction/GPU-block.png" alt=""><br><img src="/2020/06/28/Intel vulkan driver introduction/GPU-block1.png" alt=""></p>
<p>Here is the 3D pipeline block of <a href="https://01.org/sites/default/files/documentation/snb_ihd_os_vol2_part1_0.pdf" target="_blank" rel="external">Intel Gen GPU</a>. the left part is the 3D pipleine, the right part is the GPU hardware block.</p>
<p><img src="/2020/06/28/Intel vulkan driver introduction/GPU-pipeline.png" alt=""><br><img src="/2020/06/28/Intel vulkan driver introduction/GPU-pipeline1.png" alt=""></p>
<p>The GPU driver (userspace and kernel space) will configure the above hardware block according to graphics API’s input, then trigger gpu hardware to execute as its configuration. So GPU driver’s task is simple, just to configure the GPU hardware!</p>
<h1 id="0x2-Component-overview"><a href="#0x2-Component-overview" class="headerlink" title="0x2 Component overview"></a>0x2 Component overview</h1><p>We know mesa includes several abstraction layers. it supports different graphics api,different compiler frontend, different gpu hardware code generation.</p>
<p>In mesa, Intel vulkan driver’s module name is ANV.Here is the diagram about how ANV driver is built from different sub component.<br><img src="/2020/06/28/Intel vulkan driver introduction/component_overview.png" alt=""></p>
<p>And here is the relationship of intel vulkan driver library and its dpendencies.<br><img src="/2020/06/28/Intel vulkan driver introduction/component_overview_1.png" alt=""></p>
<h1 id="0x3-Mem-interface"><a href="#0x3-Mem-interface" class="headerlink" title="0x3 Mem interface"></a>0x3 Mem interface</h1><p>GPU harware needs serveral input data for further processing, like vertex buffer, texture buffer, uniform buffer and surface, these buffer will be accessed by CPU and GPU together. so mesa should provide interface to alloc/release buffer, set these buffer’s address to GPU hardware then issue hardware to execute it.</p>
<p>Let’s have brief explanation about how buffer alloc/release happen in ANV vulkan driver.</p>
<p>Here is the sequence about allocating gem buffer.</p>
<p><img src="/2020/06/28/Intel vulkan driver introduction/gem_alloc.png" alt=""></p>
<p>Here is the sequence about releasing buffer.</p>
<p><img src="/2020/06/28/Intel vulkan driver introduction/gem_release.png" alt=""></p>
<p>Here is the sequence about issuing command to kernel driver.</p>
<p><img src="/2020/06/28/Intel vulkan driver introduction/gem_execbuffer.png" alt=""></p>
<p>For performance optimization, ANV can use a cache mechansim to boost the performance since the memory alloc/release is resource heavy operation. In broadcom close source v3d driver, it uses a similar mechansim like linux slab to cache buffer in userland driver.</p>
<h1 id="0x4-Typical-objects-in-vulkan"><a href="#0x4-Typical-objects-in-vulkan" class="headerlink" title="0x4 Typical objects in vulkan"></a>0x4 Typical objects in vulkan</h1><p>Here are several important objects of vulkan concepts. RenderPass object and ShaderModule object are passed to Pipeline through VkGraphicsPipelineCreateInfo when creating Pipeline object. then Pipeline is binded to CommandBuffer using VkCmdBindPipeline api, after that the commanbuffer can use the passing Pipeline object, RenderPass object and ShaderModule object.<br><img src="/2020/06/28/Intel vulkan driver introduction/architecture.png" alt=""></p>
<h1 id="0x5-GPU-codegen"><a href="#0x5-GPU-codegen" class="headerlink" title="0x5 GPU codegen"></a>0x5 GPU codegen</h1><p>Here is the diagram about generating gpu code from SPIRV code.<br><img src="/2020/06/28/Intel vulkan driver introduction/spirv_to_nir_to_gpucode.png" alt=""></p>
<p>The gpu code is the code which will run on Intel GPU’s EUs(execution unit), it is programmable shader unit, likes broadcom v3d’s QPU.</p>
<p>The input of the pipeline is SPIRV code, the SPIRV format is the standard IR for different shader formats like glsl,opencl. </p>
<p>Then ANV driver will convert it to mesa internal IR format(NIR) code.</p>
<p>Then it will be optimized by different passes, this idea is similar as other compiler’s optimization passes.</p>
<p>The last step is gpu code generation.It uses typical graphic coloring algorithm. at this stage,we must read the GPU programmer guide carefully,then learn how to generate effective code for intel gen gpu.</p>
<h1 id="0x6-Framebuffer-dump"><a href="#0x6-Framebuffer-dump" class="headerlink" title="0x6 Framebuffer dump"></a>0x6 Framebuffer dump</h1><p>This feature is useful for us to check the render result in the framebuffer. it is similar as we can use glReadPixels to read back framebuffer’s content on OpenGL.</p>
<p>Currently mesa’s anv dump code has bug to blit framebuffer to write image, and I have fixed it to make this feature can work well.</p>
<p>Here is the diagram about how to dump framebuffer.<br><img src="/2020/06/28/Intel vulkan driver introduction/anv_dump.png" alt=""></p>
<p>It uses gdb call method to dump data, here is the use instruction about it.</p>
<ul>
<li>To dump the framebuffers of an application after each render pass, all you</li>
<li>have to do is the following<br>*</li>
<li>1) Start the application in GDB</li>
<li>2) Run until you get to the point where the rendering errors occur</li>
<li>3) Pause in GDB and set a breakpoint in anv_QueuePresentKHR</li>
<li>4) Continue until it reaches anv_QueuePresentKHR</li>
<li>5) Call anv_dump_start(queue-&gt;device, ANV_DUMP_FRAMEBUFFERS_BIT)</li>
<li>6) Continue until the next anv_QueuePresentKHR call</li>
<li>7) Call anv_dump_finish() to complete the dump and write files</li>
</ul>
<p>Here is the dump result with the above method.<br><img src="/2020/06/28/Intel vulkan driver introduction/anv_dump_result.png" alt=""></p>
<h1 id="0x7-Hardware-state-dump"><a href="#0x7-Hardware-state-dump" class="headerlink" title="0x7 Hardware state dump"></a>0x7 Hardware state dump</h1><p>It uses preload method to hook api, the hook api will dump state to a file.</p>
<p>Here is the diagram about it.<br><img src="/2020/06/28/Intel vulkan driver introduction/intel_gpu_dump.png" alt=""></p>
<p>Here is the gdb command for capturing data</p>
<p>gdb -iex “set exec-wrapper env LD_PRELOAD=/home/kevin/mesa/mesa_build_vulkan/libexec/libintel_dump_gpu.so INTEL_DUMP_GPU_CONFIG=/home/kevin/mesa/test_intel_dump_gpu/dump_config” –args “/home/kevin/vulkan/build/bin/multithreading”</p>
<p>Then we can use Aubinator Viewer to check the dumped states. please notice that this dump mechansim is also working for Opengl case, and the dump items are the same as Vulkan’s since the dump is for getting content of gpu hardware statue.</p>
<p>The dump item shows what vulkan driver program the hardware. we can see the following states’s content like 3DSTATE_VS and other states.</p>
<p><img src="/2020/06/28/Intel vulkan driver introduction/intel_gpu_dump_result.png" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/30/EGL in Mesa/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/05/30/EGL in Mesa/" itemprop="url">EGL in Mesa</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-30T18:10:10+08:00">
                2020-05-30
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2020/05/30/EGL in Mesa/" class="leancloud_visitors" data-flag-title="EGL in Mesa">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="0x1-EGL介绍"><a href="#0x1-EGL介绍" class="headerlink" title="0x1 EGL介绍"></a>0x1 EGL介绍</h1><p>我们知道通过OpenGL来绘制的时候需要和EGL配合才能完成渲染，本文主要来介绍一下mesa中的EGL驱动实现。下面先来简单介绍一下EGL。<br>EGL用于管理绘图表面，其主要提供了下列几种功能，</p>
<p>a 与设备平台的原生窗口系统进行交互。</p>
<p>b 查询可用的绘制类似和相关配置。</p>
<p>c 创建和管理绘制surface。</p>
<p>d 创建和管理绘制context。</p>
<p>e 提供present接口eglSwapBuffers，一般通过交换前后缓存区来实现。</p>
<p>EGL驱动中包括了对下面这些EGL API的封装，应用调用这些API来和EGL驱动交互。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line">eglBindAPI</div><div class="line">eglBindTexImage</div><div class="line">eglChooseConfig</div><div class="line">eglClientWaitSync</div><div class="line">eglCopyBuffers</div><div class="line">eglCreateContext</div><div class="line">eglCreateImage</div><div class="line">eglCreatePbufferFromClientBuffer</div><div class="line">eglCreatePbufferSurface</div><div class="line">eglCreatePixmapSurface</div><div class="line">eglCreatePlatformPixmapSurface</div><div class="line">eglCreatePlatformWindowSurface</div><div class="line">eglCreateSync</div><div class="line">eglCreateWindowSurface</div><div class="line">eglDestroyContext</div><div class="line">eglDestroyImage</div><div class="line">eglDestroySurface</div><div class="line">eglDestroySync</div><div class="line">eglGetConfigAttrib</div><div class="line">eglGetConfigs</div><div class="line">eglGetCurrentContext</div><div class="line">eglGetCurrentDisplay</div><div class="line">eglGetCurrentSurface</div><div class="line">eglGetDisplay</div><div class="line">eglGetError</div><div class="line">eglGetPlatformDisplay</div><div class="line">eglGetProcAddress</div><div class="line">eglGetSyncAttrib</div><div class="line">eglInitialize</div><div class="line">eglMakeCurrent</div><div class="line">eglQueryAPI</div><div class="line">eglQueryContext</div><div class="line">eglQueryString</div><div class="line">eglQuerySurface</div><div class="line">eglReleaseTexImage</div><div class="line">eglReleaseThread</div><div class="line">eglSurfaceAttrib</div><div class="line">eglSwapBuffers</div><div class="line">eglSwapInterval</div><div class="line">eglTerminate</div><div class="line">eglWaitClient</div><div class="line">eglWaitGL</div><div class="line">eglWaitNative</div><div class="line">eglWaitSync</div><div class="line">MesaGLInteropEGLQueryDeviceInfo</div><div class="line">MesaGLInteropEGLExportObject</div></pre></td></tr></table></figure></p>
<p>mesa中egl架构如下图所示。</p>
<p><img src="/2020/05/30/EGL in Mesa/mesa_egl-architecture.svg" alt="EGL in Mesa"></p>
<p>对上图简单说明如下，<br>从上图左上角可以看到，EGL需要和具体显示平台的窗口NativeWindow交互。这个NativeWindow需要在应用侧创建好，创建的NativeWindow是根据具体的平台(如Android， X11， Wayland)的不同而不同。这个应用创建好的NativeWindow通过调用eglCreateWindowSurface()传入到egl驱动中。</p>
<p>EGL还需要和绘制缓冲区对象(framebuffer)进行交互，这些缓冲区一般由EGL驱动调用外部窗口系统的提供的接口(如android上的surface)来分配和释放。绘制之前需要先得到空闲的buffer，绘制完成以后需要把buffer送给下一级pipeline，交出控制权。这里面一般会创建2~3个buffer，和下一级pipeline一起循环使用。这些buffer在pipeline的不同阶段流动，控制权也在各个阶段中流转，所以需要一种同步机制来保证buffer何时可读，何时可写，在android上是通过fence机制来保证的。</p>
<p>GL Driver调用EGL的内部接口(getBuffers)来得到当前绘制的目标buffer，然后GL Driver就可以发送绘制命令给GPU硬件，GPU硬件把渲染结果绘制到目标buffer中。</p>
<p>笔者的测试平台是Intel i3，GPU是Gen5xx，通过配置mesa的编译参数，可以编译出GPU平台相关的库是iris_dri.so。<br>这种配置下mesa中代码调用关系如下图所示。<br>从下图可以看出，mesa把驱动进行了分层，上面是通用的实现，对具体gpu平台相关实现都封装在xxx_dri.so中，这里Gen5xx平台对应的是iris_dri.so，对broadcom vc4 gpu来说，对应的是vc4_dri.so。</p>
<p><img src="/2020/05/30/EGL in Mesa/code_architecture.svg" alt="EGL in Mesa"></p>
<h1 id="0x2-mesa中egl流程介绍"><a href="#0x2-mesa中egl流程介绍" class="headerlink" title="0x2 mesa中egl流程介绍"></a>0x2 mesa中egl流程介绍</h1><p>下图说明了一个OpenGL ES应用程序调用EGL接口来绘制的基本流程。<br><img src="/2020/05/30/EGL in Mesa/mesa_egl.svg" alt="EGL in Mesa"></p>
<p>下面对流程中的egl api调用做详细的说明，</p>
<h2 id="0x21-创建X11平台对应的Display和Window"><a href="#0x21-创建X11平台对应的Display和Window" class="headerlink" title="0x21 创建X11平台对应的Display和Window"></a>0x21 创建X11平台对应的Display和Window</h2><p>首先在应用程序中通过下面的代码来创建x11平台上的display和window。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// create display and window for x11 platform</span></div><div class="line">x_display = XOpenDisplay(<span class="literal">NULL</span>);</div><div class="line"><span class="keyword">if</span> ( x_display == <span class="literal">NULL</span> )</div><div class="line">&#123;</div><div class="line">    <span class="keyword">return</span> EGL_FALSE;</div><div class="line">&#125;</div><div class="line"></div><div class="line">root = DefaultRootWindow(x_display);</div><div class="line"></div><div class="line">win = XCreateWindow(</div><div class="line">            x_display, root,</div><div class="line">            <span class="number">0</span>, <span class="number">0</span>, esContext-&gt;width, esContext-&gt;height, <span class="number">0</span>,</div><div class="line">            CopyFromParent, InputOutput,</div><div class="line">            CopyFromParent, CWEventMask,</div><div class="line">            &amp;swa );</div></pre></td></tr></table></figure></p>
<h2 id="0x21-调用eglInitialize"><a href="#0x21-调用eglInitialize" class="headerlink" title="0x21 调用eglInitialize"></a>0x21 调用eglInitialize</h2><p>该函数的调用堆栈如下。</p>
<p><img src="/2020/05/30/EGL in Mesa/eglInitialize.png" alt="EGL in Mesa"></p>
<p>eglInitialize的参数是display，这就是前面调用<br>平台相关接口得到的x_display。</p>
<p>上面调用堆栈最后调用的函数是iris_screen_create，这是mesa的gallium架构下初始化具体gpu型号的硬件驱动的入口函数。<br>这个在后续的文章中会做详细的介绍，这里我们知道了应用调用eglInitialize()的时候会去调用具体的gpu型号的硬件驱动。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// src/gallium/winsys/iris/drm/iris_drm_winsys.c</span></div><div class="line"><span class="function"><span class="keyword">extern</span> struct pipe_screen *<span class="title">iris_screen_create</span><span class="params">(<span class="keyword">int</span> fd, <span class="keyword">const</span> struct pipe_screen_config *config)</span></span>;</div><div class="line"></div><div class="line"><span class="function">struct pipe_screen *</span></div><div class="line"><span class="title">iris_drm_screen_create</span><span class="params">(<span class="keyword">int</span> fd, <span class="keyword">const</span> struct pipe_screen_config *config)</span></div><div class="line">&#123;</div><div class="line">   <span class="keyword">return</span> iris_screen_create(os_dupfd_cloexec(fd), config);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>下图的调用堆栈说明了eglInitialize调用过程中的gem buffer分配操作。这个操作最后会调用到kernel 驱动中完成内存分配动作。<br><img src="/2020/05/30/EGL in Mesa/eglInitialize_alloc_buffer.png" alt="EGL in Mesa"></p>
<h2 id="0x22-eglCreateContext的调用流程"><a href="#0x22-eglCreateContext的调用流程" class="headerlink" title="0x22 eglCreateContext的调用流程"></a>0x22 eglCreateContext的调用流程</h2><p>eglCreateContext的调用堆栈如下<br><img src="/2020/05/30/EGL in Mesa/eglCreateContext.png" alt="EGL in Mesa"></p>
<p>EGL驱动最后会调用到iris driver中创建context的代码中，其中包括了初始化各种函数指针的代码，包括program, clear, blit等操作。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// src/gallium/drivers/iris/iris_context.c</span></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Create a context.</div><div class="line"> *</div><div class="line"> * This is where each context begins.</div><div class="line"> */</div><div class="line"><span class="function">struct pipe_context *</span></div><div class="line"><span class="title">iris_create_context</span><span class="params">(struct pipe_screen *pscreen, <span class="keyword">void</span> *priv, <span class="keyword">unsigned</span> flags)</span></div><div class="line">&#123;</div><div class="line">   <span class="class"><span class="keyword">struct</span> <span class="title">iris_screen</span> *<span class="title">screen</span> = (<span class="title">struct</span> <span class="title">iris_screen</span>*)<span class="title">pscreen</span>;</span></div><div class="line">   <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">gen_device_info</span> *<span class="title">devinfo</span> = &amp;<span class="title">screen</span>-&gt;<span class="title">devinfo</span>;</span></div><div class="line">   <span class="class"><span class="keyword">struct</span> <span class="title">iris_context</span> *<span class="title">ice</span> = <span class="title">rzalloc</span>(<span class="title">NULL</span>, <span class="title">struct</span> <span class="title">iris_context</span>);</span></div><div class="line">   ......</div><div class="line">   iris_init_context_fence_functions(ctx);</div><div class="line">   iris_init_blit_functions(ctx);</div><div class="line">   iris_init_clear_functions(ctx);</div><div class="line">   iris_init_program_functions(ctx);</div><div class="line">   iris_init_resource_functions(ctx);</div><div class="line">   iris_init_flush_functions(ctx);</div><div class="line">   iris_init_perfquery_functions(ctx);</div><div class="line"></div><div class="line">   iris_init_program_cache(ice);</div><div class="line">   iris_init_border_color_pool(ice);</div><div class="line">   iris_init_binder(ice);</div><div class="line"></div><div class="line">   slab_create_child(&amp;ice-&gt;transfer_pool, &amp;screen-&gt;transfer_pool);</div><div class="line"></div><div class="line">   ice-&gt;state.surface_uploader =</div><div class="line">      u_upload_create(ctx, <span class="number">16384</span>, PIPE_BIND_CUSTOM, PIPE_USAGE_IMMUTABLE,</div><div class="line">                      IRIS_RESOURCE_FLAG_SURFACE_MEMZONE);</div><div class="line">   ice-&gt;state.dynamic_uploader =</div><div class="line">      u_upload_create(ctx, <span class="number">16384</span>, PIPE_BIND_CUSTOM, PIPE_USAGE_IMMUTABLE,</div><div class="line">                      IRIS_RESOURCE_FLAG_DYNAMIC_MEMZONE);</div><div class="line"></div><div class="line">   ice-&gt;query_buffer_uploader =</div><div class="line">      u_upload_create(ctx, <span class="number">4096</span>, PIPE_BIND_CUSTOM, PIPE_USAGE_STAGING,</div><div class="line">                      <span class="number">0</span>);</div><div class="line"></div><div class="line">   genX_call(devinfo, init_state, ice);</div><div class="line">   genX_call(devinfo, init_blorp, ice);</div><div class="line">   genX_call(devinfo, init_query, ice);</div><div class="line">   ......</div><div class="line">   <span class="keyword">return</span> ctx;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>下面是iris创建context的时候初始化state相关函数指针的代码。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// src/gallium/drivers/iris/iris_state.c</span></div><div class="line"><span class="function"><span class="keyword">void</span></span></div><div class="line"><span class="title">genX</span><span class="params">(init_state)</span><span class="params">(struct iris_context *ice)</span></div><div class="line">&#123;</div><div class="line">   <span class="class"><span class="keyword">struct</span> <span class="title">pipe_context</span> *<span class="title">ctx</span> = &amp;<span class="title">ice</span>-&gt;<span class="title">ctx</span>;</span></div><div class="line">   <span class="class"><span class="keyword">struct</span> <span class="title">iris_screen</span> *<span class="title">screen</span> = (<span class="title">struct</span> <span class="title">iris_screen</span> *)<span class="title">ctx</span>-&gt;<span class="title">screen</span>;</span></div><div class="line"></div><div class="line">   ctx-&gt;create_blend_state = iris_create_blend_state;</div><div class="line">   ctx-&gt;create_depth_stencil_alpha_state = iris_create_zsa_state;</div><div class="line">   ctx-&gt;create_rasterizer_state = iris_create_rasterizer_state;</div><div class="line">   ctx-&gt;create_sampler_state = iris_create_sampler_state;</div><div class="line">   ctx-&gt;create_sampler_view = iris_create_sampler_view;</div><div class="line">   ctx-&gt;create_surface = iris_create_surface;</div><div class="line">   ctx-&gt;create_vertex_elements_state = iris_create_vertex_elements;</div><div class="line">   ctx-&gt;bind_blend_state = iris_bind_blend_state;</div><div class="line">   ctx-&gt;bind_depth_stencil_alpha_state = iris_bind_zsa_state;</div><div class="line">   ctx-&gt;bind_sampler_states = iris_bind_sampler_states;</div><div class="line">   ctx-&gt;bind_rasterizer_state = iris_bind_rasterizer_state;</div><div class="line">   ctx-&gt;bind_vertex_elements_state = iris_bind_vertex_elements_state;</div><div class="line">   ctx-&gt;delete_blend_state = iris_delete_state;</div><div class="line">   ctx-&gt;delete_depth_stencil_alpha_state = iris_delete_state;</div><div class="line">   ctx-&gt;delete_rasterizer_state = iris_delete_state;</div><div class="line">   ctx-&gt;delete_sampler_state = iris_delete_state;</div><div class="line">   ctx-&gt;delete_vertex_elements_state = iris_delete_state;</div><div class="line">   ctx-&gt;set_blend_color = iris_set_blend_color;</div><div class="line">   ctx-&gt;set_clip_state = iris_set_clip_state;</div><div class="line">   ctx-&gt;set_constant_buffer = iris_set_constant_buffer;</div><div class="line">   ctx-&gt;set_shader_buffers = iris_set_shader_buffers;</div><div class="line">   ctx-&gt;set_shader_images = iris_set_shader_images;</div><div class="line">   ctx-&gt;set_sampler_views = iris_set_sampler_views;</div><div class="line">   ctx-&gt;set_compute_resources = iris_set_compute_resources;</div><div class="line">   ctx-&gt;set_global_binding = iris_set_global_binding;</div><div class="line">   ctx-&gt;set_tess_state = iris_set_tess_state;</div><div class="line">   ctx-&gt;set_framebuffer_state = iris_set_framebuffer_state;</div><div class="line">   ctx-&gt;set_polygon_stipple = iris_set_polygon_stipple;</div><div class="line">   ctx-&gt;set_sample_mask = iris_set_sample_mask;</div><div class="line">   ctx-&gt;set_scissor_states = iris_set_scissor_states;</div><div class="line">   ctx-&gt;set_stencil_ref = iris_set_stencil_ref;</div><div class="line">   ctx-&gt;set_vertex_buffers = iris_set_vertex_buffers;</div><div class="line">   ctx-&gt;set_viewport_states = iris_set_viewport_states;</div><div class="line">   ctx-&gt;sampler_view_destroy = iris_sampler_view_destroy;</div><div class="line">   ctx-&gt;surface_destroy = iris_surface_destroy;</div><div class="line">   ctx-&gt;draw_vbo = iris_draw_vbo;</div><div class="line">   ctx-&gt;launch_grid = iris_launch_grid;</div><div class="line">   ctx-&gt;create_stream_output_target = iris_create_stream_output_target;</div><div class="line">   ctx-&gt;stream_output_target_destroy = iris_stream_output_target_destroy;</div><div class="line">   ctx-&gt;set_stream_output_targets = iris_set_stream_output_targets;</div><div class="line">   ctx-&gt;set_frontend_noop = iris_set_frontend_noop;</div><div class="line"></div><div class="line">   screen-&gt;vtbl.destroy_state = iris_destroy_state;</div><div class="line">   screen-&gt;vtbl.init_render_context = iris_init_render_context;</div><div class="line">   screen-&gt;vtbl.init_compute_context = iris_init_compute_context;</div><div class="line">   screen-&gt;vtbl.upload_render_state = iris_upload_render_state;</div><div class="line">   screen-&gt;vtbl.update_surface_base_address = iris_update_surface_base_address;</div><div class="line">   screen-&gt;vtbl.upload_compute_state = iris_upload_compute_state;</div><div class="line">   screen-&gt;vtbl.emit_raw_pipe_control = iris_emit_raw_pipe_control;</div><div class="line">   screen-&gt;vtbl.emit_mi_report_perf_count = iris_emit_mi_report_perf_count;</div><div class="line">   screen-&gt;vtbl.rebind_buffer = iris_rebind_buffer;</div><div class="line">   screen-&gt;vtbl.load_register_reg32 = iris_load_register_reg32;</div><div class="line">   screen-&gt;vtbl.load_register_reg64 = iris_load_register_reg64;</div><div class="line">   screen-&gt;vtbl.load_register_imm32 = iris_load_register_imm32;</div><div class="line">   screen-&gt;vtbl.load_register_imm64 = iris_load_register_imm64;</div><div class="line">   screen-&gt;vtbl.load_register_mem32 = iris_load_register_mem32;</div><div class="line">   screen-&gt;vtbl.load_register_mem64 = iris_load_register_mem64;</div><div class="line">   screen-&gt;vtbl.store_register_mem32 = iris_store_register_mem32;</div><div class="line">   screen-&gt;vtbl.store_register_mem64 = iris_store_register_mem64;</div><div class="line">   screen-&gt;vtbl.store_data_imm32 = iris_store_data_imm32;</div><div class="line">   screen-&gt;vtbl.store_data_imm64 = iris_store_data_imm64;</div><div class="line">   screen-&gt;vtbl.copy_mem_mem = iris_copy_mem_mem;</div><div class="line">   screen-&gt;vtbl.derived_program_state_size = iris_derived_program_state_size;</div><div class="line">   screen-&gt;vtbl.store_derived_program_state = iris_store_derived_program_state;</div><div class="line">   screen-&gt;vtbl.create_so_decl_list = iris_create_so_decl_list;</div><div class="line">   screen-&gt;vtbl.populate_vs_key = iris_populate_vs_key;</div><div class="line">   screen-&gt;vtbl.populate_tcs_key = iris_populate_tcs_key;</div><div class="line">   screen-&gt;vtbl.populate_tes_key = iris_populate_tes_key;</div><div class="line">   screen-&gt;vtbl.populate_gs_key = iris_populate_gs_key;</div><div class="line">   screen-&gt;vtbl.populate_fs_key = iris_populate_fs_key;</div><div class="line">   screen-&gt;vtbl.populate_cs_key = iris_populate_cs_key;</div><div class="line">   screen-&gt;vtbl.lost_genx_state = iris_lost_genx_state;</div><div class="line"></div><div class="line">   ice-&gt;state.dirty = ~<span class="number">0u</span>ll;</div><div class="line">   ice-&gt;state.stage_dirty = ~<span class="number">0u</span>ll;</div><div class="line"></div><div class="line">   ice-&gt;state.statistics_counters_enabled = <span class="literal">true</span>;</div><div class="line"></div><div class="line">   ice-&gt;state.sample_mask = <span class="number">0xffff</span>;</div><div class="line">   ice-&gt;state.num_viewports = <span class="number">1</span>;</div><div class="line">   ice-&gt;state.prim_mode = PIPE_PRIM_MAX;</div><div class="line">   ice-&gt;state.genx = <span class="built_in">calloc</span>(<span class="number">1</span>, <span class="keyword">sizeof</span>(struct iris_genx_state));</div><div class="line">   ice-&gt;draw.derived_params.drawid = <span class="number">-1</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="0x23-和外部NativeWindow的交互"><a href="#0x23-和外部NativeWindow的交互" class="headerlink" title="0x23 和外部NativeWindow的交互"></a>0x23 和外部NativeWindow的交互</h2><p>主要是buffer的管理, 通过dequeueBuffer取得空闲buffer供本次绘制使用，在绘制完成了以后，再调用queueBuffer把buffer送去显示。另外外部NativeWindow大小发生变化的时候，也需要调用相应的接口来通知mesa，这个时候一般的流程是先把前面分配的旧的大小的buffer释放掉，然后重新去分配新的大小的buffer，另外还需要调用glViewPort重新设置draw区域的viewport大小。</p>
<h2 id="0x24-gl-driver如何取得当前绘制的buffer"><a href="#0x24-gl-driver如何取得当前绘制的buffer" class="headerlink" title="0x24 gl driver如何取得当前绘制的buffer"></a>0x24 gl driver如何取得当前绘制的buffer</h2><p>GL Driver调用EGL的内部接口(getBuffers)来得到当前绘制的目标buffer。</p>
<p>下图是eglMakeCurrent函数执行的时候分配绘制buffer的堆栈。</p>
<p><img src="/2020/05/30/EGL in Mesa/eglMakeCurrent.png" alt="EGL in Mesa"></p>
<p>具体的调用代码如下所示，外部通过getBuffers来调用具体egl driver的buffer接口。对x11_dr3而言，最后调用的函数是loader_dri3_get_buffers，在这个时候会返回需要的buffer，如果有必要也会重新分配buffer。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// src/egl/drivers/dri2/platform_x11_dri3.c</span></div><div class="line"><span class="keyword">const</span> __DRIimageLoaderExtension dri3_image_loader_extension = &#123;</div><div class="line">   .base = &#123; __DRI_IMAGE_LOADER, <span class="number">1</span> &#125;,</div><div class="line"></div><div class="line">   .getBuffers          = loader_dri3_get_buffers,</div><div class="line">   .flushFrontBuffer    = dri3_flush_front_buffer,</div><div class="line">&#125;;</div><div class="line"></div><div class="line"><span class="comment">// src/loader/loader_dri3_helper.c</span></div><div class="line"></div><div class="line"><span class="comment">/** loader_dri3_get_buffers</span></div><div class="line"> *</div><div class="line"> * The published buffer allocation API.</div><div class="line"> * Returns all of the necessary buffers, allocating</div><div class="line"> * as needed.</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">int</span></span></div><div class="line"><span class="title">loader_dri3_get_buffers</span><span class="params">(__DRIdrawable *driDrawable,</span></div><div class="line">                        <span class="keyword">unsigned</span> <span class="keyword">int</span> format,</div><div class="line">                        <span class="keyword">uint32_t</span> *stamp,</div><div class="line">                        <span class="keyword">void</span> *loaderPrivate,</div><div class="line">                        <span class="keyword">uint32_t</span> buffer_mask,</div><div class="line">                        struct __DRIimageList *buffers)</div><div class="line">&#123;</div><div class="line">   ......</div><div class="line">   <span class="keyword">if</span> (!dri3_update_drawable(draw))</div><div class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line"></div><div class="line">   dri3_update_num_back(draw);</div><div class="line"></div><div class="line">   <span class="comment">/* Free no longer needed back buffers */</span></div><div class="line">   <span class="keyword">for</span> (buf_id = draw-&gt;num_back; buf_id &lt; LOADER_DRI3_MAX_BACK; buf_id++) &#123;</div><div class="line">      <span class="keyword">if</span> (draw-&gt;cur_blit_source != buf_id &amp;&amp; draw-&gt;buffers[buf_id]) &#123;</div><div class="line">         dri3_free_render_buffer(draw, draw-&gt;buffers[buf_id]);</div><div class="line">         draw-&gt;buffers[buf_id] = <span class="literal">NULL</span>;</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="comment">/* pixmaps always have front buffers.</span></div><div class="line">    * Exchange swaps also mandate fake front buffers.</div><div class="line">    */</div><div class="line">   <span class="keyword">if</span> (draw-&gt;is_pixmap || draw-&gt;swap_method == __DRI_ATTRIB_SWAP_EXCHANGE)</div><div class="line">      buffer_mask |= __DRI_IMAGE_BUFFER_FRONT;</div><div class="line"></div><div class="line">   <span class="keyword">if</span> (buffer_mask &amp; __DRI_IMAGE_BUFFER_FRONT) &#123;</div><div class="line">      <span class="comment">/* All pixmaps are owned by the server gpu.</span></div><div class="line">       * When we use a different gpu, we can't use the pixmap</div><div class="line">       * as buffer since it is potentially tiled a way</div><div class="line">       * our device can't understand. In this case, use</div><div class="line">       * a fake front buffer. Hopefully the pixmap</div><div class="line">       * content will get synced with the fake front</div><div class="line">       * buffer.</div><div class="line">       */</div><div class="line">      <span class="keyword">if</span> (draw-&gt;is_pixmap &amp;&amp; !draw-&gt;is_different_gpu)</div><div class="line">         front = dri3_get_pixmap_buffer(driDrawable,</div><div class="line">                                               format,</div><div class="line">                                               loader_dri3_buffer_front,</div><div class="line">                                               draw);</div><div class="line">      <span class="keyword">else</span></div><div class="line">         front = dri3_get_buffer(driDrawable,</div><div class="line">                                        format,</div><div class="line">                                        loader_dri3_buffer_front,</div><div class="line">                                        draw);</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (!front)</div><div class="line">         <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">   &#125; <span class="keyword">else</span> &#123;</div><div class="line">      dri3_free_buffers(driDrawable, loader_dri3_buffer_front, draw);</div><div class="line">      draw-&gt;have_fake_front = <span class="number">0</span>;</div><div class="line">   &#125;</div><div class="line">   ......</div><div class="line">   <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="0x25-glClear"><a href="#0x25-glClear" class="headerlink" title="0x25 glClear"></a>0x25 glClear</h2><p>glClear的调用堆栈如下，可以看到这个时候也需要分配buffer。</p>
<p><img src="/2020/05/30/EGL in Mesa/glClear.png" alt="EGL in Mesa"></p>
<h2 id="0x26-eglswapbuffer流程"><a href="#0x26-eglswapbuffer流程" class="headerlink" title="0x26 eglswapbuffer流程"></a>0x26 eglswapbuffer流程</h2><p><img src="/2020/05/30/EGL in Mesa/eglSwapBuffers.png" alt="EGL in Mesa"><br>通过调用相关的OpenGL ES API，把需要的绘制资源，如顶点数据(VBO/VAO等)，纹理资源(glTexImage2D)等准备好，mesa内部也构造好了对应GPU需要执行的command，这个时候可以启动GPU来绘制了。在函数submit_batch中通过调用DRM_IOCTL_I915_GEM_EXECBUFFER2 ioctl命令来启动kernel的绘制动作。</p>
<h2 id="0x27-egl驱动中实现的其他功能，如chooseConfig"><a href="#0x27-egl驱动中实现的其他功能，如chooseConfig" class="headerlink" title="0x27 egl驱动中实现的其他功能，如chooseConfig"></a>0x27 egl驱动中实现的其他功能，如chooseConfig</h2><p>这部分主要是软件逻辑，根据硬件平台的能力，对configure进行管理。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/26/About SceneGraph/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/26/About SceneGraph/" itemprop="url">About SceneGraph</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-04-26T20:10:10+08:00">
                2020-04-26
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2020/04/26/About SceneGraph/" class="leancloud_visitors" data-flag-title="About SceneGraph">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="0x1-什么是SceneGraph"><a href="#0x1-什么是SceneGraph" class="headerlink" title="0x1 什么是SceneGraph"></a>0x1 什么是SceneGraph</h1><p>渲染引擎需要解决的问题是如何把需要绘制的各种对象高效地组织起来并绘制出来，这其中很重要的概念是SceneGraph。目前各种渲染引擎包括2D UI引擎到3D引擎都实现了类似的概念。<br>其实SceneGraph应该称为SceneTree更合适，因为其中的数据组织一般是采用Tree的形式。</p>
<p>qt中采用的SceneGraph介绍如下<br><a href="https://doc.qt.io/qt-5/qtquick-visualcanvas-scenegraph.html" target="_blank" rel="external">https://doc.qt.io/qt-5/qtquick-visualcanvas-scenegraph.html</a></p>
<p>cocos2d也有类似的概念如下<br><a href="https://docs.cocos2d-x.org/cocos2d-x/v4/en/basic_concepts/scene.html" target="_blank" rel="external">https://docs.cocos2d-x.org/cocos2d-x/v4/en/basic_concepts/scene.html</a></p>
<p>ogre中对SceneGraph的介绍如下<br><a href="https://ogrecave.github.io/ogre/api/latest/_the-_core-_objects.html" target="_blank" rel="external">https://ogrecave.github.io/ogre/api/latest/_the-_core-_objects.html</a></p>
<h1 id="0x2-SceneGraph包括哪些功能"><a href="#0x2-SceneGraph包括哪些功能" class="headerlink" title="0x2 SceneGraph包括哪些功能"></a>0x2 SceneGraph包括哪些功能</h1><p>典型的SceneGraph包括了SceneManager，RenderManager，ResourceManager， Camera， RenderTarget，Animation， Particle子模块，下面来简单介绍一下这些概念。</p>
<p>SceneManager提供对场景图的组织和管理，具体可以采用二叉分割树，八叉树等。<br>RenderManager提供了绘制相关操作，也就是通常所说的各种Backend，如OpenGL,Directx,Metal,Vulkan等。<br>ResourceManager提供了对资源的管理，包括Material, Mesh等。<br>Camera提供了在SceneGraph中模拟眼睛的功能。<br>Viewer是在SceneGraph遨游时的眼睛，通过变化Camera的位置，我们可以看到SceneGraph中不同的风景。其中提供lookAt()类似的函数来指定场景中眼睛的位置。</p>
<h1 id="0x3-SceneGraph的设计"><a href="#0x3-SceneGraph的设计" class="headerlink" title="0x3 SceneGraph的设计"></a>0x3 SceneGraph的设计</h1><h2 id="0x31-数据结构设计"><a href="#0x31-数据结构设计" class="headerlink" title="0x31 数据结构设计"></a>0x31 数据结构设计</h2><p>渲染引擎一般采用场景节点和场景内容分离的机制，也就是说场景内容作为场景节点的成员变量，而不是把场景内容作为场景节点的子类。场景节点一般包含了类似位置，旋转等信息，场景内容指需要绘制的Mesh和渲染属性等。<br>另外一种实现方式是把场景内容作为场景节点的子类，这种实现方式把场景内容和场景节点耦合在一起，不利于添加新的场景内容的支持。<br>场景节点和场景内容分离机制带来了SceneGraph中数据松耦合的好处，场景内容添加到一个场景节点中，也可以从一个场景节点中移除。SceneManager控制的是场景节点，不需要关心具体的场景内容。我们可以精心设计场景节点的接口，这样可以保持SceneManager对场景节点的灵活控制。</p>
<p>下面是典型的SceneGraph数据结构图。</p>
<p><img src="/2020/04/26/About SceneGraph/Data_Structure.png" alt="Data_Structure"></p>
<p>SceneNode表示场景节点。<br>Object表示场景内容。一个Object可以包括多个RenderObject，如房间可以表示为一个Object，房间里的一张桌子是RenderObject。<br>RenderObject表示可被渲染的内容。RenderObject需要通过Mesh和Material来绘制。如前所述，一张桌子是RenderObject，然后我们需要知道桌子的Mesh，需要知道如何设置Mesh的渲染属性如shader，color等。</p>
<h2 id="0x32-场景图管理器"><a href="#0x32-场景图管理器" class="headerlink" title="0x32 场景图管理器"></a>0x32 场景图管理器</h2><p>场景图管理器实现的功能有，<br>第一类是数据对象管理相关的功能，包括如下功能。</p>
<ol>
<li><p>创建/删除SceneNode。</p>
</li>
<li><p>创建/删除Camera。</p>
</li>
<li><p>创建/删除各种Light。</p>
</li>
<li><p>创建/删除Object，前面提到Object作为场景内容节点挂接到SceneNode上。</p>
</li>
<li><p>创建删除各种绘制对象，设置各种绘制属性。</p>
</li>
<li><p>创建/删除ParticleSystem。</p>
</li>
<li><p>创建/删除AnimationSystem。</p>
</li>
</ol>
<p>另外是渲染流程相关功能，包括如下，</p>
<ol>
<li><p>查找当前Camera可见的渲染Object。</p>
</li>
<li><p>渲染前面查找到的渲染Object</p>
</li>
</ol>
<p>场景图管理器的结构图如下所示，<br><img src="/2020/04/26/About SceneGraph/SceneManager.png" alt="SceneManager"></p>
<p>Core下面的SceneManager提供了基本的框架和系统中其他模块交互，对应于具体的SceneManager而言，如上图所示的BspScenemanager和OctTreeSceneManager，其核心功能是解决如何高效地查找到当前Camera可见范围内的渲染Object，因为场景图中包括了很多数据，如在关卡游戏中，场景图中包括了很多游戏关卡，如果都去渲染，性能可能很差，所以通过SceneManager快速找到Camera可见范围内的渲染Object，然后只需要渲染这些Object。</p>
<h2 id="0x33-渲染管理器"><a href="#0x33-渲染管理器" class="headerlink" title="0x33 渲染管理器"></a>0x33 渲染管理器</h2><p>渲染管理器的结构图如下所示，<br><img src="/2020/04/26/About SceneGraph/RenderManager.png" alt="RenderManager"></p>
<p>渲染管理器也称为渲染的后端，这里来谈一下如何设计渲染管理器的接口使特定后端的代码量最少。也就是说如何把功能尽量放在Core中，Backend只保留特定平台相关的实现，这部分也是比较各种渲染引擎的跨平台技术做的好坏的评价标准之一。</p>
<p>RenderManager需要抽象出下面的模块作为通用的接口，这些是所有Backend都具备的特性，是公共的模块。在具体的Backend模块中中去继承这些接口从而实现各个Backend的对接。</p>
<ol>
<li><p>Texture操作接口。</p>
</li>
<li><p>HardwareBuffer操作接口，包括Index bufer/Vertex buffer/Uniform buffer/Texture buffer等。</p>
</li>
<li><p>Shader/Program操作接口。</p>
</li>
<li><p>DrawCall操作接口。</p>
</li>
</ol>
<h1 id="0x4-渲染流程设计及优化"><a href="#0x4-渲染流程设计及优化" class="headerlink" title="0x4 渲染流程设计及优化"></a>0x4 渲染流程设计及优化</h1><h2 id="0x41-数据准备"><a href="#0x41-数据准备" class="headerlink" title="0x41 数据准备"></a>0x41 数据准备</h2><p>绘制内容的设置<br>绘制内容包括各种资源，如Mesh，Skelton，Shader等。他们通过各种ReaourceManager加载进来。</p>
<p>绘制坐标的设置<br>如果SceneNode存在父子关系，有两种方法来设置绘制坐标，第一种是在生成绘制内容的时候，根据父节点的坐标计算好当前节点的坐标，然后设置到SceneNode中。另外一种方法是给SceneNode设置一个TransformNode作为SceneNode的成员，这个TransformNode是计算好的本地坐标系坐标(没有考虑父子关系)，这样在包括所有SceneNode的tree创建好了以后，再去从根节点开始遍历这颗树，根据父子关系，计算出每个SceneNode的世界坐标。具体实现中推荐采用第一种方法，因为如果SceneNode的层次太深，递归遍历节点的时候可能会出现栈溢出。</p>
<p>具有父子关系的SceneNode结构图如下所示。</p>
<p><img src="/2020/04/26/About SceneGraph/SceneNode_Strucutre.png" alt="SceneNode_Strucutre"></p>
<h2 id="0x42-数据绘制"><a href="#0x42-数据绘制" class="headerlink" title="0x42 数据绘制"></a>0x42 数据绘制</h2><p>场景绘制的完整流程如下，</p>
<p><img src="/2020/04/26/About SceneGraph/Rendering_Process.png" alt="Rendering_Process"></p>
<ol>
<li><p>首先是设置好场景数据，这些场景数据可以是通过离线工具如Blender，由美工来制作完成并导出，然后再加载进来。渲染引擎也可以提供在线实时生成场景数据的功能，如生成矩形，球形，立方体等。设置好的场景数据封装成RenderObject，再由RenderObject组成Object。</p>
</li>
<li><p>然后是需要把场景数据挂接到场景图的SceneNode中，这样场景图管理器就拥有了场景数据了，可以根据视点在场景图中执行查询等操作。</p>
</li>
<li><p>然后开始根据Camera的位置找到可见范围内的RenderObject，这个也就是前面提到的SceneManager发挥作用的地方，可以简单地称为Culling操作。</p>
</li>
<li><p>找到了需要渲染的RenderObject集合，可以对这些RenderObject的渲染顺序进行Bactch优化，如果两个RenderObject需要的渲染Maerial是一样地，可以合并成一个drawcall，这种优化方式我们称为动态Batch。如果由美工在素材制作阶段对场景数据的组织进行优化，把能用一个drawcall进行渲染的物体合并起来，这种优化被称为静态Batch。</p>
</li>
<li><p>优化好了以后就开始调用具体的Backend进行渲染了。</p>
</li>
</ol>
<h2 id="0x43-流程优化"><a href="#0x43-流程优化" class="headerlink" title="0x43 流程优化"></a>0x43 流程优化</h2><p>如下图所示，可以把渲染过程划分成两个线程并行处理，这样在数据加载阶段可以做上一帧的绘制动作，等数据加载完成再同步给渲染线程。</p>
<p><img src="/2020/04/26/About SceneGraph/Pipeline_Optimization.png" alt="Pipeline_Optimization"></p>
<p>另外一个优化是资源的异步加载，如果前面的Load Thread同时要响应用户操作，如果长时间在运行，会造成UI卡死，这个时候可以通过开启异步线程来处理。</p>
<h1 id="0x5-SceneGraph的发展方向思考"><a href="#0x5-SceneGraph的发展方向思考" class="headerlink" title="0x5 SceneGraph的发展方向思考"></a>0x5 SceneGraph的发展方向思考</h1><p>SceneGraph技术作为各种渲染引擎的根基，目前是很完善的技术了。包括光线跟踪渲染引擎，其中也包含了SceneGraph的实现。如果要考虑未来方向，是否可以和其他方向结合，如人工智能等？搞出一套智能的渲染引擎。如是否可以用CNN来加速特大场景图的可见渲染物体查询？</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/15/clDNN Introduction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/03/15/clDNN Introduction/" itemprop="url">clDNN Introduction</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-03-15T20:20:31+08:00">
                2020-03-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2020/03/15/clDNN Introduction/" class="leancloud_visitors" data-flag-title="clDNN Introduction">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="0x1-总体结构"><a href="#0x1-总体结构" class="headerlink" title="0x1 总体结构"></a>0x1 总体结构</h1><p>clDNN(Compute Library for Deep Neural Networks)是采用OpenCL来加速DNN(Deep Neural Networks)的framework。目标平台是Intel® HD and Iris™ Pro Graphics。clDNN目前已经是Intel OpenVINO的一部分。OpenVINO还包括了其它各种硬件平台的加速库，如CPU上的加速库mklDNN等。clDNN当然也可以改造成在NVIDIA和AMD的GPU上运行，虽然这个时候的性能可能需要进一步tuning。</p>
<p>clDNN对DNN中有关概念进行了抽象，其中有关数据类型的层次结构如下。</p>
<p><img src="/2020/03/15/clDNN Introduction/cldnn.png" alt=""></p>
<p>这些数据类型的定义简单说明如下。</p>
<p>Kernel - 算子计算的OpenCL实现。<br>Primitive - DNN中基本运算单元，如convolution, pooling, softmax等，也就是通常所说的算子。<br>Data - 特殊的算子，用来表示运算过程中的参数，如weights和biases, 也指DNN的输入和输出。<br>Engine - DNN中运行的加速器的类型，目前只有OpenCL engine一种。<br>Topology - 指DNN中的graph，其中包括了primitives, data和他们之间的关系。<br>Program - 位于Topology和Network之间(可选项)，是编译好的graph网络但是没有分配内存。<br>Network - 编译好的graph网络并且已经分配内存，可以运行，在编译网络的过程中，网络参数可以进行特殊的优化如fusing，data reordering等。</p>
<p>clDNN的执行<a href="https://intel.github.io/clDNN/index.html" target="_blank" rel="external">流程图</a>如下所示。</p>
<p><img src="/2020/03/15/clDNN Introduction/workflow.jpg" alt=""></p>
<p>执行过程包括下面的步骤<br>a.Create Engine.<br>b.Declare or define primitives parameters (weights and biases) if needed.<br>c.Create primitives. It is required to provide name for each primitive.<br>d.Create topology<br>e.Add primitives to topology<br>f.Build Network from topology<br>h.Set Inputs data<br>g.Execute Network</p>
<p>本文后续对这些过程进行详细的说明。</p>
<h1 id="0x2-LoadNetwork流程分析"><a href="#0x2-LoadNetwork流程分析" class="headerlink" title="0x2 LoadNetwork流程分析"></a>0x2 LoadNetwork流程分析</h1><p>   <img src="/2020/03/15/clDNN Introduction/loadnetwork.svg" alt=""><br>   LoadNetwork的执行流程如上图所示，下面详细来介绍一下其中涉及到的内容。</p>
<h2 id="0x21-kernel-selector"><a href="#0x21-kernel-selector" class="headerlink" title="0x21 kernel selector"></a>0x21 kernel selector</h2><p>  前面已经知道，clDNN是通过OpenCL来加速DNN的推理执行，就是说其中的算子是通过OpenCL来加速的，kernel就是指采用OpenCL内核实现的算子。<br>  kernel selector提供了如何选择最适合的kernel的接口，Primitive创建kernel的时候，调用kernel selector来得到最合适的kernel。</p>
<p>  上层不能直接操作OpenCL kernel，所以提供了对应的wrapper，这些wrapper都在下面这个目录中。<br>  inference-engine\thirdparty\clDNN\kernel_selector\core\actual_kernels<br>  另外wrapper还定义了kernel支持的输入和输出数据格式。</p>
<p>  对应的OpenCL kernel的定义都在这个目录下面。<br>  inference-engine\thirdparty\clDNN\kernel_selector\core\cl_kernels</p>
<p>  现在我们想知道OpenCL kernel是什么时候创建的呢？通过分析代码，我们可以知道OpenCL kernel的创建是在build_program的时候通过下面的循环来实现的。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">void</span> compile_graph::run(program_impl&amp; p) &#123;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; node : p.get_processing_order()) &#123;</div><div class="line">        <span class="keyword">if</span> (!node-&gt;is_type&lt;internal_primitive&gt;() &amp;&amp; !node-&gt;is_type&lt;data&gt;()) &#123;</div><div class="line">            node-&gt;get_output_layout();</div><div class="line">            <span class="keyword">if</span> (!node-&gt;is_type&lt;data&gt;() &amp;&amp; !(node-&gt;is_type&lt;mutable_data&gt;() &amp;&amp; node-&gt;get_dependencies().empty())) &#123;</div><div class="line">                node-&gt;selected_impl = node-&gt;type()-&gt;choose_impl(p.get_engine(), *node);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>上述代码中selected_impl的定义为primitive_impl类型的std::shared_ptr变量。<br>上述函数会调用到下面的create()函数。<br>这个函数再通过调用kernel_selector.GetBestKernels来创建最合适的OpenCL kernel。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">static</span> primitive_impl* <span class="title">create</span><span class="params">(<span class="keyword">const</span> scale_node&amp; arg)</span> </span>&#123;</div><div class="line">    ......</div><div class="line">    ew_params.layoutBased = <span class="literal">true</span>;</div><div class="line"></div><div class="line">    <span class="keyword">auto</span>&amp; kernel_selector = kernel_selector::eltwise_kernel_selector::Instance();</div><div class="line">    <span class="keyword">auto</span> best_kernels = kernel_selector.GetBestKernels(ew_params, ew_optional_params);</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> scale = <span class="keyword">new</span> scale_gpu(arg, best_kernels[<span class="number">0</span>]);</div><div class="line"></div><div class="line">    <span class="keyword">return</span> scale;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="0x22-primitive封装"><a href="#0x22-primitive封装" class="headerlink" title="0x22 primitive封装"></a>0x22 primitive封装</h2><p>primitive是对前面通过kernel selector取得的kernel的封装。<br>其中的primitive结构体都是通过typed_primitive_gpu_impl来定义的。</p>
<p>clDNN Library提供了下面这些<a href="https://intel.github.io/clDNN/index.html" target="_blank" rel="external">primitives</a>，</p>
<pre><code>Convolution
Fully connected (inner product)
Pooling
    average
    maximum
Normalization
    across channel
    within channel
    batch
Activation
    logistic
    tanh
    rectified linear unit (ReLU)
    softplus (softReLU)
    abs
    square
    sqrt
    linear
Softmax
Crop
Deconvolution
Depth concatenation
Eltwise
ROI pooling
Simpler NMS
Prior box
Detection output
</code></pre><p>通过对上述primitive的封装，clDNN提供了下面的topologies<br>    Alexnet<br>    Googlenet(v1-v3)<br>    ResNet<br>    VGG<br>    faster-rCNN and other.</p>
<h2 id="0x23-OpenCL接口的封装"><a href="#0x23-OpenCL接口的封装" class="headerlink" title="0x23 OpenCL接口的封装"></a>0x23 OpenCL接口的封装</h2><p>在目录inference-engine\thirdparty\clDNN\src\gpu\下面提供了OpenCL封装的代码，这些代码对OpenCL的底层api进行了封装，方便了clDNN其他模块的调用。</p>
<p>其中的gpu_queue类提供了对OpenCL command queue的封装，对外提供了command queue的创建和使用的接口。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">gpu_queue</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    ......</div><div class="line"><span class="keyword">private</span>:</div><div class="line">    <span class="keyword">uint32_t</span> id;</div><div class="line">    <span class="built_in">std</span>::weak_ptr&lt;gpu_toolkit&gt; _context;</div><div class="line">    cl::CommandQueue _command_queue;</div><div class="line">    <span class="built_in">std</span>::atomic&lt;<span class="keyword">uint64_t</span>&gt; _queue_counter&#123;<span class="number">0</span>&#125;;</div><div class="line">    <span class="built_in">std</span>::atomic&lt;<span class="keyword">uint64_t</span>&gt; _last_barrier&#123;<span class="number">0</span>&#125;;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;events_pool&gt; _events_pool;</div><div class="line">    cl::Event _last_barrier_ev;</div><div class="line">    <span class="keyword">bool</span> _output_event = <span class="literal">false</span>;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>gpu_toolkit类提供了OpenCL操作的统一接口，其他模块只需要调用gpu_toolkit就可以实现OpenCL的相关操作。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">gpu_toolkit</span> :</span> <span class="keyword">public</span> <span class="built_in">std</span>::enable_shared_from_this&lt;gpu_toolkit&gt; &#123;</div><div class="line">    ......</div><div class="line"><span class="keyword">private</span>:</div><div class="line">    configuration _configuration;</div><div class="line">    cl::Device _device;</div><div class="line">    cl::Context _context;</div><div class="line">    cl_platform_id _platform_id;</div><div class="line">    device_info_internal _device_info;</div><div class="line">    <span class="keyword">bool</span> _neo_driver = <span class="literal">false</span>;</div><div class="line">    kernels_cache _kernels_cache;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">map</span>&lt;<span class="keyword">uint32_t</span>, gpu_queue&gt; _command_queues_w;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;rapidjson::Document&gt; _device_cache;</div><div class="line">    kernels_binaries_container _binaries;</div><div class="line">    <span class="keyword">bool</span> _serialize = <span class="literal">false</span>;</div><div class="line"></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">string</span> _extensions;</div><div class="line"></div><div class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ocl_logger</span>;</span></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;ocl_logger&gt; _logger;</div><div class="line"></div><div class="line">    <span class="comment">// returns whether a barrier has been added</span></div><div class="line">    <span class="built_in">std</span>::<span class="function">ofstream&amp; <span class="title">open_log</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">    <span class="built_in">std</span>::<span class="function"><span class="built_in">string</span> <span class="title">get_device_version</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> _device.getInfo&lt;CL_DEVICE_VERSION&gt;(); &#125;</div><div class="line"></div><div class="line">    <span class="comment">// void build_command_queues();</span></div><div class="line">    <span class="function">gpu_queue&amp; <span class="title">get_command_queue</span><span class="params">(<span class="keyword">uint32_t</span> id)</span></span>;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h2 id="0x24-graph-optimizer"><a href="#0x24-graph-optimizer" class="headerlink" title="0x24 graph optimizer"></a>0x24 graph optimizer</h2><p>在build_program的时候会初始化graph，然后执行graph优化，包括pre_optimize_graph和post_optimize_graph。<br>执行步骤都是在下面的build_program函数中完成的。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">void</span> program_impl::build_program(<span class="keyword">bool</span> is_internal) &#123;</div><div class="line">    init_graph();</div><div class="line">    &#123; pre_optimize_graph(is_internal); &#125;</div><div class="line">    run_graph_compilation();</div><div class="line">    &#123; post_optimize_graph(is_internal); &#125;</div><div class="line">    prepare_memory_dependencies();</div><div class="line">    engine-&gt;compile_program(*<span class="keyword">this</span>);</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (!is_internal)</div><div class="line">        prim_info = get_current_stage_info();</div><div class="line"></div><div class="line">    cleanup();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>下面来分析一下pre_optimize_graph和post_optimize_graph分别是如何对graph进行优化的。<br>graph优化是通过调用apply_opt_pass来实现的。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">apply_opt_pass&lt;trim_to_outputs&gt;();</div></pre></td></tr></table></figure>
<p>apply_opt_pass是模板函数，模板参数trim_to_outputs是继承于base_pass的优化pass。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">trim_to_outputs</span> :</span> <span class="keyword">public</span> base_pass &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    trim_to_outputs() : base_pass(<span class="string">"trimmed"</span>) &#123;&#125;</div><div class="line"></div><div class="line"><span class="keyword">private</span>:</div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">(program_impl&amp; p)</span> override</span>;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>模板函数apply_opt_pass的定义如下。在模板函数中生成Pass对象，Pass对象的基类是base_pass，然后调用pass_manager的run函数执行优化操作。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">apply_opt_pass</span><span class="params">(base_pass&amp; pass)</span> </span>&#123; pm-&gt;run(*<span class="keyword">this</span>, pass); &#125;</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span> <span class="title">Pass</span>, <span class="title">typename</span>... <span class="title">Args</span>&gt;</span></div><div class="line"><span class="title">typename</span> <span class="title">std</span>::enable_if&lt;<span class="built_in">std</span>::is_base_of&lt;base_pass, Pass&gt;::value &amp;&amp;</div><div class="line">                        <span class="built_in">std</span>::is_constructible&lt;Pass, Args...&gt;::value&gt;::<span class="function">type</span></div><div class="line"><span class="title">apply_opt_pass</span><span class="params">(Args&amp;&amp;... args)</span> &#123;</div><div class="line">    <span class="keyword">auto</span> pass = Pass(<span class="built_in">std</span>::forward&lt;Args&gt;(args)...);</div><div class="line">    apply_opt_pass(pass);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>pass_manager的run函数定义如下。在run函数里会调用优化pass的run函数来执行具体的优化操作。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">void</span> pass_manager::run(program_impl&amp; p, base_pass&amp; pass) &#123;</div><div class="line">    ......</div><div class="line">    pass.run(p);</div><div class="line">    ......</div><div class="line">    pass_count++;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="0x25-program-node创建"><a href="#0x25-program-node创建" class="headerlink" title="0x25 program node创建"></a>0x25 program node创建</h2><p>program_node的定义如下，每一个program_node和一个primitive_impl相对应，primitive_impl是前面提到的OpenCL kernel函数的封装。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/*</span></div><div class="line">    Base class for all primitives which wraps API class and extends it to be used</div><div class="line">    in graph context.</div><div class="line">*/</div><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">program_node</span> &#123;</span></div><div class="line">    ......</div><div class="line"><span class="keyword">protected</span>:</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;primitive&gt; desc;</div><div class="line">    program_impl&amp; myprog;</div><div class="line"></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;primitive_impl&gt; selected_impl;</div><div class="line"></div><div class="line">    <span class="keyword">bool</span> valid_output_layout = <span class="literal">false</span>;</div><div class="line">    layout output_layout = layout(data_types::f32, format::bfyx, tensor());</div><div class="line"></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;program_node*&gt; dependencies;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">list</span>&lt;program_node*&gt; users;</div></pre></td></tr></table></figure>
<p>program_node的创建函数如下，创建好的node保存在nodes_map中。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// create all nodes from topology primitives, add dependencies among them and create inputs list</span></div><div class="line"><span class="keyword">void</span> program_impl::prepare_nodes(topology_impl <span class="keyword">const</span>&amp; topology) &#123;</div><div class="line">    <span class="keyword">auto</span> <span class="keyword">const</span>&amp; topo_map = topology.get_primitives();</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; prim : topo_map) &#123;</div><div class="line">        get_or_create(prim.second);</div><div class="line">    &#125;</div><div class="line">    ......</div><div class="line">&#125;</div><div class="line"></div><div class="line">program_node&amp; program_impl::get_or_create(<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;primitive&gt; prim) &#123;</div><div class="line">    <span class="keyword">auto</span> itr = nodes_map.lower_bound(prim-&gt;id);</div><div class="line">    <span class="keyword">if</span> (itr != nodes_map.end() &amp;&amp; itr-&gt;first == prim-&gt;id)</div><div class="line">        <span class="keyword">return</span> *itr-&gt;second;</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> new_node = prim-&gt;type-&gt;create_node(*<span class="keyword">this</span>, prim);</div><div class="line">    nodes_map.insert(itr, &#123;prim-&gt;id, new_node&#125;);</div><div class="line">    <span class="keyword">return</span> *new_node;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>typed_program_node是program_node的继承类，提供了对各种类型的program_node的封装。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">template</span> &lt;&gt;</div><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">typed_program_node</span>&lt;activation&gt; :</span> <span class="keyword">public</span> typed_program_node_base&lt;activation&gt; &#123;</div><div class="line">    <span class="keyword">using</span> parent = typed_program_node_base&lt;activation&gt;;</div><div class="line">    typed_program_node(<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;activation&gt; prim, program_impl&amp; prog) : parent(prim, prog) &#123;</div><div class="line">        support_padding_all(<span class="literal">true</span>);</div><div class="line">    &#125;</div><div class="line">    ......</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h1 id="0x3-Infer流程分析"><a href="#0x3-Infer流程分析" class="headerlink" title="0x3 Infer流程分析"></a>0x3 Infer流程分析</h1><p>前面网络加载好了以后，下面就开始真正的推理执行了，详细的流程如下。<br>   <img src="/2020/03/15/clDNN Introduction/infer.svg" alt=""><br>这个时候为了加速推理执行，如上图所示，采用了多线程的方法来提高执行的并行度，主线程把不同stage的task分配到不同的线程中去执行。<br>每个kernel执行的时候会调用enqueueNDRangeKernel来issue OpenCL驱动来执行计算。</p>
<p>我们知道一个推理网络执行的时候会有很多算子在执行，这些算子的执行在GPU上，如果每个算子执行完成以后都需要把结果从GPU读取到CPU中的话，效率会很低，这种执行模型如下所示，我们称之为sync执行模式。<br>   <img src="/2020/03/15/clDNN Introduction/execution_sync.png" alt=""></p>
<p>clDNN中采用的是如下图所示的async执行模型，各个算子之间的同步通过event来控制，每次算子执行完成以后，不需要把数据从GPU读取到CPU中。整个流程中只需要一次GPU buffer写入操作和一次GPU buffer读取操作。<br>   <img src="/2020/03/15/clDNN Introduction/execution_async.png" alt=""></p>
<p>下面是clDNN中enqueue kernel的代码。从代码中我们可以看到算子在每次执行enqueueNDRangeKernel的时候，需要等待一个算子执行完成的event被触发，这样算子之间的数据同步就不需要CPU的干预了。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line">event_impl::ptr gpu_queue::enqueue_kernel(cl::Kernel <span class="keyword">const</span>&amp; kern,</div><div class="line">                                          cl::NDRange <span class="keyword">const</span>&amp; global,</div><div class="line">                                          cl::NDRange <span class="keyword">const</span>&amp; local,</div><div class="line">                                          <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;event_impl::ptr&gt; <span class="keyword">const</span>&amp; deps) &#123;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;cl::Event&gt; dep_events;</div><div class="line">    <span class="keyword">auto</span> dep_events_ptr = &amp;dep_events;</div><div class="line">    <span class="keyword">if</span> (!context()-&gt;get_configuration().host_out_of_order) &#123;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; dep : deps)</div><div class="line">            <span class="keyword">if</span> (<span class="keyword">auto</span> ocl_ev = <span class="keyword">dynamic_cast</span>&lt;base_event*&gt;(dep.get()))</div><div class="line">                dep_events.push_back(ocl_ev-&gt;get());</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">        dep_events_ptr = <span class="literal">nullptr</span>;</div><div class="line"></div><div class="line">        sync_events(deps);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    cl::Event ret_ev;</div><div class="line"></div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line">        <span class="keyword">if</span> (!context()-&gt;get_configuration().host_out_of_order || _output_event ||</div><div class="line">            context()-&gt;get_configuration().enable_profiling) &#123;</div><div class="line">            _command_queue.enqueueNDRangeKernel(kern, cl::NullRange, global, local, dep_events_ptr, &amp;ret_ev);</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            _command_queue.enqueueNDRangeKernel(kern, cl::NullRange, global, local, dep_events_ptr, <span class="literal">nullptr</span>);</div><div class="line">        &#125;</div><div class="line">    &#125; <span class="keyword">catch</span> (cl::Error <span class="keyword">const</span>&amp; err) &#123;</div><div class="line">        <span class="keyword">throw</span> ocl_error(err);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> _events_pool-&gt;get_from_base_pool(context(), ret_ev, ++_queue_counter);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">void</span> gpu_queue::sync_events(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;event_impl::ptr&gt; <span class="keyword">const</span>&amp; deps) &#123;</div><div class="line">    <span class="keyword">bool</span> needs_barrier = <span class="literal">false</span>;</div><div class="line">    ......</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (needs_barrier) &#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            <span class="keyword">if</span> (_output_event)</div><div class="line">                _command_queue.enqueueBarrierWithWaitList(<span class="literal">nullptr</span>, &amp;_last_barrier_ev);</div><div class="line">            <span class="keyword">else</span></div><div class="line">                _command_queue.enqueueBarrierWithWaitList(<span class="literal">nullptr</span>, <span class="literal">nullptr</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (cl::Error <span class="keyword">const</span>&amp; err) &#123;</div><div class="line">            <span class="keyword">throw</span> ocl_error(err);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        _last_barrier = ++_queue_counter;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/22/Cycles in Blender/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/02/22/Cycles in Blender/" itemprop="url">Cycles in Blender</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-02-22T19:02:32+08:00">
                2020-02-22
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2020/02/22/Cycles in Blender/" class="leancloud_visitors" data-flag-title="Cycles in Blender">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="0x1-Blender简介"><a href="#0x1-Blender简介" class="headerlink" title="0x1 Blender简介"></a>0x1 Blender简介</h1><p>   Blender是一款开源的跨平台全能三维动画制作软件，提供从建模、动画、材质、渲染、到音频处理、视频剪辑等一系列动画短片制作解决方案。Blender的代码大体架构如下。<br>   <img src="/2020/02/22/Cycles in Blender/architecture.png" alt=""></p>
<p>   如图所示，Blender内置了基于物理渲染的光线追踪渲染器Cycles， Cycles除了实现CPU处理以外，还提供了OpenCL和CUDA的GPU加速，可以大幅度提升渲染速度。<br>   Cycles具有如下特点。Pach-Tracer渲染算法，多核CPU加速渲染，CUDA和OpenCL的GPU渲染支持，多GPU支持，CPU与GPU 混合加速渲染内核。</p>
<p>   除了Cycles以外，Blender从2.8版本开始还提供了EEVEE渲染引擎，EEVEE同样是基于物理渲染的光线追踪渲染器，其目标是提升渲染速度，因为目前Cycles的渲染速度还是比较慢的。<br>   本文会对Blender中Cycles的执行流程做进行分析，后续也会对EEVEE的执行流程做介绍。</p>
<h1 id="0x2-Cycles中的线程模型"><a href="#0x2-Cycles中的线程模型" class="headerlink" title="0x2 Cycles中的线程模型"></a>0x2 Cycles中的线程模型</h1><p>   Cycles中的线程模型如下所示。<br>   <img src="/2020/02/22/Cycles in Blender/thread_model.png" alt=""><br>   Cycles启动以后会创建Session线程，Session会创建一个线程池，这个线程池中的线程数量是cpu的核数。只要有需要并行处理的任务就push到线程池中的queue中，然后空闲线程从queue中取得需要处理的任务并执行。<br>   上图中左边的线程是Session线程，中间的线程TaskScheduler是线程池中其中一个线程的执行过程，线程池中其他线程的执行流程类似。<br>   上图最右边最上边的框中列出了创建线程池中线程的代码。中间的框列出了线程池中的空闲线程从队列中取出任务的过程。下面的框列出了如何把任务push到线程池的代码，注意这些push操作可以在Session中执行，也可以在线程池中的线程运行过程中执行。</p>
<h1 id="0x3-创建Session"><a href="#0x3-创建Session" class="headerlink" title="0x3 创建Session"></a>0x3 创建Session</h1><p>   创建Session的流程图如下所示。<br>   <img src="/2020/02/22/Cycles in Blender/start session.svg" alt=""><br>   这个过程主要是构建Scene Graph的过程，Scene Graph的结构体定义如下，其中可以看到需要渲染的数据都保存在这个结构体中，包括Camera，Film，Shader，Mesh，Light，Integrator等。</p>
<p>   其中的sync_data过程可以理解成把数据从Blender的上层模块设置到Cycles渲染器中。这样Cycles执行光线跟踪的时候就可以用到这些设置。</p>
<p>   数据设置好了以后就可以开始render过程，这个过程是采用光线跟踪的方式渲染出图像。<br>   这个过程中需要关注的是ShaderManager, ShaderManager管理着ShaderGraph，ShaderGraph管理着Node，并且把多个Node连接起来，组成特定操作的Pipeline.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Scene</span> &#123;</span></div><div class="line"> <span class="keyword">public</span>:</div><div class="line">  <span class="comment">/* Optional name. Is used for logging and reporting. */</span></div><div class="line">  <span class="built_in">string</span> name;</div><div class="line"></div><div class="line">  <span class="comment">/* data */</span></div><div class="line">  Camera *camera;</div><div class="line">  Camera *dicing_camera;</div><div class="line">  LookupTables *lookup_tables;</div><div class="line">  Film *film;</div><div class="line">  Background *background;</div><div class="line">  Integrator *integrator;</div><div class="line"></div><div class="line">  <span class="comment">/* data lists */</span></div><div class="line">  <span class="built_in">vector</span>&lt;Object *&gt; objects;</div><div class="line">  <span class="built_in">vector</span>&lt;Mesh *&gt; meshes;</div><div class="line">  <span class="built_in">vector</span>&lt;Shader *&gt; shaders;</div><div class="line">  <span class="built_in">vector</span>&lt;Light *&gt; lights;</div><div class="line">  <span class="built_in">vector</span>&lt;ParticleSystem *&gt; particle_systems;</div><div class="line"></div><div class="line">  <span class="comment">/* data managers */</span></div><div class="line">  ImageManager *image_manager;</div><div class="line">  LightManager *light_manager;</div><div class="line">  ShaderManager *shader_manager;</div><div class="line">  MeshManager *mesh_manager;</div><div class="line">  ObjectManager *object_manager;</div><div class="line">  ParticleSystemManager *particle_system_manager;</div><div class="line">  CurveSystemManager *curve_system_manager;</div><div class="line">  BakeManager *bake_manager;</div><div class="line"></div><div class="line">  <span class="comment">/* default shaders */</span></div><div class="line">  Shader *default_surface;</div><div class="line">  Shader *default_light;</div><div class="line">  Shader *default_background;</div><div class="line">  Shader *default_empty;</div><div class="line"></div><div class="line">  <span class="comment">/* device */</span></div><div class="line">  Device *device;</div><div class="line">  DeviceScene dscene;</div><div class="line"></div><div class="line">  <span class="comment">/* parameters */</span></div><div class="line">  SceneParams params;</div><div class="line"></div><div class="line">  <span class="comment">/* mutex must be locked manually by callers */</span></div><div class="line">  thread_mutex mutex;</div><div class="line">  ......</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h1 id="0x4-光线跟踪的执行"><a href="#0x4-光线跟踪的执行" class="headerlink" title="0x4 光线跟踪的执行"></a>0x4 光线跟踪的执行</h1><p>   光线跟踪的执行流程如下所示。<br>   <img src="/2020/02/22/Cycles in Blender/path render.svg" alt=""><br>   这个过程是一个典型的光线跟踪渲染过程，先构建BVH结构体用于后续的加速，然后把一幅图像划分成tile的形式进行渲染，每个线程只处理一个tile，当然每一个位置还需要根据设置的sample的数量进行多次处理，最后根据多次处理的结果生成每一个位置对应的最后的像素值。<br>   这里的svm指的是shader virtual machine, svm对shader的执行进行了抽象，把shader中的操作提练成一个个op的形式，通过对op执行的模拟来执行shader，这些op可以理解成是shader的IR(Intermediate Representation).</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/01/12/The lifecycle of opt_gemm in tvm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/12/The lifecycle of opt_gemm in tvm/" itemprop="url">The lifecycle of opt_gemm in tvm</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-01-12T20:00:10+08:00">
                2020-01-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2020/01/12/The lifecycle of opt_gemm in tvm/" class="leancloud_visitors" data-flag-title="The lifecycle of opt_gemm in tvm">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="0x0-简介"><a href="#0x0-简介" class="headerlink" title="0x0 简介"></a>0x0 简介</h1><p>TVM是目前比较热门的深度学习编译框架，本文对tvm的函数注册机制和执行机制进行介绍，这些函数作为在python和c++代码之间交互的接口，可以理解成python和c++之间有统一的command交互接口。理解了这个交互接口，对理解tvm从python到c++的完整执行流程有很大的帮助。<br>另外本文后面以opt_gemm.py为例子，对tvm的从python到c++的执行流程进行了分析。</p>
<h1 id="0x1-函数注册"><a href="#0x1-函数注册" class="headerlink" title="0x1 函数注册"></a>0x1 函数注册</h1><p>TVM中所有上下层交互函数都封装到PackedFunc中，并且所有函数都保存在下面所示的Manager中，每一个函数都封装在Registry中，通过string作为key可以找到注册的函数并调用。tvm中使用的函数为什么要这样设计呢？好处是可以从python调用到这些函数的时候可以用统一的接口，简化接口层代码的编写，只需要把函数名作为key从Manager中找到对应的函数并调用。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// fmap以函数名称为key，保存函数列表</span></div><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Registry</span>:</span>:Manager &#123;</div><div class="line">  <span class="built_in">std</span>::<span class="built_in">unordered_map</span>&lt;<span class="built_in">std</span>::<span class="built_in">string</span>, Registry*&gt; fmap;</div><div class="line">  <span class="comment">// mutex</span></div><div class="line">  <span class="built_in">std</span>::mutex mutex;</div><div class="line"></div><div class="line">  Manager() &#123;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>Registry的定义如下，Registry提供接口把函数都封装到PackedFunc类型的变量中，后面会详细介绍这些接口。<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">class Registry &#123;</div><div class="line"> public:</div><div class="line">  Registry&amp; set_body(PackedFunc::FType f) &#123;  // NOLINT(*)</div><div class="line">    return set_body(PackedFunc(f));</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  template&lt;typename FLambda&gt;</div><div class="line">  Registry&amp; set_body_typed(FLambda f) &#123;</div><div class="line">    using FType = typename detail::function_signature&lt;FLambda&gt;::FType;</div><div class="line">    return set_body(TypedPackedFunc&lt;FType&gt;(std::move(f)).packed());</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  template&lt;typename T, typename R, typename ...Args&gt;</div><div class="line">  Registry&amp; set_body_method(R (T::*f)(Args...) const) &#123;</div><div class="line">    auto fwrap = [f](const T target, Args... params) -&gt; R &#123;</div><div class="line">      // call method pointer</div><div class="line">      return (target.*f)(params...);</div><div class="line">    &#125;;</div><div class="line">    return set_body(TypedPackedFunc&lt;R(const T, Args...)&gt;(fwrap));</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  template&lt;typename TObjectRef, typename TNode, typename R, typename ...Args,</div><div class="line">    typename = typename std::enable_if&lt;std::is_base_of&lt;ObjectRef, TObjectRef&gt;::value&gt;::type&gt;</div><div class="line">  Registry&amp; set_body_method(R (TNode::*f)(Args...)) &#123;</div><div class="line">    auto fwrap = [f](TObjectRef ref, Args... params) &#123;</div><div class="line">      TNode* target = ref.operator-&gt;();</div><div class="line">      // call method pointer</div><div class="line">      return (target-&gt;*f)(params...);</div><div class="line">    &#125;;</div><div class="line">    return set_body(TypedPackedFunc&lt;R(TObjectRef, Args...)&gt;(fwrap));</div><div class="line">  &#125;</div><div class="line">protected:</div><div class="line">  /*! \brief name of the function */</div><div class="line">  std::string name_;</div><div class="line">  /*! \brief internal packed function */</div><div class="line">  PackedFunc func_;</div><div class="line">  friend struct Manager;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>PackedFunc的定义如下。<br>PackedFunc内部使用std::function来保存函数对象。<br>TVMArgs提供了对函数参数的封装，可以包括多个参数。<br>TVMRetValue提供了对函数返回值的封装。<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">/*!</div><div class="line"> * \brief Packed function is a type-erased function.</div><div class="line"> *  The arguments are passed by packed format.</div><div class="line"> *</div><div class="line"> *  This is an useful unified interface to call generated functions,</div><div class="line"> *  It is the unified function function type of TVM.</div><div class="line"> *  It corresponds to TVMFunctionHandle in C runtime API.</div><div class="line"> */</div><div class="line">class PackedFunc &#123;</div><div class="line"> public:</div><div class="line">   /*!</div><div class="line">   * \brief The internal std::function</div><div class="line">   * \param args The arguments to the function.</div><div class="line">   * \param rv The return value.</div><div class="line">   */</div><div class="line">  using FType = std::function&lt;void (TVMArgs args, TVMRetValue* rv)&gt;;</div><div class="line">  /*! \brief default constructor */</div><div class="line">  PackedFunc() &#123;&#125;</div><div class="line">  /*! \brief constructor from null */</div><div class="line">  PackedFunc(std::nullptr_t null) &#123;&#125;  // NOLINT(*)</div><div class="line">  /*!</div><div class="line">   * \brief constructing a packed function from a std::function.</div><div class="line">   * \param body the internal container of packed function.</div><div class="line">   */</div><div class="line">  explicit PackedFunc(FType body) : body_(body) &#123;&#125;</div><div class="line"></div><div class="line"> private:</div><div class="line">  /*! \brief internal container of packed function */</div><div class="line">  FType body_;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>PackedFunc中的函数参数TVMArgs定义如下，可以支持可变长度的函数参数。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/*!</span></div><div class="line"> * \brief Union type of values</div><div class="line"> *  being passed through API and function calls.</div><div class="line"> */</div><div class="line"><span class="keyword">typedef</span> <span class="keyword">union</span> &#123;</div><div class="line">  <span class="keyword">int64_t</span> v_int64;</div><div class="line">  <span class="keyword">double</span> v_float64;</div><div class="line">  <span class="keyword">void</span>* v_handle;</div><div class="line">  <span class="keyword">const</span> <span class="keyword">char</span>* v_str;</div><div class="line">  TVMType v_type;</div><div class="line">  TVMContext v_ctx;</div><div class="line">&#125; TVMValue;</div><div class="line"></div><div class="line"><span class="comment">/*! \brief Arguments into TVM functions. */</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">TVMArgs</span> &#123;</span></div><div class="line"> <span class="keyword">public</span>:</div><div class="line">  <span class="keyword">const</span> TVMValue* values;</div><div class="line">  <span class="keyword">const</span> <span class="keyword">int</span>* type_codes;</div><div class="line">  <span class="keyword">int</span> num_args;</div></pre></td></tr></table></figure></p>
<p>下面来分析在tvm中注册执行函数的具体执行流程，包括三种方式。</p>
<h2 id="0x11-通过set-body-typed的注册"><a href="#0x11-通过set-body-typed的注册" class="headerlink" title="0x11 通过set_body_typed的注册"></a>0x11 通过set_body_typed的注册</h2><p>下图说明了通过set_body_typed来注册函数对象到Registry::Manager的详细过程。<br><img src="/2020/01/12/The lifecycle of opt_gemm in tvm/set_body_typed.png" alt=""></p>
<p>下面是set_body_typed注册函数对象的举例说明。<br>relay模块中通过set_body_typed的注册方式来注册函数_make.relu。<br>注意这个函数内部还通过Op::Get()来得到op operator，这个op operator的管理在本文0x14小节中介绍。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// src\relay\op\nn\nn.cc</span></div><div class="line">TVM_REGISTER_GLOBAL(<span class="string">"relay.op.nn._make.relu"</span>)</div><div class="line">.set_body_typed([](Expr data) &#123;</div><div class="line">    <span class="keyword">static</span> <span class="keyword">const</span> Op&amp; op = Op::Get(<span class="string">"nn.relu"</span>);</div><div class="line">    <span class="keyword">return</span> CallNode::make(op, &#123;data&#125;, Attrs(), &#123;&#125;);</div><div class="line">  &#125;);</div></pre></td></tr></table></figure>
<p>relay模块依赖于topi层的实现，topi层中对relu的定义如下。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">// topi\include\topi\nn.h</div><div class="line">template &lt;typename T&gt;</div><div class="line">inline tvm::Tensor relu(const tvm::Tensor&amp; t,</div><div class="line">                        T threshold = static_cast&lt;T&gt;(0),</div><div class="line">                        std::string name = "T_relu",</div><div class="line">                        std::string tag = kElementWise) &#123;</div><div class="line">  return tvm::compute(</div><div class="line">      t-&gt;shape,</div><div class="line">      [&amp;](const tvm::Array&lt;tvm::Var&gt;&amp; i) &#123;</div><div class="line">        auto threshold_const = tvm::make_const(t-&gt;dtype, threshold);</div><div class="line">        return tvm::max(t(i), threshold_const);</div><div class="line">      &#125;,</div><div class="line">      name,</div><div class="line">      tag);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>最后调用到lang模块中实现的tvm::max，构造出相应的TVM IR。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// src\lang\expr_operator.cc</span></div><div class="line"><span class="function">Expr <span class="title">max</span><span class="params">(Expr a, Expr b)</span> </span>&#123;</div><div class="line">  <span class="comment">// inf-aware simplificaiton</span></div><div class="line">  <span class="keyword">using</span> arith::is_pos_inf;</div><div class="line">  <span class="keyword">using</span> arith::is_neg_inf;</div><div class="line">  <span class="keyword">if</span> (is_pos_inf(a)) <span class="keyword">return</span> a;</div><div class="line">  <span class="keyword">if</span> (is_neg_inf(a)) <span class="keyword">return</span> b;</div><div class="line">  <span class="keyword">if</span> (is_pos_inf(b)) <span class="keyword">return</span> b;</div><div class="line">  <span class="keyword">if</span> (is_neg_inf(b)) <span class="keyword">return</span> a;</div><div class="line">  BinaryOpMatchTypes(a, b);</div><div class="line">  Expr ret = arith::TryConstFold&lt;ir::Max&gt;(a, b);</div><div class="line">  <span class="keyword">if</span> (ret.defined()) <span class="keyword">return</span> ret;</div><div class="line">  <span class="keyword">return</span> ir::Max::make(a, b);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>最后python模块中的relay层对relu的实现提供了python封装。这样python就可以调用到前面介绍的C++模块中的对应实现。<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">// python\tvm\relay\op\nn\nn.py</div><div class="line">def relu(data):</div><div class="line">    """Rectified linear unit.</div><div class="line">    return _make.relu(data)</div></pre></td></tr></table></figure></p>
<h2 id="0x12-通过set-body-method的注册"><a href="#0x12-通过set-body-method的注册" class="headerlink" title="0x12 通过set_body_method的注册"></a>0x12 通过set_body_method的注册</h2><p>下图说明了通过set_body_method来注册函数对象到Registry::Manager的详细过程。<br><img src="/2020/01/12/The lifecycle of opt_gemm in tvm/set_body_method.png" alt=""><br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">下面是一个set_body_method的调用示例。</div><div class="line"><span class="comment">// src\api\api_lang.cc</span></div><div class="line">TVM_REGISTER_GLOBAL(<span class="string">"_BijectiveLayoutBackwardShape"</span>)</div><div class="line">.set_body_method(&amp;BijectiveLayout::BackwardShape);</div></pre></td></tr></table></figure></p>
<h2 id="0x13-通过set-body的注册"><a href="#0x13-通过set-body的注册" class="headerlink" title="0x13 通过set_body的注册"></a>0x13 通过set_body的注册</h2><p>下图说明了通过set_body来注册函数对象到Registry::Manager的详细过程。<br><img src="/2020/01/12/The lifecycle of opt_gemm in tvm/set_body.png" alt=""></p>
<p>下面是一个set_body的调用示例。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">TVM_REGISTER_GLOBAL(<span class="string">"device_api.opencl"</span>)</div><div class="line">.set_body([](TVMArgs args, TVMRetValue* rv) &#123;</div><div class="line">    DeviceAPI* ptr = OpenCLWorkspace::Global().get();</div><div class="line">    *rv = <span class="keyword">static_cast</span>&lt;<span class="keyword">void</span>*&gt;(ptr);</div><div class="line">  &#125;);</div></pre></td></tr></table></figure></p>
<h2 id="0x14-Relay-OP注册"><a href="#0x14-Relay-OP注册" class="headerlink" title="0x14 Relay OP注册"></a>0x14 Relay OP注册</h2><p>Relay OP保存在另外一个OpManager中，和前面的函数注册不是一个地方，这是因为这个OpManager管理的是relay operator函数，这些函数不会直接从python中调用过来。</p>
<p>OpManager的相关代码如下。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// src\relay\ir\op.cc</span></div><div class="line">::dmlc::Registry&lt;OpRegistry&gt;* OpRegistry::Registry() &#123;</div><div class="line">  <span class="keyword">return</span> ::dmlc::Registry&lt;OpRegistry&gt;::Get();</div><div class="line">&#125;</div><div class="line"><span class="comment">// single manager of operator information.</span></div><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">OpManager</span> &#123;</span></div><div class="line">  <span class="comment">// mutex to avoid registration from multiple threads.</span></div><div class="line">  <span class="built_in">std</span>::mutex mutex;</div><div class="line">  <span class="comment">// global operator counter</span></div><div class="line">  <span class="built_in">std</span>::atomic&lt;<span class="keyword">int</span>&gt; op_counter&#123;<span class="number">0</span>&#125;;</div><div class="line">  <span class="comment">// storage of additional attribute table.</span></div><div class="line">  <span class="built_in">std</span>::<span class="built_in">unordered_map</span>&lt;<span class="built_in">std</span>::<span class="built_in">string</span>, <span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;GenericOpMap&gt;&gt; attr;</div><div class="line">  <span class="comment">// frontend functions</span></div><div class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;PackedFunc*&gt; frontend_funcs;</div><div class="line">  <span class="comment">// get singleton of the op manager</span></div><div class="line">  <span class="function"><span class="keyword">static</span> OpManager* <span class="title">Global</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">static</span> OpManager* inst = <span class="keyword">new</span> OpManager();</div><div class="line">    <span class="keyword">return</span> inst;</div><div class="line">  &#125;</div><div class="line">&#125;;</div><div class="line"></div><div class="line"><span class="comment">// find operator by name</span></div><div class="line"><span class="keyword">const</span> Op&amp; Op::Get(<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; name) &#123;</div><div class="line">  <span class="keyword">const</span> OpRegistry* reg = dmlc::Registry&lt;OpRegistry&gt;::Find(name);</div><div class="line">  CHECK(reg != <span class="literal">nullptr</span>) &lt;&lt; <span class="string">"Operator "</span> &lt;&lt; name &lt;&lt; <span class="string">" is not registered"</span>;</div><div class="line">  <span class="keyword">return</span> reg-&gt;op();</div><div class="line">&#125;</div><div class="line"></div><div class="line">OpRegistry::OpRegistry() &#123;</div><div class="line">  OpManager* mgr = OpManager::Global();</div><div class="line">  ObjectPtr&lt;OpNode&gt; n = make_object&lt;OpNode&gt;();</div><div class="line">  n-&gt;index_ = mgr-&gt;op_counter++;</div><div class="line">  op_ = Op(n);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> EntryType&gt;</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Registry</span> &#123;</span></div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>下面是调用OpManager来注册op函数的代码示例。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">RELAY_REGISTER_OP(<span class="string">"argsort"</span>)</div><div class="line">.describe(<span class="string">R"doc(Returns the indices that would sort an</span></div><div class="line">input array along the given axis.</div><div class="line">)doc" TVM_ADD_FILELINE)</div><div class="line">.set_num_inputs(<span class="number">1</span>)</div><div class="line">.set_attrs_type&lt;ArgsortAttrs&gt;()</div><div class="line">.add_argument(<span class="string">"data"</span>, <span class="string">"Tensor"</span>, <span class="string">"Input data."</span>)</div><div class="line">.set_support_level(<span class="number">6</span>)</div><div class="line">.add_type_rel(<span class="string">"Argsort"</span>, ArgsortRel);</div></pre></td></tr></table></figure></p>
<p>如何取得OpManager中注册的op函数呢？答案是像下面这段代码所示通过调用Op::Get()来得到。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Cache the operators that are checked </span></div><div class="line"><span class="comment">// recursively to reduce lookup overhead.</span></div><div class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">auto</span>&amp; expand_dims_op = Op::Get(<span class="string">"expand_dims"</span>);</div><div class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">auto</span>&amp; reshape_op = Op::Get(<span class="string">"reshape"</span>);</div><div class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">auto</span>&amp; transpose_op = Op::Get(<span class="string">"transpose"</span>);</div><div class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">auto</span>&amp; squeeze_op = Op::Get(<span class="string">"squeeze"</span>);</div></pre></td></tr></table></figure></p>
<h1 id="0x2-执行流程介绍"><a href="#0x2-执行流程介绍" class="headerlink" title="0x2 执行流程介绍"></a>0x2 执行流程介绍</h1><p>前面介绍了执行函数是如何注册的，那这些函数是怎样被python调用到的呢？下面来介绍一下。<br>我们知道从python调用过来的接口定义在c_runtime_api.h头文件中，这其中比较重要的是这两个API，TVMFuncCall()和TVMArrayAlloc，从API的名称上可知，TVMFuncCall对应于从python来的函数调用，TVMArrayAlloc对应于数组的分配。<br>这两个API接口定义如下。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// tvm\include\tvm\runtime\c_runtime_api.h</span></div><div class="line"></div><div class="line"><span class="function">TVM_DLL <span class="keyword">int</span> <span class="title">TVMFuncCall</span><span class="params">(TVMFunctionHandle func,</span></span></div><div class="line">                        TVMValue* arg_values,</div><div class="line">                        <span class="keyword">int</span>* type_codes,</div><div class="line">                        <span class="keyword">int</span> num_args,</div><div class="line">                        TVMValue* ret_val,</div><div class="line">                        <span class="keyword">int</span>* ret_type_code);</div><div class="line"></div><div class="line"><span class="function">TVM_DLL <span class="keyword">int</span> <span class="title">TVMArrayAlloc</span><span class="params">(<span class="keyword">const</span> <span class="keyword">tvm_index_t</span>* shape,</span></span></div><div class="line">                          <span class="keyword">int</span> ndim,</div><div class="line">                          <span class="keyword">int</span> dtype_code,</div><div class="line">                          <span class="keyword">int</span> dtype_bits,</div><div class="line">                          <span class="keyword">int</span> dtype_lanes,</div><div class="line">                          <span class="keyword">int</span> device_type,</div><div class="line">                          <span class="keyword">int</span> device_id,</div><div class="line">                          TVMArrayHandle* out);</div></pre></td></tr></table></figure></p>
<p>然而python是如何知道前面的函数Manager中包括了哪些函数呢？这个时候Manager提供了一个函数供上层来调用得到所有注册函数名称列表，这个函数的定义如下。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">TVMFuncListGlobalNames</span><span class="params">(<span class="keyword">int</span> *out_size,</span></span></div><div class="line">                           <span class="keyword">const</span> <span class="keyword">char</span>*** out_array) &#123;</div><div class="line">  API_BEGIN();</div><div class="line">  TVMFuncThreadLocalEntry *ret = TVMFuncThreadLocalStore::Get();</div><div class="line">  ret-&gt;ret_vec_str = tvm::runtime::Registry::ListNames();</div><div class="line">  ret-&gt;ret_vec_charp.clear();</div><div class="line">  <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; ret-&gt;ret_vec_str.size(); ++i) &#123;</div><div class="line">    ret-&gt;ret_vec_charp.push_back(ret-&gt;ret_vec_str[i].c_str());</div><div class="line">  &#125;</div><div class="line">  *out_array = dmlc::BeginPtr(ret-&gt;ret_vec_charp);</div><div class="line">  *out_size = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(ret-&gt;ret_vec_str.size());</div><div class="line">  API_END();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>然后python层根据前面的函数名称列表，通过下面的函数来得到每一个函数名称所对应的函数对象，python层拿到了这些函数对象以后，会在python层也创建相应的函数对象。这样python和c++层的函数操作就可以对应起来了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">TVMFuncGetGlobal</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span>* name, TVMFunctionHandle* out)</span> </span>&#123;</div><div class="line">  API_BEGIN();</div><div class="line">  <span class="keyword">const</span> tvm::runtime::PackedFunc* fp =</div><div class="line">      tvm::runtime::Registry::Get(name);</div><div class="line">  <span class="keyword">if</span> (fp != <span class="literal">nullptr</span>) &#123;</div><div class="line">    *out = <span class="keyword">new</span> tvm::runtime::PackedFunc(*fp);  <span class="comment">// NOLINT(*)</span></div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    *out = <span class="literal">nullptr</span>;</div><div class="line">  &#125;</div><div class="line">  API_END();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>在python中创建函数对象的代码如下，先根据函数TVMFuncGetGlobal()来查找底层的函数对象，找到以后根据返回的handle创建上层函数对象Function。<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">def get_global_func(name, allow_missing=False):</div><div class="line">    handle = FunctionHandle()</div><div class="line">    check_call(_LIB.TVMFuncGetGlobal(c_str(name), ctypes.byref(handle)))</div><div class="line">    if handle.value:</div><div class="line">        return Function(handle, False)</div><div class="line"></div><div class="line">    if allow_missing:</div><div class="line">        return None</div><div class="line"></div><div class="line">    raise ValueError("Cannot find global function %s" % name)</div></pre></td></tr></table></figure></p>
<p>下面来介绍一下函数调用是如何从python层调用到C++层的，其中核心是要理解TVMFuncCall的调用过程。</p>
<h2 id="0x21-TVMFuncCall的调用过程"><a href="#0x21-TVMFuncCall的调用过程" class="headerlink" title="0x21 TVMFuncCall的调用过程"></a>0x21 TVMFuncCall的调用过程</h2><p>Python中调用TVMFuncCall的代码如下所示，其中包括了函数参数的封装。<br>self.handle是python中持有的C++ PackedFunc对象。<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">class FunctionBase(object):</div><div class="line">    def __call__(self, *args):</div><div class="line"></div><div class="line">        temp_args = []</div><div class="line">        values, tcodes, num_args = _make_tvm_args(args, temp_args)</div><div class="line">        ret_val = TVMValue()</div><div class="line">        ret_tcode = ctypes.c_int()</div><div class="line">        if _LIB.TVMFuncCall(</div><div class="line">                self.handle, values, tcodes, ctypes.c_int(num_args),</div><div class="line">                ctypes.byref(ret_val), ctypes.byref(ret_tcode)) != 0:</div><div class="line">            raise get_last_ffi_error()</div><div class="line">        _ = temp_args</div><div class="line">        _ = args</div><div class="line">        return RETURN_SWITCH[ret_tcode.value](ret_val)</div></pre></td></tr></table></figure></p>
<p>从Python代码调用到C++代码的入口函数如下。<br>函数参数func是封装好的PackedFunc对象。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// src\runtime\c_runtime_api.cc</span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">TVMFuncCall</span><span class="params">(TVMFunctionHandle func,</span></span></div><div class="line">                TVMValue* args,</div><div class="line">                <span class="keyword">int</span>* arg_type_codes,</div><div class="line">                <span class="keyword">int</span> num_args,</div><div class="line">                TVMValue* ret_val,</div><div class="line">                <span class="keyword">int</span>* ret_type_code) &#123;</div><div class="line">  API_BEGIN();</div><div class="line">  TVMRetValue rv;</div><div class="line">  (*<span class="keyword">static_cast</span>&lt;<span class="keyword">const</span> PackedFunc*&gt;(func)).CallPacked(</div><div class="line">      TVMArgs(args, arg_type_codes, num_args), &amp;rv);</div><div class="line">  <span class="comment">// handle return string.</span></div><div class="line">  <span class="keyword">if</span> (rv.type_code() == kStr ||</div><div class="line">      rv.type_code() == kTVMType ||</div><div class="line">      rv.type_code() == kBytes) &#123;</div><div class="line">    TVMRuntimeEntry* e = TVMAPIRuntimeStore::Get();</div><div class="line">    <span class="keyword">if</span> (rv.type_code() != kTVMType) &#123;</div><div class="line">      e-&gt;ret_str = *rv.ptr&lt;<span class="built_in">std</span>::<span class="built_in">string</span>&gt;();</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      e-&gt;ret_str = rv.<span class="keyword">operator</span> <span class="built_in">std</span>::<span class="built_in">string</span>();</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">if</span> (rv.type_code() == kBytes) &#123;</div><div class="line">      e-&gt;ret_bytes.data = e-&gt;ret_str.c_str();</div><div class="line">      e-&gt;ret_bytes.size = e-&gt;ret_str.length();</div><div class="line">      *ret_type_code = kBytes;</div><div class="line">      ret_val-&gt;v_handle = &amp;(e-&gt;ret_bytes);</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      *ret_type_code = kStr;</div><div class="line">      ret_val-&gt;v_str = e-&gt;ret_str.c_str();</div><div class="line">    &#125;</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    rv.MoveToCHost(ret_val, ret_type_code);</div><div class="line">  &#125;</div><div class="line">  API_END();</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// tvm\include\tvm\runtime\packed_func.h</span></div><div class="line"><span class="keyword">inline</span> <span class="keyword">void</span> PackedFunc::CallPacked(TVMArgs args, TVMRetValue* rv) <span class="keyword">const</span> &#123;</div><div class="line">  body_(args, rv);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>下面执行对body_的调用，利用可变参数模板的递归展开来实现，这样就可以调用到真正的注册函数了。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// include\tvm\runtime\packed_func.h</span></div><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> R, <span class="keyword">typename</span> ...Args&gt;</div><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> FType&gt;</div><div class="line"><span class="keyword">inline</span> <span class="keyword">void</span> TypedPackedFunc&lt;R(Args...)&gt;::AssignTypedLambda(FType flambda) &#123;</div><div class="line">  packed_ = PackedFunc([flambda](<span class="keyword">const</span> TVMArgs&amp; args, TVMRetValue* rv) &#123;</div><div class="line">      detail::unpack_call&lt;R, <span class="keyword">sizeof</span>...(Args)&gt;(flambda, args, rv);</div><div class="line">    &#125;);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> R, <span class="keyword">int</span> nargs, <span class="keyword">typename</span> F&gt;</div><div class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">unpack_call</span><span class="params">(<span class="keyword">const</span> F&amp; f, <span class="keyword">const</span> TVMArgs&amp; args, TVMRetValue* rv)</span> </span>&#123;</div><div class="line">  unpack_call_dispatcher&lt;R, nargs, <span class="number">0</span>, F&gt;::run(f, args, rv);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> R, <span class="keyword">int</span> nleft, <span class="keyword">int</span> index, <span class="keyword">typename</span> F&gt;</div><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">unpack_call_dispatcher</span> &#123;</span></div><div class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> ...Args&gt;</div><div class="line">  <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(<span class="keyword">const</span> F&amp; f,</span></span></div><div class="line">                  <span class="keyword">const</span> TVMArgs&amp; args_pack,</div><div class="line">                  TVMRetValue* rv,</div><div class="line">                  Args&amp;&amp;... unpacked_args) &#123;</div><div class="line">    unpack_call_dispatcher&lt;R, nleft - <span class="number">1</span>, index + <span class="number">1</span>, F&gt;</div><div class="line">        ::run(f, args_pack, rv,</div><div class="line">              <span class="built_in">std</span>::forward&lt;Args&gt;(unpacked_args)...,</div><div class="line">              args_pack[index]);</div><div class="line">  &#125;</div><div class="line">&#125;;</div><div class="line"></div><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> R, <span class="keyword">int</span> index, <span class="keyword">typename</span> F&gt;</div><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">unpack_call_dispatcher</span>&lt;R, 0, index, F&gt; &#123;</span></div><div class="line">  <span class="keyword">template</span>&lt;<span class="keyword">typename</span> ...Args&gt;</div><div class="line">  <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(<span class="keyword">const</span> F&amp; f,</span></span></div><div class="line">                  <span class="keyword">const</span> TVMArgs&amp; args_pack,</div><div class="line">                  TVMRetValue* rv,</div><div class="line">                  Args&amp;&amp;... unpacked_args) &#123;</div><div class="line">    *rv = R(f(<span class="built_in">std</span>::forward&lt;Args&gt;(unpacked_args)...));</div><div class="line">  &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>最后可以看到调用的是Variable::make来生成tvm IR。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// src\api\api_ir.cc</span></div><div class="line">TVM_REGISTER_GLOBAL(<span class="string">"_Var"</span>)</div><div class="line">.set_body_typed([](<span class="built_in">std</span>::<span class="built_in">string</span> s, DataType t) &#123;</div><div class="line">    <span class="keyword">return</span> Variable::make(t, s);</div><div class="line">  &#125;);</div></pre></td></tr></table></figure>
<h2 id="0x22-TVMArrayAlloc的调用过程"><a href="#0x22-TVMArrayAlloc的调用过程" class="headerlink" title="0x22 TVMArrayAlloc的调用过程"></a>0x22 TVMArrayAlloc的调用过程</h2><p>TVMArrayAlloc的调用过程比较简单，直接调用NDArray的接口来分配Array。<br>  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">  <span class="function"><span class="keyword">int</span> <span class="title">TVMArrayAlloc</span><span class="params">(<span class="keyword">const</span> <span class="keyword">tvm_index_t</span>* shape,</span></span></div><div class="line">                  <span class="keyword">int</span> ndim,</div><div class="line">                  <span class="keyword">int</span> dtype_code,</div><div class="line">                  <span class="keyword">int</span> dtype_bits,</div><div class="line">                  <span class="keyword">int</span> dtype_lanes,</div><div class="line">                  <span class="keyword">int</span> device_type,</div><div class="line">                  <span class="keyword">int</span> device_id,</div><div class="line">                  TVMArrayHandle* out) &#123;</div><div class="line">  API_BEGIN();</div><div class="line">  DLDataType dtype;</div><div class="line">  dtype.code = <span class="keyword">static_cast</span>&lt;<span class="keyword">uint8_t</span>&gt;(dtype_code);</div><div class="line">  dtype.bits = <span class="keyword">static_cast</span>&lt;<span class="keyword">uint8_t</span>&gt;(dtype_bits);</div><div class="line">  dtype.lanes = <span class="keyword">static_cast</span>&lt;<span class="keyword">uint16_t</span>&gt;(dtype_lanes);</div><div class="line">  DLContext ctx;</div><div class="line">  ctx.device_type = <span class="keyword">static_cast</span>&lt;DLDeviceType&gt;(device_type);</div><div class="line">  ctx.device_id = device_id;</div><div class="line">  *out = NDArray::Internal::MoveToFFIHandle(</div><div class="line">      NDArray::Empty(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int64_t</span>&gt;(shape, shape + ndim), dtype, ctx));</div><div class="line">  API_END();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h1 id="0x03-opt-gemm-py执行流程分析"><a href="#0x03-opt-gemm-py执行流程分析" class="headerlink" title="0x03 opt_gemm.py执行流程分析"></a>0x03 opt_gemm.py执行流程分析</h1><p>下面来分析tvm自带的矩阵优化测试程序opt_gemm.py的执行流程。</p>
<h2 id="0x31-根据算法创建数据流图"><a href="#0x31-根据算法创建数据流图" class="headerlink" title="0x31 根据算法创建数据流图"></a>0x31 根据算法创建数据流图</h2><p>python代码如下，这部分描述了算法是两个矩阵相乘，根据矩阵的大小分配了相应的占位符placeholder,placeholder和tensorflow中的概念类似。然后调用compute()函数创建tvm IR。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">M = <span class="number">1024</span></div><div class="line">K = <span class="number">1024</span></div><div class="line">N = <span class="number">1024</span></div><div class="line"></div><div class="line">k = tvm.reduce_axis((<span class="number">0</span>, K), <span class="string">'k'</span>)</div><div class="line">A = tvm.placeholder((M, K), name=<span class="string">'A'</span>)</div><div class="line">B = tvm.placeholder((K, N), name=<span class="string">'B'</span>)</div><div class="line">C = tvm.compute(</div><div class="line">           (M, N),</div><div class="line">           lambda x, y: tvm.sum(A[x, k] * B[k, y], axis=k),</div><div class="line">           name=<span class="string">'C'</span>)</div></pre></td></tr></table></figure></p>
<p>上面算法描述对应到C++代码中，会创建相应的tvm node，这部分可以理解成是tvm的IR的生成。<br>下面的代码描述了上述python流程执行的最后创建ComputeOpNode的过程。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">Operation ComputeOpNode::make(<span class="built_in">std</span>::<span class="built_in">string</span> name,</div><div class="line">                              <span class="built_in">std</span>::<span class="built_in">string</span> tag,</div><div class="line">                              Map&lt;<span class="built_in">std</span>::<span class="built_in">string</span>, ObjectRef&gt; attrs,</div><div class="line">                              Array&lt;IterVar&gt; axis,</div><div class="line">                              Array&lt;Expr&gt; body) &#123;</div><div class="line">  <span class="keyword">if</span> (!attrs.defined()) &#123;</div><div class="line">    attrs = Map&lt;<span class="built_in">std</span>::<span class="built_in">string</span>, ObjectRef&gt;();</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">auto</span> n = make_object&lt;ComputeOpNode&gt;();</div><div class="line">  n-&gt;name = <span class="built_in">std</span>::move(name);</div><div class="line">  n-&gt;tag = <span class="built_in">std</span>::move(tag);</div><div class="line">  n-&gt;attrs = <span class="built_in">std</span>::move(attrs);</div><div class="line">  n-&gt;axis = <span class="built_in">std</span>::move(axis);</div><div class="line">  n-&gt;body = <span class="built_in">std</span>::move(body);</div><div class="line">  <span class="keyword">if</span> (n-&gt;body[<span class="number">0</span>]-&gt;IsInstance&lt;ir::Reduce&gt;()) &#123;</div><div class="line">    <span class="keyword">const</span> ir::Reduce* reduce = n-&gt;body[<span class="number">0</span>].as&lt;ir::Reduce&gt;();</div><div class="line">    n-&gt;reduce_axis = reduce-&gt;axis;</div><div class="line">  &#125;</div><div class="line">  VerifyComputeOp(n.get());</div><div class="line">  <span class="keyword">return</span> Operation(n);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="0x32-创建Schedule"><a href="#0x32-创建Schedule" class="headerlink" title="0x32 创建Schedule"></a>0x32 创建Schedule</h2><p>python代码如下。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">s = tvm.create_schedule(C.op)</div></pre></td></tr></table></figure></p>
<p>对应的C++代码如下，这个时候会根据前面创建的tvm IR来生成reader graph，reader graph中描述了node之间的数据依赖关系。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line">Schedule ScheduleNode::make(Array&lt;Operation&gt; ops) &#123;</div><div class="line">  <span class="keyword">auto</span> n = make_object&lt;ScheduleNode&gt;();</div><div class="line">  <span class="function">Schedule <span class="title">sch</span><span class="params">(n)</span></span>;</div><div class="line">  n-&gt;outputs = ops;</div><div class="line">  <span class="keyword">auto</span> g = schedule::CreateReadGraph(n-&gt;outputs);</div><div class="line">  Array&lt;Operation&gt; post_order = schedule::PostDFSOrder(n-&gt;outputs, g);</div><div class="line">  <span class="comment">// output set.</span></div><div class="line">  <span class="built_in">std</span>::<span class="built_in">unordered_set</span>&lt;Operation&gt; output_set;</div><div class="line">  <span class="keyword">for</span> (Operation x : ops) &#123;</div><div class="line">    output_set.insert(x);</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">for</span> (Operation op : post_order) &#123;</div><div class="line">    <span class="function">Stage <span class="title">stage</span><span class="params">(op)</span></span>;</div><div class="line">    stage-&gt;is_output = output_set.count(op) != <span class="number">0</span>;</div><div class="line">    n-&gt;stages.push_back(stage);</div><div class="line">    n-&gt;stage_map.Set(op, stage);</div><div class="line">    <span class="comment">// mark scan updates.</span></div><div class="line">    <span class="keyword">if</span> (<span class="keyword">const</span> ScanOpNode* scan = op.as&lt;ScanOpNode&gt;()) &#123;</div><div class="line">      Array&lt;Tensor&gt; inputs;</div><div class="line">      <span class="keyword">for</span> (Tensor t : scan-&gt;state_placeholder) &#123;</div><div class="line">        inputs.push_back(t);</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">for</span> (Tensor t : scan-&gt;inputs) &#123;</div><div class="line">        inputs.push_back(t);</div><div class="line">      &#125;</div><div class="line">      <span class="comment">// Create the scan group.</span></div><div class="line">      Stage scan_group = sch.create_group(scan-&gt;update, inputs, <span class="literal">false</span>);</div><div class="line">      scan_group-&gt;attach_type = kScanUpdate;</div><div class="line">      scan_group-&gt;attach_stage = stage;</div><div class="line"></div><div class="line">      <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; scan-&gt;update.size(); ++i) &#123;</div><div class="line">        Stage s = n-&gt;stage_map[scan-&gt;update[i]-&gt;op];</div><div class="line">        CHECK(scan_group.same_as(s-&gt;group));</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">return</span> sch;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="0x32-用TVM-Pass来处理schedule生成的graph"><a href="#0x32-用TVM-Pass来处理schedule生成的graph" class="headerlink" title="0x32 用TVM Pass来处理schedule生成的graph"></a>0x32 用TVM Pass来处理schedule生成的graph</h2><p>执行下面的测试代码以后会调用下面的语句来创建stmt。<br>func = tvm.build(s, [A, B, C], target=target, name=’mmult’)</p>
<p>其Python代码如下。<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div></pre></td><td class="code"><pre><div class="line">def lower(sch,</div><div class="line">          args,</div><div class="line">          name="default_function",</div><div class="line">          binds=None,</div><div class="line">          simple_mode=False):</div><div class="line"> </div><div class="line">    cfg = current_build_config()</div><div class="line">    add_lower_pass = cfg.add_lower_pass if cfg.add_lower_pass else []</div><div class="line">    if cfg.dump_pass_ir:</div><div class="line">        add_lower_pass = BuildConfig._dump_ir.decorate_custompass(add_lower_pass)</div><div class="line">    lower_phase0 = [x[1] for x in add_lower_pass if x[0] == 0]</div><div class="line">    lower_phase1 = [x[1] for x in add_lower_pass if x[0] == 1]</div><div class="line">    lower_phase2 = [x[1] for x in add_lower_pass if x[0] == 2]</div><div class="line">    lower_phase3 = [x[1] for x in add_lower_pass if x[0] &gt; 2]</div><div class="line"></div><div class="line">    # Phase 0</div><div class="line">    if isinstance(sch, schedule.Schedule):</div><div class="line">        stmt = form_body(sch)</div><div class="line"></div><div class="line">    for f in lower_phase0:</div><div class="line">        stmt = f(stmt)</div><div class="line"></div><div class="line">    compact = ir_pass.VerifyCompactBuffer(stmt)</div><div class="line">    binds, arg_list = get_binds(args, compact, binds)</div><div class="line"></div><div class="line">    # Phase 1</div><div class="line">    stmt = ir_pass.RewriteForTensorCore(stmt, sch, binds)</div><div class="line">    stmt = ir_pass.StorageFlatten(stmt, binds, 64, cfg.instrument_bound_checkers)</div><div class="line">    stmt = ir_pass.CanonicalSimplify(stmt)</div><div class="line">    for f in lower_phase1:</div><div class="line">        stmt = f(stmt)</div><div class="line"></div><div class="line">    # Phase 2</div><div class="line">    if not simple_mode:</div><div class="line">        stmt = ir_pass.LoopPartition(stmt, cfg.partition_const_loop)</div><div class="line">    if cfg.disable_vectorize:</div><div class="line">        stmt = ir_pass.SkipVectorize(stmt)</div><div class="line">    else:</div><div class="line">        stmt = ir_pass.VectorizeLoop(stmt)</div><div class="line">    stmt = ir_pass.InjectVirtualThread(stmt)</div><div class="line">    stmt = ir_pass.InjectDoubleBuffer(stmt, cfg.double_buffer_split_loop)</div><div class="line">    stmt = ir_pass.StorageRewrite(stmt)</div><div class="line">    stmt = ir_pass.UnrollLoop(</div><div class="line">        stmt,</div><div class="line">        cfg.auto_unroll_max_step,</div><div class="line">        cfg.auto_unroll_max_depth,</div><div class="line">        cfg.auto_unroll_max_extent,</div><div class="line">        cfg.unroll_explicit)</div><div class="line">    for f in lower_phase2:</div><div class="line">        stmt = f(stmt)</div><div class="line"></div><div class="line">    # Phase 3</div><div class="line">    stmt = ir_pass.Simplify(stmt)</div><div class="line">    stmt = ir_pass.RemoveNoOp(stmt)</div><div class="line">    if not cfg.disable_select_rewriting:</div><div class="line">        stmt = ir_pass.RewriteUnsafeSelect(stmt)</div><div class="line">    for f in lower_phase3:</div><div class="line">        stmt = f(stmt)</div><div class="line">    # Instrument BoundCheckers</div><div class="line">    if cfg.instrument_bound_checkers:</div><div class="line">        stmt = ir_pass.InstrumentBoundCheckers(stmt)</div><div class="line">    if simple_mode:</div><div class="line">        return stmt</div><div class="line"></div><div class="line">    return ir_pass.MakeAPI(stmt, name, arg_list, 0, cfg.restricted_func)</div></pre></td></tr></table></figure></p>
<p>前面的ir_pass.xxx函数调用都会对应到C++的实现，这些pass是tvm中实现的中间流程处理操作，<br>例如前面的函数中执行的下列python代码，<br>stmt = ir_pass.RemoveNoOp(stmt)<br>其对应的C++代码如下所示。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// src\pass\remove_no_op.cc</span></div><div class="line"><span class="comment">// Mark the statment of each stage.</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">NoOpRemover</span> :</span> <span class="keyword">public</span> StmtMutator &#123;</div><div class="line"> <span class="keyword">public</span>:</div><div class="line">  <span class="function">Stmt <span class="title">VisitStmt_</span><span class="params">(<span class="keyword">const</span> LetStmt* op)</span> final </span>&#123;</div><div class="line">    Stmt stmt = StmtMutator::VisitStmt_(op);</div><div class="line">    op = stmt.as&lt;LetStmt&gt;();</div><div class="line">    <span class="keyword">return</span> is_no_op(op-&gt;body) ? MakeEvaluate(op-&gt;value) : stmt;</div><div class="line">  &#125;</div><div class="line">  <span class="function">Stmt <span class="title">VisitStmt_</span><span class="params">(<span class="keyword">const</span> AttrStmt* op)</span> final </span>&#123;</div><div class="line">    <span class="keyword">if</span> (op-&gt;attr_key == <span class="string">"pragma_debug_skip_region"</span>) &#123;</div><div class="line">      <span class="keyword">return</span> MakeEvaluate(<span class="number">0</span>);</div><div class="line">    &#125;</div><div class="line">    Stmt stmt = StmtMutator::VisitStmt_(op);</div><div class="line">    op = stmt.as&lt;AttrStmt&gt;();</div><div class="line">    <span class="keyword">return</span> is_no_op(op-&gt;body) ? MakeEvaluate(op-&gt;value) : stmt;</div><div class="line">  &#125;</div><div class="line">  ......</div><div class="line">&#125;;</div><div class="line"></div><div class="line"><span class="function">Stmt <span class="title">RemoveNoOp</span><span class="params">(Stmt stmt)</span> </span>&#123;</div><div class="line">  <span class="keyword">return</span> NoOpRemover()(<span class="built_in">std</span>::move(stmt));</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="0x33-把前面优化过的Pass调用LLVM-codegen来生成LLVM-IR"><a href="#0x33-把前面优化过的Pass调用LLVM-codegen来生成LLVM-IR" class="headerlink" title="0x33 把前面优化过的Pass调用LLVM codegen来生成LLVM IR"></a>0x33 把前面优化过的Pass调用LLVM codegen来生成LLVM IR</h2><p>python代码如下。<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">def build_module(lowered_func, target):</div><div class="line">    return _Build(lowered_func, target)</div></pre></td></tr></table></figure></p>
<p>C++代码如下，该段代码把tvm IR翻译成LLVM IR。<br>在其调用的Finish()函数中还会采用LLVM PassManager对已经生成的LLVM IR进行进一步优化。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">Init</span><span class="params">(<span class="keyword">const</span> Array&lt;LoweredFunc&gt;&amp; funcs, <span class="built_in">std</span>::<span class="built_in">string</span> target)</span> </span>&#123;</div><div class="line">    InitializeLLVM();</div><div class="line">    tm_ = GetLLVMTargetMachine(target);</div><div class="line">    <span class="keyword">bool</span> system_lib = (target.find(<span class="string">"-system-lib"</span>) != <span class="built_in">std</span>::<span class="built_in">string</span>::npos);</div><div class="line">    CHECK_NE(funcs.size(), <span class="number">0U</span>);</div><div class="line">    ctx_ = <span class="built_in">std</span>::make_shared&lt;llvm::LLVMContext&gt;();</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;CodeGenLLVM&gt; cg = CodeGenLLVM::Create(tm_.get());</div><div class="line">    entry_func_ = funcs[<span class="number">0</span>]-&gt;name;</div><div class="line">    cg-&gt;Init(funcs[<span class="number">0</span>]-&gt;name, tm_.get(), ctx_.get(), system_lib, system_lib);</div><div class="line">    <span class="keyword">for</span> (LoweredFunc f :  funcs) &#123;</div><div class="line">      cg-&gt;AddFunction(f);</div><div class="line">    &#125;</div><div class="line">    cg-&gt;AddMainFunction(funcs[<span class="number">0</span>]-&gt;name);</div><div class="line">    module_ = cg-&gt;Finish();</div><div class="line"></div><div class="line">    module_-&gt;addModuleFlag(llvm::Module::Warning, <span class="string">"tvm_target"</span>, llvm::MDString::get(*ctx_, target));</div><div class="line">    module_-&gt;addModuleFlag(llvm::Module::Override, <span class="string">"Debug Info Version"</span>,</div><div class="line">                           llvm::DEBUG_METADATA_VERSION);</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (tm_-&gt;getTargetTriple().isOSDarwin()) &#123;</div><div class="line">      module_-&gt;addModuleFlag(llvm::Module::Override, <span class="string">"Dwarf Version"</span>, <span class="number">2</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">string</span> verify_errors_storage;</div><div class="line">    llvm::<span class="function">raw_string_ostream <span class="title">verify_errors</span><span class="params">(verify_errors_storage)</span></span>;</div><div class="line">    LOG_IF(FATAL, llvm::verifyModule(*module_, &amp;verify_errors))</div><div class="line">        &lt;&lt; <span class="string">"LLVM module verification failed with the following errors: \n"</span></div><div class="line">        &lt;&lt; verify_errors.str();</div><div class="line">    target_ = target;</div><div class="line">    mptr_ = module_.get();</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<h2 id="0x34-根据LLVM-IR生成对应的机器指令"><a href="#0x34-根据LLVM-IR生成对应的机器指令" class="headerlink" title="0x34 根据LLVM IR生成对应的机器指令"></a>0x34 根据LLVM IR生成对应的机器指令</h2><p>调用了如下python代码就触发了机器指令的生成。<br>func(a, b, c)</p>
<p>func为前面返回的LLVM IR module对应的地址，a, b, c为对应的执行参数，也就是矩阵运算的输入。<br>对应到C++中的下述实现，调用LLVM模块来生成对应target的机器代码。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function">PackedFunc <span class="title">WrapPackedFunc</span><span class="params">(BackendPackedCFunc faddr,</span></span></div><div class="line">                          <span class="keyword">const</span> ObjectPtr&lt;Object&gt;&amp; sptr_to_self) &#123;</div><div class="line">  <span class="keyword">return</span> PackedFunc([faddr, sptr_to_self](TVMArgs args, TVMRetValue* rv) &#123;</div><div class="line">      <span class="keyword">int</span> ret = (*faddr)(</div><div class="line">          <span class="keyword">const_cast</span>&lt;TVMValue*&gt;(args.values),</div><div class="line">          <span class="keyword">const_cast</span>&lt;<span class="keyword">int</span>*&gt;(args.type_codes),</div><div class="line">          args.num_args);</div><div class="line">      CHECK_EQ(ret, <span class="number">0</span>) &lt;&lt; TVMGetLastError();</div><div class="line">    &#125;);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="0x35-评估执行时间"><a href="#0x35-评估执行时间" class="headerlink" title="0x35 评估执行时间"></a>0x35 评估执行时间</h2><p>python代码。<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">evaluator = func.time_evaluator(func.entry_name, ctx, number=1)</div><div class="line">print('Baseline: %f' % evaluator(a, b, c).mean)</div></pre></td></tr></table></figure></p>
<p>c++代码如下，调用LLVM生成的机器指令来执行具体的运算。这部分还包括了把运算调用到其他机器的rpc操作。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="function">PackedFunc <span class="title">WrapTimeEvaluator</span><span class="params">(PackedFunc pf,</span></span></div><div class="line">                             TVMContext ctx,</div><div class="line">                             <span class="keyword">int</span> number,</div><div class="line">                             <span class="keyword">int</span> repeat,</div><div class="line">                             <span class="keyword">int</span> min_repeat_ms) &#123;</div><div class="line">    ......</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; repeat; ++i) &#123;</div><div class="line">        ......</div><div class="line">        <span class="comment">// start timing</span></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; number; ++i) &#123;</div><div class="line">          pf.CallPacked(args, &amp;temp);</div><div class="line">        &#125;</div><div class="line">        ......</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/14/Analysis of mali kernel driver/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/12/14/Analysis of mali kernel driver/" itemprop="url">Analysis of mali kernel driver</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-12-14T20:18:31+08:00">
                2019-12-14
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2019/12/14/Analysis of mali kernel driver/" class="leancloud_visitors" data-flag-title="Analysis of mali kernel driver">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="0x1-硬件模块"><a href="#0x1-硬件模块" class="headerlink" title="0x1 硬件模块"></a>0x1 硬件模块</h1><p>分析Mali kernel driver代码，我们可以知道Mali Midgard硬件中包括下图所示的这些模块。下面简单介绍一下这些模块。</p>
<p>Shader Core指的是执行Shader的ALU单元，是可编程的运算单元。</p>
<p>Fixed Function Operator指的是Graphics Pipeline中诸如插值，光栅化等不可编程的硬件模块。</p>
<p>MMU是GPU中执行虚拟地址到物理地址转换的硬件模块。</p>
<p>Tiler指的是Tile Based Render中执行Tile划分的硬件模块。</p>
<p>Power Manager指管理GPU中各个硬件子模块的Power的硬件模块。</p>
<p>Job Executor，GPU User space driver根据应用执行的Graphics API来生成的Job，Job Executor是消费这些Job来驱动GPU硬件执行的状态机。</p>
<p>Cache，和CPU中的Cache类似，GPU中的cache也是为了提高GPU访问内存的速度与效率。<br><img src="/2019/12/14/Analysis of mali kernel driver/architecture.png" alt=""></p>
<h1 id="0x2-Power-Manager"><a href="#0x2-Power-Manager" class="headerlink" title="0x2 Power Manager"></a>0x2 Power Manager</h1><p>Mali Midgard中的Power Manager模块和SOC中的Power Manager模块关系如下图所示。<br><img src="/2019/12/14/Analysis of mali kernel driver/power_manager.png" alt=""></p>
<p>SoC中的Power Manager提供GPU硬件的Power输入。在SoC bring up阶段，经常会出现GPU不能工作的情况，这个时候需要和硬件工程师配合，检查SoC的Power输出到GPU的Power输入有没有配置好，是否没有上电，电压是否符合要求。另外经常出现的功耗问题也和GPU的Power设置相关，如suspend以后没有关闭GPU的Power，这样测量出来的功耗数据会很高。</p>
<p>如上图所示，GPU中包括三个可以独立控制Power的模块。分别是L2 cache，Shader cores和Tiler cores。<br>我们来想一下为什么要分成几个独立的Power模块呢？原因也是为了功耗的考虑。我们可以单独打开/关闭Shader cores的Power，同理对L2 cache和Tiler cores模块也是如此，这样可以根据GPU执行任务的情况灵活地控制这些模块Power的打开或者关闭。</p>
<h1 id="0x3-内存分配和释放"><a href="#0x3-内存分配和释放" class="headerlink" title="0x3  内存分配和释放"></a>0x3  内存分配和释放</h1><p>下图说明了kernel driver中分配内存的执行流程。<br>这个流程是由gpu user space driver驱动的，最后调用alloc_pages从Linux系统的内存管理模块分配出内存，分配的内存返回给user space driver以后，可以写入GPU执行过程中需要的数据，包括Job数据，顶点数据，纹理数据等，注意这些数据的写入是由CPU来完成的。当数据在user space driver都准备好了以后，就可以trigger kernel driver来执行GPU硬件工作，这个时候GPU硬件需要读取前面准备好的数据，这时需要借助GPU MMU来完成地址的转换工作，否则GPU没有办法完成数据的正确读取。</p>
<p><img src="/2019/12/14/Analysis of mali kernel driver/alloc_memory.svg" alt=""></p>
<p>前面介绍了内存是如何分配的，下面解释一下分配好的内存在被gpu user space driver填充好需要的数据以后，又回到gpu kernel driver是如何执行的呢？下图说明了执行的流程。具体的gpu job相关处理会在后面的章节中介绍。</p>
<p><img src="/2019/12/14/Analysis of mali kernel driver/use_memory.svg" alt=""></p>
<h1 id="0x4-GPU-MMU"><a href="#0x4-GPU-MMU" class="headerlink" title="0x4 GPU MMU"></a>0x4 GPU MMU</h1><p>前面已经提到GPU MMU用于支持GPU对非连续内存的访问。</p>
<p><img src="/2019/12/14/Analysis of mali kernel driver/mmu.png" alt=""></p>
<p>GPU MMU的实现和CPU用来管理内存的MMU实现机制类似，也就是提供了虚拟地址到物理地址的转换。<br>如果GPU中没有MMU，则GPU需要访问的物理地址空间必须是连续的，这对系统的内存管理提出了很高的要求，如在Android系统中只能使用通过ion driver分配的cma buffer(当然也可以是系统启动时候预留出来的物理连续内存, 不过这种情况不常见)。处理不好的话，很大概率会出现内存不足OOM(Out of memory)的错误。</p>
<p>驱动中提供了两种mmu的实现，根据硬件平台进行选择。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> (kbase_hw_has_feature(kbdev, BASE_HW_FEATURE_AARCH64_MMU))</div><div class="line">	kbdev-&gt;mmu_mode = kbase_mmu_mode_get_aarch64();</div><div class="line"><span class="keyword">else</span></div><div class="line">	kbdev-&gt;mmu_mode = kbase_mmu_mode_get_lpae();</div></pre></td></tr></table></figure></p>
<p>每一种mmu的实现都实现了下面的结构体。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * struct kbase_mmu_mode - object containing pointer to methods invoked for</div><div class="line"> *                         programming the MMU, as per the MMU mode supported</div><div class="line"> *                         by Hw.</div><div class="line"> * @update:           enable &amp; setup/configure one of the GPU address space.</div><div class="line"> * @get_as_setup:     retrieve the configuration of one of the GPU address space.</div><div class="line"> * @disable_as:       disable one of the GPU address space.</div><div class="line"> * @pte_to_phy_addr:  retrieve the physical address encoded in the page table entry.</div><div class="line"> * @ate_is_valid:     check if the pte is a valid address translation entry</div><div class="line"> *                    encoding the physical address of the actual mapped page.</div><div class="line"> * @pte_is_valid:     check if the pte is a valid entry encoding the physical</div><div class="line"> *                    address of the next lower level page table.</div><div class="line"> * @entry_set_ate:    program the pte to be a valid address translation entry to</div><div class="line"> *                    encode the physical address of the actual page being mapped.</div><div class="line"> * @entry_set_pte:    program the pte to be a valid entry to encode the physical</div><div class="line"> *                    address of the next lower level page table.</div><div class="line"> * @entry_invalidate: clear out or invalidate the pte.</div><div class="line"> * @flags:            bitmask of MMU mode flags. Refer to KBASE_MMU_MODE_ constants.</div><div class="line"> */</div><div class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">kbase_mmu_mode</span> <span class="title">const</span> <span class="title">lpae_mode</span> = &#123;</span></div><div class="line">	.update = mmu_update,</div><div class="line">	.get_as_setup = mmu_get_as_setup,</div><div class="line">	.disable_as = mmu_disable_as,</div><div class="line">	.pte_to_phy_addr = pte_to_phy_addr,</div><div class="line">	.ate_is_valid = ate_is_valid,</div><div class="line">	.pte_is_valid = pte_is_valid,</div><div class="line">	.entry_set_ate = entry_set_ate,</div><div class="line">	.entry_set_pte = entry_set_pte,</div><div class="line">	.entry_invalidate = entry_invalidate,</div><div class="line">	.flags = <span class="number">0</span></div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>GPU MMU中的页表结构和CPU MMU的类似，也是采用了多级页表结构。</p>
<p>GPU MMU中page fault的处理。<br>在MMU中断处理函数中判断是否发生了page fault，如果是则需要分配新的page给GPU，并把新分配的page信息更新到MMU中。</p>
<h1 id="0x5-GPU-Cache"><a href="#0x5-GPU-Cache" class="headerlink" title="0x5 GPU Cache"></a>0x5 GPU Cache</h1><p>GPU Cache位于gpu和memory之间，用来提高内存访问速度和效率。</p>
<p><img src="/2019/12/14/Analysis of mali kernel driver/cache.png" alt=""></p>
<p>这里面涉及到CPU和GPU之间的cache coherency的概念，指的是硬件平台上CPU的cache和GPU的cache是否可以同步。<br>如上图所示，CPU需要对内存中地址为addr的内存进行写操作，如果CPU采用的是write through的cache机制，CPU对内存地址addr的修改会立即写入到内存中，如果在GPU的cache中原来保存有地址addr的cache，这个时候通过Coherent Connection机制来通知GPU，告知内存地址addr对应的cache失效了，下次GPU访问内存地址addr的内存，从GPU的cache中不能读取到内存地址addr对应的数据了(cache不命中)，需要重新从内存中读取才能得到正确数据。</p>
<p>如果CPU采用的是write back的cache机制，CPU对地址addr修改以后不会立刻写回内存，这个时候可能大家觉得这样就没有办法通过到GPU了，其实还是有机制在这种情况下也是有办法来通过GPU去使对应的GPU cache失效的。这种机制叫“窥探（snooping）”协议，窥探协议的思想是，cache不仅仅在做内存传输的时候才和总线打交道，而是不停地在窥探总线上发生的数据交换，跟踪其他缓存在做什么。所以当CPU的cache代表CPU去读写内存时，GPU也会得到通知，这样CPU和GPU的缓存可以时刻保持同步。只要GPU或者CPU其中任何一方写了内存或者cache，对方马上就知道这块内存在它们自己的cache中对应的段已经失效，然后读取的时候需要从内存中读取。</p>
<p>注意在支持cache coherency的硬件平台上，上述操作是不需要软件干涉的，都是通过硬件来保证的。指ARM平台上CPU和GPU是cache coherency的。</p>
<p>但是如果CPU是x86的，GPU的mali的SoC平台中，要做到硬件的cache coherency比较困难，这个时候是需要软件来保证的。这样gpu driver的复杂度就增加了。</p>
<p>在mali 驱动中有下面三种cache coherency的设置。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">define</span> COHERENCY_ACE_LITE 0</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> COHERENCY_ACE      1</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> COHERENCY_NONE     31</span></div></pre></td></tr></table></figure></p>
<p>在驱动初始化函数kbase_device_coherency_init()中会设置cache coherency的类型。<br>如下所示，默认是设置成COHERENCY_NONE<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kbdev-&gt;system_coherency = COHERENCY_NONE;</div></pre></td></tr></table></figure></p>
<p>也可以通过dts来配置<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">coherency_override_dts = of_get_property(kbdev-&gt;dev-&gt;of_node,</div><div class="line">                        <span class="string">"system-coherency"</span>,</div><div class="line">                        <span class="literal">NULL</span>);</div><div class="line">override_coherency = be32_to_cpup(coherency_override_dts);</div><div class="line">kbdev-&gt;system_coherency = override_coherency;</div></pre></td></tr></table></figure></p>
<p>如下代码中，在CPU更新完page directory以后，如果不是cache coherency平台，这个时候需要sync来保证cache的一致性。<br>注意这个时候page directoy是在CPU侧写入的，CPU写入有可能只是写到cache的write buffer中，并没有真正写入内存，需要通过dma_sync_single_for_device来保证cache的write buffer中的内容都<br>写入了memory，这样后续GPU访问page directoy的时候能取得正确的数据。<br>这里有一个疑问，就是如果GPU的cache中已经有了对应内存地址的缓存内容，在不是cache coherency的平台中，是如何通知到GPU，使其对应的cache失效的呢？这部分我的理解可能也是通过硬件总线来完成的。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * kbase_mmu_sync_pgd - sync page directory to memory</div><div class="line"> * This should be called after each page directory update.</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">kbase_mmu_sync_pgd</span><span class="params">(struct kbase_device *kbdev,</span></span></div><div class="line">		<span class="keyword">dma_addr_t</span> handle, <span class="keyword">size_t</span> size)</div><div class="line">&#123;</div><div class="line">	<span class="comment">/* If page table is not coherent then ensure the gpu can read</span></div><div class="line">	 * the pages from memory</div><div class="line">	 */</div><div class="line">	<span class="keyword">if</span> (kbdev-&gt;system_coherency != COHERENCY_ACE)</div><div class="line">		dma_sync_single_for_device(kbdev-&gt;dev, handle, size,</div><div class="line">				DMA_TO_DEVICE);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>如下代码所示，在security模式下关闭cache coherent，保证内存数据读写的安全性。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">kbase_gpu_disable_coherent</span><span class="params">(struct kbase_device *kbdev)</span></span></div><div class="line">&#123;</div><div class="line">	lockdep_assert_held(&amp;kbdev-&gt;hwaccess_lock);</div><div class="line"></div><div class="line">	<span class="comment">/*</span></div><div class="line">	 * When entering into protected mode, we must ensure that the</div><div class="line">	 * GPU is not operating in coherent mode as well. This is to</div><div class="line">	 * ensure that no protected memory can be leaked.</div><div class="line">	 */</div><div class="line">	<span class="keyword">if</span> (kbdev-&gt;system_coherency == COHERENCY_ACE)</div><div class="line">		kbase_cache_set_coherency_mode(kbdev, COHERENCY_ACE_LITE);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>我们可以从下面的代码来理解一下dma_sync_single_for_cpu和dma_sync_single_for_device的区别。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">kbasep_10969_workaround_clamp_coordinates</span><span class="params">(struct kbase_jd_atom *katom)</span></span></div><div class="line">&#123;</div><div class="line">    ......</div><div class="line">    <span class="comment">// DMA transfer is complete</span></div><div class="line">    copy_size = MIN(PAGE_SIZE - offset, JOB_HEADER_SIZE);</div><div class="line">    page_1 = kmap_atomic(p);</div><div class="line">    <span class="comment">/* page_1 is a u32 pointer, offset is expressed in bytes */</span></div><div class="line">    page_1 += offset&gt;&gt;<span class="number">2</span>;</div><div class="line">    kbase_sync_single_for_cpu(katom-&gt;kctx-&gt;kbdev,</div><div class="line">            kbase_dma_addr(p) + offset,</div><div class="line">            copy_size, DMA_BIDIRECTIONAL);</div><div class="line">    <span class="built_in">memcpy</span>(dst, page_1, copy_size);</div><div class="line">    ......</div><div class="line">    <span class="comment">/* Flush CPU cache to update memory for future GPU reads*/</span></div><div class="line">    <span class="built_in">memcpy</span>(page_1, dst, copy_size);</div><div class="line">    p = as_page(page_array[page_index]);</div><div class="line">    kbase_sync_single_for_device(katom-&gt;kctx-&gt;kbdev,</div><div class="line">            kbase_dma_addr(p) + offset,</div><div class="line">            copy_size, DMA_TO_DEVICE);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>kbase_sync_single_for_cpu等同于dma_sync_single_for_cpu。用于数据从GPU到内存的DMA传送刚刚完成的情况。当DMA传输完成时，GPU已经将数据传输到内存，但是cache中可能还有老数据，为了避免CPU读取还是cache中的老数据，需要调用dma_sync_single_for_cpu，在ARM平台上相当于”invalidate”操作，也就是使cache无效的操作。从上面的代码可以，DMA传输完成后，先是调用了dma_sync_single_for_cpu，CPU再从内存地址page_1中读取数据。</p>
<p><img src="/2019/12/14/Analysis of mali kernel driver/dma_sync_single_for_cpu.png" alt=""></p>
<p>kbase_sync_single_for_device等同于dma_sync_single_for_device。用于数据从内存到GPU的DMA传送开始之前的情况，在CPU往内存的DMA缓冲区写入数据之后，这个时候数据可能没有立即反映到内存的DMA缓冲区上，因为该DMA缓冲区可能带有write buffer，导致数据只是写到了write buffer中，没有写入内存的DMA缓冲区上（为什么没有立即写入到内存的DMA缓冲区上呢？ 是为了等write buffer达到一定的大小以后一次写入到内存，为了提高效率）。这个时候需要调用dma_sync_single_for_device来做flush/clean操作，这样后续GPU启动DMA传输的时候可以从DMA缓冲区得到正确的数据。<br>如上代码所示，dma_sync_single_for_device之前调用了memcpy把数据传输到DMA缓冲区中，然后执行dma_sync_single_for_device()flush<br>write buffer中的数据，保证后续GPU的操作能得到正确的DMA数据。</p>
<p><img src="/2019/12/14/Analysis of mali kernel driver/dma_sync_single_for_device.png" alt=""></p>
<h1 id="0x6-中断处理"><a href="#0x6-中断处理" class="headerlink" title="0x6 中断处理"></a>0x6 中断处理</h1><p>从下面代码中我们可以知道gpu kernel driver需要处理下面三种中断。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">static</span> <span class="keyword">irq_handler_t</span> kbase_handler_table[] = &#123;</div><div class="line">    [JOB_IRQ_TAG] = kbase_job_irq_handler,</div><div class="line">    [MMU_IRQ_TAG] = kbase_mmu_irq_handler,</div><div class="line">    [GPU_IRQ_TAG] = kbase_gpu_irq_handler,</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>下图是三种中断处理函数的执行流程。</p>
<p><img src="/2019/12/14/Analysis of mali kernel driver/irq.png" alt=""></p>
<p>中断的处理流程如下。</p>
<ol>
<li>调用request_irq注册中断。</li>
<li>操作GPU register启动中断。</li>
<li>GPU硬件执行完成，触发中断。</li>
<li>处理中断处理函数，读取GPU register来判断硬件执行情况做进一步动作。</li>
</ol>
<h1 id="0x7-GPU-Job处理"><a href="#0x7-GPU-Job处理" class="headerlink" title="0x7. GPU Job处理"></a>0x7. GPU Job处理</h1><p>Mali GPU Job可以理解成GPU硬件能理解的IR(中间语言)。在Broadcom V3D中的CLE(control list executor)也是类似的概念。<br>gpu user space driver简单来说就是把上层应用的API调用转换成Job的描述。<br>kernel driver拿到这些Job以后，把Job的内存地址告诉GPU硬件，GPU硬件的Job Executor就开始parse这些Job，然后驱动GPU硬件的其他模块完成渲染或者计算工作。<br>Job可以组成Job chain的形式，Job chain中Job的执行可以有前后关系，如果该Job中需要读取texture信息，则Job中还包括texture存储位置的地址信息。</p>
<p><img src="/2019/12/14/Analysis of mali kernel driver/job.png" alt=""></p>
<p>下面的流程说明了GPU Job在kernel driver中是如何提交给GPU硬件的Job Executor的。<br><img src="/2019/12/14/Analysis of mali kernel driver/job_submit.svg" alt=""></p>
<h1 id="0x8-GPU-DVFS"><a href="#0x8-GPU-DVFS" class="headerlink" title="0x8. GPU DVFS"></a>0x8. GPU DVFS</h1><p>这部分是根据GPU的loading进行动态调整GPU的运行频率，也可以动态调整GPU Power的电压。这部分的实现依赖于Linux kernel提供的DVFS（Dynamic Voltage and Frequency Scaling）机制。<br>当然GPU dvfs的启用与否是根据场景来的。在功耗不敏感的场景下，如汽车娱乐系统中，GPU DVFS一般是关闭的。</p>
<h1 id="0x9-Reference"><a href="#0x9-Reference" class="headerlink" title="0x9 Reference"></a>0x9 Reference</h1><p><a href="https://developer.arm.com/tools-and-software/graphics-and-gaming/mali-drivers/midgard-kernel" target="_blank" rel="external">mali kernel driver source code</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/17/Understanding of eglSwapBuffers/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/17/Understanding of eglSwapBuffers/" itemprop="url">Understanding of eglSwapBuffers</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-17T20:00:30+08:00">
                2019-11-17
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2019/11/17/Understanding of eglSwapBuffers/" class="leancloud_visitors" data-flag-title="Understanding of eglSwapBuffers">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="0x1-eglSwapBuffers在图形系统中的作用"><a href="#0x1-eglSwapBuffers在图形系统中的作用" class="headerlink" title="0x1 eglSwapBuffers在图形系统中的作用"></a>0x1 eglSwapBuffers在图形系统中的作用</h1><p>在开发图形程序的时候，经常有同事问是不是调用eglSwapBuffers函数以后就可以输出显示了，如果简单来说可以这么理解，但是实际上gpu驱动中eglSwapBuffers函数执行以后只是提示上层模块该输出buffer可以使用了，这个时候是把输出buffer显示到屏幕上还是输出到文件中，或者是通过网络发送到远程终端上，取决于上层图形系统的设计。另外eglSwapBuffers函数需要配合上层模块(如Android上的Surface)完成buffer管理的工作。<br>本文详细介绍了eglSwapBuffers函数在图形系统中是如何配合上层buffer管理模块，完成从应用绘制到屏幕显示的完整流程的。</p>
<p>在典型图形系统中，一般包括了如下图所示的几个模块，应用程序绘制UI，合成器把多个UI合成为一帧图像，然后Frame buffer driver把合成好的图像绘制到屏幕硬件上。</p>
<p><img src="/2019/11/17/Understanding of eglSwapBuffers/eglswapbuffers.png" alt=""></p>
<p>这里有几个生产者-消费者模型，<br>App1/App2是UI内容的生产者，Compositor是App1/App2生产出来的UI内容的消费者，Compositor本身又是Frame buffer driver输入buffer的生产者。Frame buffer driver是Compositor生产出的buffer内容的消费者。</p>
<p>App1分配了三块buffer供gpu绘制使用，buffer的管理可以通过BufferQueue的模块来管理，在App1的绘制线程中调用gpu driver的eglSwapBuffers函数，eglSwapBuffers函数在执行的时候首先需要从BufferQueue中取得一块可以供GPU写入的buffer，如果这个时候没有空闲的buffer，gpu driver会在这里等待，如果发生这种情况，在性能分析的时候，我们可以在systrace上看到eglSwapBuffers占用的时间较长，从上面分析的buffer模型可以看出，出现没有空闲的buffer可能是Compositor执行太慢，三块buffer都被Compositor占用了，另外的原因可能是App1中gpu driver绘制执行时间太长，三块buffer都还在等待gpu硬件的写入完成。</p>
<p>eglSwapBuffers申请到了空闲的buffer以后，就可以把空闲buffer的地址设置给GPU硬件，并根据App1的其他设置驱动GPU硬件开始工作。这个时候eglSwapBuffers是否需要等待GPU硬件把完整的一帧绘制完成才返回呢?答案是不需要等待，但是会给这块buffer设置相应的fence，然后把这块buffer送给后续的Compositor来使用，Compositor在需要读取这块buffer内容之前，GPU硬件可以继续完成该buffer的绘制工作，达到CPU处理(Compositor的处理流程)和GPU处理的并行，Compositor在执行到了必须读取这块buffer内容的时候，会去检查buffer对应的fence的状态，如果还没有被signal，则需要等待，直至GPU绘制完成后singal对应的fence。</p>
<h1 id="0x2-应用进程使用eglSwapBuffers"><a href="#0x2-应用进程使用eglSwapBuffers" class="headerlink" title="0x2 应用进程使用eglSwapBuffers"></a>0x2 应用进程使用eglSwapBuffers</h1><p>App1执行流程如下所示。</p>
<p><img src="/2019/11/17/Understanding of eglSwapBuffers/app_draw.svg" alt=""></p>
<ol>
<li>应用程序调用createBufferQueue创建BufferQueue，其中包括Buffer的Producer和Consumer。Producer是buffer的生产者，Consumer是buffer的消费者。这样应用中的渲染线程相当于Producer，合成器是Consumer，是buffer的消费者。</li>
<li>BufferQueue通过合成器进程创建buffer队列，一般创建3个buffer。</li>
<li>渲染线程把Producer包装成Surface，然后把Surface作为参数去调用eglCreateWindowSurface。这样GPU driver相当于Producer，负责生产buffer。</li>
<li>应用程序调用draw命令，渲染线程调用eglSwapBuffers。</li>
<li>eglSwapBuffers通过dequeue()查找BufferQueue中空闲的buffer，如果没有空闲的buffer则需要等待。</li>
<li>eglSwapBuffers把空闲的buffer的地址设置给GPU硬件，并设置其他参数，驱动GPU硬件工作。</li>
<li>eglSwapBuffers通过queue()把前面GPU的写入buffer返回给BufferQueue，并设置相应的fence。</li>
<li>BufferQueue通过Consumer接口通知合成器有新的buffer到来，可以进行合成工作。</li>
</ol>
<h1 id="0x3-合成器进程使用eglSwapBuffers"><a href="#0x3-合成器进程使用eglSwapBuffers" class="headerlink" title="0x3 合成器进程使用eglSwapBuffers"></a>0x3 合成器进程使用eglSwapBuffers</h1><p>Compositor执行流程如下所示。<br>这里我们只讨论采用GPU来做合成的情况，如采用2D加速硬件来做合成的话就不会在合成器中调用eglSwapBuffers。</p>
<p><img src="/2019/11/17/Understanding of eglSwapBuffers/compositor_draw.svg" alt=""></p>
<ol>
<li>应用程序创建的时候会在合成器中创建相应的Layer，这样应用程序的绘制输出就可以通知到对应的Layer。</li>
<li>创建相应的DisplayDevice，在创建DisplayDevice的时候创建BufferQueue，这里Producer是合成器线程，Consumer是后面连接的Frame buffer driver。</li>
<li>应用程序通过其渲染线程中的eglSwapBuffers通知合成器有新的buffer到来，需要进行合成工作。</li>
<li>合成器线程准备开始合成，等待应用渲染线程中的buffer被GPU硬件绘制完成。</li>
<li>合成器线程调用eglSwapBuffers。</li>
<li>eglSwapBuffers通过dequeue()查找BufferQueue中空闲的buffer，如果没有空闲的buffer则需要等待。</li>
<li>eglSwapBuffers通过queue()把前面GPU的写入buffer返回给BufferQueue，并设置相应的fence。</li>
<li>BufferQueue通过Consumer接口通知Frame buffer driver有新的buffer到来，可以把buffer内容绘制到屏幕硬件上。</li>
</ol>
<h1 id="0x4-图形系统中buffer管理的特点"><a href="#0x4-图形系统中buffer管理的特点" class="headerlink" title="0x4 图形系统中buffer管理的特点"></a>0x4 图形系统中buffer管理的特点</h1><p>上面分析基本是基于Android系统的，从上面的流程可知，buffer的分配是在合成器进程中分配的，然后返回给应用进程使用。<br>如果是采用wayland协议的weston图形系统中，buffer的分配是在应用进程中进行的，然后把相应的buffer handle传给weston进程，作为weston合成的输入buffer使用。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/13/About Video Codec Optimization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kevin Wen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kevin Wen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/13/About Video Codec Optimization/" itemprop="url">About Video Codec Optimization</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-13T18:01:30+08:00">
                2019-10-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2019/10/13/About Video Codec Optimization/" class="leancloud_visitors" data-flag-title="About Video Codec Optimization">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="0x1-Video-Codec流程"><a href="#0x1-Video-Codec流程" class="headerlink" title="0x1 Video Codec流程"></a>0x1 Video Codec流程</h1><p>视频编码流程如下图所示。<br><img src="/2019/10/13/About Video Codec Optimization/Encoder.png" alt=""><br>视频解码流程如下图所示。<br><img src="/2019/10/13/About Video Codec Optimization/Decoder.png" alt=""><br>如何对编解码器进行优化呢？<br>主要方法有算法优化，指令集优化和并行优化。本文的后面部分会对这些优化方法进行详细的介绍。<br>这边先来介绍一下优化的量化指标。</p>
<p>对编解码来说，共性的指标是编解码速度和消耗的功耗。编解码速度可以用fps来量化。这个是典型的软件优化过程，这个时候，诸如降低cache miss率，循环展开等优化思想都是适用的。<br>对软件编解码器而言，功耗可以量化为CPU占用率或者是MIPS(Million Instructions Per Second)。对硬件编解码器来说，功耗可以量化成硬件执行频率/硬件使用率等，也可以是硬件电压和电流参数。</p>
<p>对编码器来说，我们还需要保证相同码率下图像质量不衰退，这个衡量指标是PSNR和码率。在编码优化过程中，如何保证优化以后不出问题呢？我们知道编码的流程中是包括解码过程的，我们可以把编码过程中解码部分输出的YUV数据保存下来，再把编码生成的码流用参考解码器进行解码并保存为参考YUV输出，这个参考YUV输出和前面编码器中保存的YUV数据进行比较，如果两者的YUV数据有差异，可以确定是编码器优化出了问题，这个时候可以比较具体的比特位差异来快速定位问题。</p>
<p>另外在编解码优化过程中，我们还会用到码流分析工具，如<a href="http://www.interrasystems.com/pdf/datasheet/Vega_Datasheet.pdf" target="_blank" rel="external">Vega</a>,<a href="https://www.elecard.com/zh/products/video-analysis/streameye" target="_blank" rel="external">streameye</a>和yuvviewer等。</p>
<p>对解码器来说，我们还需要运行各种conformance test来保证解码优化以后不引入衰退。</p>
<h1 id="0x2-算法优化"><a href="#0x2-算法优化" class="headerlink" title="0x2 算法优化"></a>0x2 算法优化</h1><p>算法优化主要针对编码器而言的。<br>编码算法优化的目标有三个，一个是在保证质量的前提下降低码率，另一个是码率不变情况下提升编码质量。第三个目标是保证图形质量和码率不变的情况下提升编码速度。</p>
<p>前面两个的目标也是制定编解码器标准的目标，在一种特定的码流格式确定之前需要召开多次会议来讨论码流的细节，这种会议会讨论各个单位的提案，选出最佳的coding tools，达到最佳的压缩效率。下面我们来讨论一下如何按照第三个目标来优化编码器。</p>
<p>编码算法进行优化后，如何保证编码质量呢？这个时候需要通过客观指标如PSNR来保证，或者是类似的主观指标如MOS或者DMOS来保证。通过比较优化前后的PSNR，我们可以知道编码质量有没有下降。如何检查码率有没有变化呢？这个很简单，直接比较编码生成的文件大小有没有增加即可。</p>
<p>下面以AVC的编码器为例，看看如何对编码算法进行一定的优化。</p>
<p>帧内预测优化<br>比如在AVC的Luma帧内编码过程中，对应4x4大小的block，我们需要遍历9种预测方向来找到最优的预测方式。这个时候我们可以利用像素的特点减少预测方向的数量。另外还有16x16,8x8(High Profile而言)大小需要比较，这个时候都可以通过减少预测数量来优化。</p>
<p>帧间预测优化<br>对帧间预测的模式选择过程进行优化，因为运动估计比较耗时，如果所有模式都搜索一遍很耗时，可以利用像素特点对运动估计进行简化。<br>还有一种是I macroblock in P frame，需要计算什么情况下要在P frame采用Intra macroblock，这个过程也可以优化，对P frame中一个特定的宏块，可以采用某种方式来判断是否需要进行采用Intra编码，而不是需要计算好Inter和Intra的cost才能通过比较cost来选择。<br>另外可以采用不同的运动搜索算法来对简化通过运动搜索找到最佳运动矢量的过程。</p>
<p>码率控制优化<br>码率控制的过程是选择哪个宏块采用哪个量化参数QP的过程，有frame level的码率控制， 这个时候整个frame都是采用固定的QP。有slice level的码率控制，这个时候整个slice采用固定的QP。有macroblock level的码率控制，这个时候每个宏块可以自由地调节QP。macroblock level的码率控制是最准确的，但是计算复杂度也最大，可以通过在这几种码率控制级别之间进行选择，来达到码率控制和计算复杂度之间的平衡。</p>
<p>解码因为是固定的流程，算法没有办法进行优化，当然也有特例，如2006年左右PC性能比较差的时候，需要播放BluRay的AVC码流，在1080P情况下AVC软件解码性能不足，CPU占用率高，某播放器公司是把AVC的deblocking关闭的，当然画面质量会受到一些影响。另外在早期SOC平台性能不足，在软件解码的时候，很多时候会把不参与预测的B帧直接丢弃。</p>
<h1 id="0x3-平台指令集优化"><a href="#0x3-平台指令集优化" class="headerlink" title="0x3 平台指令集优化"></a>0x3 平台指令集优化</h1><p>这种优化方法是采用各个平台特有的SIMD指令对编解码过程中某些运算过程进行加速，如x86上的mmx/sse/sse2/sse3/sse4/avx/avx512等SIMD指令，ARM平台上的SIMD指令有neon指令。</p>
<p>如编解码过程中典型的Hadmard变换，SATD, SAD, DCT, IDCT,运动补偿插值，Deblocking等过程都是很适合采用SIMD指令来加速的。<br>这里特别说明一下运动补偿插值的过程，目前AVC的Luma分量支持1/4像素的插值，也就是说每个像素需要插值成15个分像素点供后续运动估计使用。如果内存充足的话，可以利用SIMD方法把15个分像素点先计算好，这样在运动估计的时候就不需要做插值工作。<br>如下图所示，方框所示为整像素点，圆形所示为分像素点。可以按照1/2/3, 4/8/12, 5/7/13/15, 10, 6/9/11/14的过程进行SIMD计算。<br><img src="/2019/10/13/About Video Codec Optimization/Quarter pixel interpolation.png" alt=""><br>目前各个开源编解码库，如ffmpeg,x264,xvid,x265等，这些库的很大部分优化工作就是在各个平台上进行SIMD优化。</p>
<h1 id="0x4-GPU并行优化"><a href="#0x4-GPU并行优化" class="headerlink" title="0x4 GPU并行优化"></a>0x4 GPU并行优化</h1><p>这里说的GPU并行优化一般指采用opencl/cuda之类的GPU Compute API来进行编解码的处理。</p>
<p>x264中采用了opencl来进行编码优化，把CPU需要完成的工作offload到GPU中来完成，其中x264采用opencl来在analysis阶段分析像素的特点来提前确定GOP中IBP帧的排列分布，还用来判断当前Slice是需要用Intra编码还是Inter编码。</p>
<h1 id="0x5-并行优化"><a href="#0x5-并行优化" class="headerlink" title="0x5 并行优化"></a>0x5 并行优化</h1><h2 id="0x51-分布式优化"><a href="#0x51-分布式优化" class="headerlink" title="0x51 分布式优化"></a>0x51 分布式优化</h2><p>分布式优化一般用于编码优化，基本原理是把需要编码的文件划分成几个部分，每一部分分别在不同的机器上进行编码，编码完成以后再把编码好的几段码流合并成一个完整的码流。这种编码优化方法一般多见于专业视频制作过程，需要保证图形质量最佳的情况下码率最小，一般会启用编码器中的所有feature。另外一般采用多pass的编码方法，第一个pass先分析输入素材的特点，根据分布式处理的机器数目来确定那一段输入素材在哪台机器上进行编码。另外需要指出的是在分割点附近的码率控制算法需要特别处理，否则容易出现码率突然增大的情况。<br><img src="/2019/10/13/About Video Codec Optimization/Clip Level Parallel.png" alt=""></p>
<h2 id="0x52-GOP并行优化"><a href="#0x52-GOP并行优化" class="headerlink" title="0x52 GOP并行优化"></a>0x52 GOP并行优化</h2><p>这种优化方法是把一个GOP分配给一个线程来进行优化。<br>对编码而言，可以控制每个GOP中frame的数目，并且不采用Open GOP，只采用Close GOP的方式来进行编码。这样每个线程的负载可以做到比较平均。每个GOP开头和结尾处的码率控制需要特别处理。</p>
<p>对解码而言， 如果GOP之间的frame数目差别较大，则没有办法做到线程的负载平衡。而且如果是Open GOP的话，线程之间也有等待操作。<br><img src="/2019/10/13/About Video Codec Optimization/GOP Level Parallel.png" alt=""></p>
<h2 id="0x53-Frame并行优化"><a href="#0x53-Frame并行优化" class="headerlink" title="0x53 Frame并行优化"></a>0x53 Frame并行优化</h2><p>Frame级别优化是把Frame分配给不同的线程处理，一般用于视频解码，如果当前帧的当前宏块的解码过程需要依赖于前面帧的解码完成，这个时候是需要等待，这个在目前的视频标准中是很常见的。如P帧的解码需要依赖前面I帧的解码完成。<br><img src="/2019/10/13/About Video Codec Optimization/Frame Level Parallel.png" alt=""></p>
<h2 id="0x54-Slice并行优化"><a href="#0x54-Slice并行优化" class="headerlink" title="0x54 Slice并行优化"></a>0x54 Slice并行优化</h2><p>对编码器来说，可以按照多个Slice来并行编码，只需要在编码器启动的时候配置好Slice数目即可，需要注意的是，Slice编码完成以后，一般需要进行Deblocking，这个过程是跨Slice边界的，也就是说这个时候没有办法并行处理了，需要等待所有Slice编码完成以后在Control Thread中完成Deblocking的过程。<br>对解码器来说，按照码流中的slice数目启动多线程解码。<br>这种并行优化方式的优点是实现简单。<br>这种并行优化方式的缺点是，对编码器来说会稍微损失码率，对解码器来说是依赖于slice数目，如果只有一个slice,没办法并行处理。<br><img src="/2019/10/13/About Video Codec Optimization/Slice Level Parallel.png" alt=""></p>
<h2 id="0x55-MB-Block并行优化"><a href="#0x55-MB-Block并行优化" class="headerlink" title="0x55 MB Block并行优化"></a>0x55 MB Block并行优化</h2><p>这种优化方式一般用于解码器。优点是线程负载比较平衡，缺点是实现较复杂，需要深入解码器内部进行划分任务，把解码任务划分成不同的阶段，如VLD，IDCT，MC，Deblocking等。每个线程只是执行一个阶段的任务，而且执行的宏块数也只是上图中一个长方框内的宏块数目。这个时候如果算法的实现中对前后方框之间的宏块有数据依赖的话，需要加入同步机制。如ffmpeg就没有实现这种方式。<br><img src="/2019/10/13/About Video Codec Optimization/Macroblock Level Parallel.png" alt=""></p>
<h1 id="0x6-AI优化"><a href="#0x6-AI优化" class="headerlink" title="0x6 AI优化"></a>0x6 AI优化</h1><p>AV1的参考编码器libaom中采用了AI来加速partiton划分, partiton划分在libaom中占用了大概80%的复杂度。libaom编码过程中采用的CNN + DNN的网络是经过训练的，在libaom的代码中并没有提供这个网络结构的训练过程代码。但是从其推理过程我们可以大体知道其训练过程，其实现方式应该是设计好网络以后，通过大量样本数据来训练得到该推理网络的。</p>
<h1 id="0x7-硬件优化"><a href="#0x7-硬件优化" class="headerlink" title="0x7 硬件优化"></a>0x7 硬件优化</h1><p>下面提到的DXVA和LibVA是指通过GPU集成的视频编解码能力来加速视频处理。<br>DXVA指Windows平台上的GPU视频编解码加速标准。<br>LibVA指Linux平台上的GPU视频编解码加速标准。</p>
<p>DXVA架构图如下所示。<br><img src="/2019/10/13/About Video Codec Optimization/DXVA.png" alt=""><br>LibVA架构图如下所示。<br><img src="/2019/10/13/About Video Codec Optimization/LibVA.png" alt=""><br>ASIC优化<br>还有一种优化方法是把编解码模块做成ASIC模块，如早期的WisChip公司的视频编解码器。<br>现在Verisilicon公司的Hantro IP, Broadcom的VideoCore， 各个手机SOC厂商（Huawei, MTK, Spreadtrum, qualcomm)在SOC中集成的视频编解码IP。</p>
<p>DSP优化<br>如TI公司的DSP平台如TMS320C64可以用来优化Codec。</p>
<p>FPGA优化<br>如Altera和Xilinx的FPGA都可以用来优化视频编解码能力。</p>
<h1 id="0x8-优化思考"><a href="#0x8-优化思考" class="headerlink" title="0x8 优化思考"></a>0x8 优化思考</h1><p>目前openmp, tbb等基础库已经很成熟，已经广泛应用于各种深度学习推理框架的优化中。视频编解码优化应该也可以采用这些基础库来优化。<br>另外是可以思考是否可以采用TVM类似框架来优化，现在对推理框架的优化热潮和十多年前对codec的优化热潮很像。如果可以有TVM类似的框架，目前视频编解码优化中各种平台上的手写SIMD优化工作应该可以通过类似的AutoTune工作来完成。这样视频编解码优化的工作可以从繁重的手写汇编的工作中解放出来，把优化侧重点放在对算法和计算流程方面的优化。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Kevin Wen" />
          <p class="site-author-name" itemprop="name">Kevin Wen</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">39</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">21</span>
                <span class="site-state-item-name">标签</span>
              
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Kevin Wen</span>
</div>


<div> <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
访问量 <span id="busuanzi_value_site_pv"></span>
访问人数 <span id="busuanzi_value_site_uv"></span>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("orq8xxsDQDXKiHdqSRcjlflB-gzGzoHsz", "ecCFdIcWDfbJKQOCiLFf1EBm");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  

  

  

</body>
</html>
